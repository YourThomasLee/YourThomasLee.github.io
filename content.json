{"meta":{"title":"Thomas Lee(李柏珍,Baizhen Li)","subtitle":"抱残守缺","description":"个人博客试验田1号","author":"Thomas Lee (李柏珍,Baizhen Li)","url":"http://YourThomasLee.github.io","root":"/"},"pages":[],"posts":[{"title":"Curriculum vitae - Baizhen Li","slug":"Curriculum Vitae - Baizhen Li","date":"2022-12-26T13:54:13.432Z","updated":"2022-12-27T03:32:08.569Z","comments":true,"path":"2022/12/26/Curriculum Vitae - Baizhen Li/","link":"","permalink":"http://yourthomaslee.github.io/2022/12/26/Curriculum%20Vitae%20-%20Baizhen%20Li/","excerpt":"","text":"Contact information: 1833009 [at] tongji [dot] edu [dot] cn || baizhen9406 [at] 163 [dot] com Education Tongji UNIVERSITY 06/2018 - 03/2021 M.E., Computer Technology. GPA: 87/100 Thesis: Research on dialogue state tracking algorithm based on cross-layer fusion Awards and honors: National Scholarship(2020), Second Prize of the 15th China Post-graduate Mathematical Contest in Modelling, Outstanding Dissertation Award YANTAI UNIVERSITY 06/2013 - 07/2017 B.E., Computer Science and Technology. GPA: 79/100 Thesis: Research on knowledge acquisition algorithms: a discernibility matrix approach Awards and honors: Outstanding Dissertation Award, Third Prize of LAN QIAO International Collegiate Programming Contest Experiences I. Research experiences From 08/2019 to 12/2020, I participated in “Research on the Refined Description and Interpretability of Targets under Surveillance Video”(National natural science foundation of China, No. 61976160). I was in charge of models that provide task-oriented description of a picture collected from surveillance video while working as a researcher under the direction of professor Zhihua Wei and associate professor Lijun Sun. From 06/2018 to 07/2019, I took part in \"Topic Analysis Technology based on Natural Language Processing” (application research cooperated with the key lab of information network security, China ministry of public security, No. C18608). I created topic analysis-based detection techniques for illicit websites detection while working as a researcher and developer under the direction of professor Zhihua Wei and associate professor Lijun Sun. From 03/2014 to 06/2017, I participated in “Knowledge Space Research based on Granular Computing Method” (national natural science foundation of China youth science fund project, No. 61403329). I created two more effective rough sets-based knowledge discovery algorithms as a research assistant under the direction of associate professor Nan Zhang. II. Work/Internship experiences BAIDU CHINA CO., LTD. 03/2021 – 05/2022 As an engineer, I was in charge of the real-time bidding system’s cost-per-thousand-impression calibration(CTIA) module. By tweaking the algorithm’s parameters and state estimates, I improved the proportional-integral-derivative (PID) control algorithm’s performance in CTIA. HAIYIZHI INFORMATION TECHNOLOGY CO., LTD. 06/2020 – 09/2020 I created a robot that serves as the customer support representative in the postal service’s online chat. After that, I used a non-autoregressive dialog state tracking model to reduce the inference latency for dialog state tracking. Publications [1] Baizhen Li, Yibin Zhan, Zhihua Wei, Shikun Huang, Lijun Sun: Improved non-autoregressive dialog state tracking model. CCRIS 2021: 199-203 [2] Baizhen Li, Zhihua Wei, Duoqian Miao, Nan Zhang, Wen Shen, Chang Gong, Hongyun Zhang, Lijun Sun: Improved general attribute reduction algorithms. Inf. Sci. 536: 298-316 (2020) [3] Baizhen Li, Wei Chen, Zhihua Wei, Hongyun Zhang, Nan Zhang, Lijun Sun: Quick Maximum Distribution Reduction in Inconsistent Decision Tables. IJCRS 2020: 169-182 [4] Nan Zhang, Baizhen Li, Zhongxi Zhang, Yanyan Guo: A Quick Algorithm for Binary Discernibility Matrix Simplification using Deterministic Finite Automata. Inf. 9(12): 314 (2018)","categories":[],"tags":[]},{"title":"Note - Prioritized training on points that are learnable worth learning and not yet learnt","slug":"Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt","date":"2022-07-22T02:40:05.000Z","updated":"2022-12-27T03:36:11.314Z","comments":true,"path":"2022/07/22/Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/22/Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt/","excerpt":"","text":"This paper introduce RHO_LOSS, which selects points that are learnable, worth learning, and not yet learnt. RHO-LOSS trains in far fewer steps than prior art, improves accuracy, and speeds up training on a wide range of datasets, hyperparameters, and architectures (MLPs, CNNs, and BERT) Code: https://github.com/OATML/RHO-Loss Concepts: a model with parameter training on dataset using stochastic gradient descent(SGD) : a batch of size from dataset at step with is the predictive distribution of the current model, where is the sequence of data the model was trained on before training step $ D_{ho} ={ (x_{ho}, y_{ho}) } {i=1}^{n{ho} } x_{ho}y_{ho}p_{true}(x′, y′)D$. Intuition: Previous online batch selection methods aim to select points that minimize the training set loss. Instead, we aim to select points that minimize the loss on a holdout set. We aim to acquire the point that would minimize the negative log-likelihood/cross-entropy loss on the holdout set: $ arg \\min {(x,y)\\in B_t} - \\log p(y{ho}|x_{ho};D_t \\cup (x, y))$ [get similar distribution as holdout set] Inference: For a model using a point estimate of (such as an MLE or MAP), rather than a distribution over , the holdout loss factorises and (up to a constant factor) forms a Monte Carlo approximation of the expected loss under : , where denotes the cross-entropy loss: , $$ \\log p(y_{ho}|x_{ho};D_t \\cup (x, y)) = \\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x,x_{ho};D_t)}[Bayes; rule]\\ =\\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x;D_t)}[conditional; independence; rule]\\ \\propto L[y|x;D_t] - L[y|x;D_{ho},D_t]\\ \\sim L[y|x;D_t] - L[y|x;D_{ho}]\\ \\Rightarrow \\arg \\max {(x,y) \\in B_t} L[y|x;D_t] - L[y|x;D{ho}]\\quad[training; loss - ;irreducible; holdout; loss] $$ Algorithm: Exploring: why not design a new simpler loss based on rough set thoery? it seems RHOLOSS is still a little expensive in implementation and computation. Actually this work provides a good way to think about the training sample selection problem. There are still room for some more further researches in computation simplicity and cost aspects","categories":[],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"http://yourthomaslee.github.io/tags/deep-learning/"},{"name":"training sample selection","slug":"training-sample-selection","permalink":"http://yourthomaslee.github.io/tags/training-sample-selection/"}]},{"title":"Note-Trainable learning rate","slug":"Note-Trainable-learning-rate","date":"2022-07-19T09:26:53.000Z","updated":"2022-12-27T03:38:45.291Z","comments":true,"path":"2022/07/19/Note-Trainable-learning-rate/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/19/Note-Trainable-learning-rate/","excerpt":"","text":"Problem: selecting an appropriate learning rate is a challenge considering different model structures and datasets. Work: we propose an algorithm for automatically adjusting the learning rate during the gradient descent (line search method) Given the weights’ gradients, one could estimate if an overestimation or an underestimation of learning rate could further reduce the task loss by casting the learning rate as an extra trainable parameter. Problem Statement: the gradient descent framework (GD). vanilla form: , where is learning rate, is loss function and is the model parameters at iteration . In vanilla GD, Is treated as a hyperparameter and does not contribute to the loss. We introduce an augmented loss term , where we consider as the learnable variable. . Something noticing is that minimizing is equivalent to finding the optimal step-size for current . Naive GD-TLR: A straightforward idea is to apply GD over : , where hyperparameter Controls the updates of the initial learning rate Disadvantages: the addition of requires an extra forward-backward pass in order to compute the introduction of a GD step for creates the extra hyperparameter Efficient GD-TLR: let Denotes a standard feed-forward network of Layers, where and denote the non-linear activation and linear transformation corresponding to layer respectively. For the convenience of writing, we just consider the linearity of a single layer , where is the input from the previous layer, is the matrix of parameters, is the output. (, ) denotes the variables after GD update. So we have First-order gradient and insight: Assuming that corresponds to a specific layer, the gradient of the augmented loss compute as: the learning rate gradient can be expressed as the inner product of consecutive gradients , as a result we can rewrite equation (2) as $ \\frac{\\partial L_\\alpha}{\\partial \\alpha}|{a=\\alpha_t} = -&lt;\\triangledown L(w_t), \\triangledown L(w{t - 1})&gt; = -&lt;g_t, g_{t-1}&gt; $. The derived gradient (take indicator ind for simplifing) has an intuitive interpretation: Ind &gt; 0: the learning rate should be increased Ind &lt; 0: the learning rate should be decreased Ind = 0: either we reached a converged state of gradient directions are perpendicular. Second-order gradient: a newton-based method requires Hessian computations/approximations of the network’s weights, and the problem at hand has an intuitive analytical form, using only first-order weight gradients, as following suggests: $$ \\frac{\\partial^2L}{\\partial \\alpha^2}|{\\alpha=\\alpha_t}=\\frac{4}{\\alpha}&lt;g_t, g_t-g{t-1}&gt;=\\frac{4}{\\alpha_t}(||g_t||^2-&lt;g_t,g_{t-1}&gt;) \\eta_t = \\frac{\\alpha_t}{\\max(4&lt;g_t, g_t-g_{t-1}), c^{-1}&lt;g_t, g_{t-1}&gt;)} $$ where we form an overall bound on the update of which imposes smoother behavior (c was set as 1/4 in paper) Efficient GD-TLR Input: number of iterations , initial weights , learning rate , hyperparameter Output: optimized weights step 1: initialize = 0 step 2: for to do step 3: single forward-backward pass: step 4: compute step 5: update alpha according to Equation 2 and 3 [ ] step 6: update w: ; step 7: ; step 8: end for Exploring problem： the analysis in appendices, may be we will explore it next time I read it. Interested in automatical layer-wise learning rate in the future research the performance and the disadvantage of the algorithm. I think there is still necessity of experiment","categories":[],"tags":[{"name":"trainable learning rate","slug":"trainable-learning-rate","permalink":"http://yourthomaslee.github.io/tags/trainable-learning-rate/"}]},{"title":"Notes-mitigating neural network overconfidence with logit normalization","slug":"Note-mitigating neural network overconfidence with logit-normalization","date":"2022-07-11T08:49:33.000Z","updated":"2022-12-27T03:34:16.757Z","comments":true,"path":"2022/07/11/Note-mitigating neural network overconfidence with logit-normalization/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/11/Note-mitigating%20neural%20network%20overconfidence%20with%20logit-normalization/","excerpt":"introduce Logit Normalization (LogitNorm), a simple fix to the cross-entropy loss (by enforcing a constant vector norm on the logits in training), to deal with overfitting or overconfidence for both in- and out-of-distribution inputs.","text":"introduce Logit Normalization (LogitNorm), a simple fix to the cross-entropy loss (by enforcing a constant vector norm on the logits in training), to deal with overfitting or overconfidence for both in- and out-of-distribution inputs. Problem: we find that even when most training examples are classified to their correct labels, the softmax cross-entropy loss can continue to increase the magnitude of the logit vectors. The growing magnitude during training thus leads to the overconfidence issue, despite having no improvement on the classification accuracy. Work: To mitigate the issue, our key idea behind LogitNorm is to decouple the influence of output’s norm from the training objective and its optimization. This can be achieved by normalizing the logit vector to have a constant norm dur- ing training. In effect, our LogitNorm loss encourages the direction of the logit output to be consistent with the corre- sponding one-hot label, without exacerbating the magnitude of the output. Trained with normalized outputs, the network tends to give conservative predictions and results in strong separability of softmax confidence scores between ID and OOD inputs Codes: https://github.com/hongxin001/logitnorm_ood Core equation: to make sure that the logit vector is a unit vector, it alleviate some challenges in optimization, or rather, let optimization does more things useful! where is logit vector, is the Euclidean norm of the logit vector, and denotes the quantity of different class labels. Comment: This work restricts the numerical bound of logit vector during optimization, and it results better model performance in classification task. Exploring problem： Can we get the better performance if we use label smoothing? what is the difference between LayerNorm and LogitNorm? Is there any other efficient way to implement LogitNorm? Is this work compatible to the paper “Long-Tail Learning via Logit Adjustment” (https://arxiv.org/pdf/2007.07314.pdf)?","categories":[],"tags":[{"name":"overfitting","slug":"overfitting","permalink":"http://yourthomaslee.github.io/tags/overfitting/"},{"name":"logit normalization","slug":"logit-normalization","permalink":"http://yourthomaslee.github.io/tags/logit-normalization/"}]},{"title":"Hello World","slug":"hello-world","date":"2022-03-20T15:33:35.180Z","updated":"2022-03-20T15:33:34.000Z","comments":true,"path":"2022/03/20/hello-world/","link":"","permalink":"http://yourthomaslee.github.io/2022/03/20/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new \"My New Post\" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"http://yourthomaslee.github.io/tags/deep-learning/"},{"name":"training sample selection","slug":"training-sample-selection","permalink":"http://yourthomaslee.github.io/tags/training-sample-selection/"},{"name":"trainable learning rate","slug":"trainable-learning-rate","permalink":"http://yourthomaslee.github.io/tags/trainable-learning-rate/"},{"name":"overfitting","slug":"overfitting","permalink":"http://yourthomaslee.github.io/tags/overfitting/"},{"name":"logit normalization","slug":"logit-normalization","permalink":"http://yourthomaslee.github.io/tags/logit-normalization/"}]}