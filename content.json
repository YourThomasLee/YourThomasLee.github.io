{"meta":{"title":"Thomas Lee(李柏珍,Baizhen Li)","subtitle":"抱残守缺","description":"个人博客试验田1号","author":"Thomas Lee (李柏珍,Baizhen Li)","url":"http://YourThomasLee.github.io","root":"/"},"pages":[],"posts":[{"title":"1223. Dice Roll Simulation","slug":"Leetcode 1223","date":"2023-02-10T02:40:05.000Z","updated":"2023-02-10T03:16:52.183Z","comments":true,"path":"2023/02/10/Leetcode 1223/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/10/Leetcode%201223/","excerpt":"","text":"The problem description can be found at the link Solution explanation can be referred at link Solution: 123456789101112131415161718192021class Solution {public: static constexpr int mod = 1E9 + 7; int dieSimulator(int n, vector&lt;int&gt;&amp; rollMax) { vector d(n + 1, vector&lt;int&gt;(6, 0)); vector&lt;int&gt; sum(n + 1, 0); sum[0] = 1; for (int i = 1; i &lt;= n; i++) { for (int j = 0; j &lt; 6; j++) { int pos = max(i - rollMax[j] - 1, 0); int sub = ((sum[pos] - d[pos][j]) % mod + mod) % mod; d[i][j] = ((sum[i - 1] - sub) % mod + mod) % mod; if (i &lt;= rollMax[j]) { d[i][j] = (d[i][j] + 1) % mod; } sum[i] = (sum[i] + d[i][j]) % mod; } } return sum[n]; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"dynamic programming","slug":"dynamic-programming","permalink":"http://yourthomaslee.github.io/tags/dynamic-programming/"},{"name":"combination","slug":"combination","permalink":"http://yourthomaslee.github.io/tags/combination/"},{"name":"interesting problems","slug":"interesting-problems","permalink":"http://yourthomaslee.github.io/tags/interesting-problems/"}]},{"title":"1797. Design Authentication Manager","slug":"Leetcode 1797","date":"2023-02-09T02:40:05.000Z","updated":"2023-02-09T02:37:57.470Z","comments":true,"path":"2023/02/09/Leetcode 1797/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/09/Leetcode%201797/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425class AuthenticationManager {public: int timeToLive; map&lt;string, int&gt; u2t; AuthenticationManager(int timeToLive) { this-&gt;timeToLive = timeToLive; } void generate(string tokenId, int currentTime) { u2t[tokenId] = currentTime; } void renew(string tokenId, int currentTime) { if(u2t.find(tokenId) != u2t.end() &amp;&amp; currentTime - u2t[tokenId] &lt; timeToLive) u2t[tokenId] = currentTime; } int countUnexpiredTokens(int currentTime) { int ans = 0; for(auto x: u2t){ if(currentTime - x.second &lt; timeToLive) ans++; } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"}]},{"title":"1233. Remove Sub-Folders from the Filesystem","slug":"Leetcode 1233","date":"2023-02-08T02:40:05.000Z","updated":"2023-02-08T01:23:00.267Z","comments":true,"path":"2023/02/08/Leetcode 1233/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/08/Leetcode%201233/","excerpt":"","text":"Problem description can be found at link My solution: 12345678910111213141516171819class Solution {public: vector&lt;string&gt; removeSubfolders(vector&lt;string&gt;&amp; folder) { sort(folder.begin(), folder.end()); vector&lt;string&gt; ans; int p = 0, len = 0; ans.emplace_back(folder[0]); for(int i = 1; i &lt; folder.size(); ++i){ len = min(folder[i].size(), folder[p].size()); if(folder[i].substr(0, len) == folder[p].substr(0, len) &amp;&amp; folder[i][len] == '/'){ continue; }else{ ans.emplace_back(folder[i]); p = i; } } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"array","slug":"array","permalink":"http://yourthomaslee.github.io/tags/array/"}]},{"title":"Machine learning foundation 1 - linear regression","slug":"Machine learning foundation 1 - linear regression","date":"2023-02-08T02:40:05.000Z","updated":"2023-02-08T15:28:35.380Z","comments":true,"path":"2023/02/08/Machine learning foundation 1 - linear regression/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/08/Machine%20learning%20foundation%201%20-%20linear%20regression/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 Outline 1234567891011121314graph LRA(线性回归) --&gt; B[直觉]A(线性回归) --&gt; C[模型]A(线性回归) --&gt; D[优化]A(线性回归) --&gt; E[拓展]B[直觉] --&gt; F[找到一条直线或一个平面能够根据输入的特征向量来更好的预测输出y的值]B[直觉] --&gt; G[损失函数:平方损失,绝对值损失,huber损失]C[模型] --&gt; N[线性函数]D[优化] --&gt; H[梯度下降]D[优化] --&gt; I[正规方程组]E[拓展] --&gt; J[Lasso回归-L1 Norm]E[拓展] --&gt; K[岭回归-L2 Norm]E[拓展] --&gt; L[局部加权线性回归]E[拓展] --&gt; M[ElasticNet-L1 L2 Norm] 1. 直觉与目标 简单来说，线性回归算法就是**找到一条直线（一元线性回归）或一个平面（多元线性回归）能够根据输入的特征向量来更好的预测输出y的值。**其本质含义在于 X 与 Y 是线性相关的。 在有了该直觉之后，我们的第一个目标是根据给定的如何评估一条直线是否合理，也就是如何评估出多个不同的直线的序，目前比较典型的思路是设计一个函数，输入给定的模型和数据，输出键值，比较键值大小就可以知晓哪一条直线是最优的(一般默认越小越好)。就目前来说，典型的键值(损失)函数有三种，具体公式如下，损失函数图如下。 平方损失： , 对异常点有较大的惩罚，不够robust。 绝对值损失：，在0处不可导，不易优化 Huber损失：，该损失函数是1,2的综合，较为鲁棒 第一个目标达成后，我们的目标就变为根据数据将不合理的直线调整变换为合理，该过程也叫学习，在机器学习中叫优化, 该部分内容详见第3部分。 2. 模型 给定训练数据, 线性回归的模型设定为 一般地，我们使用平方损失函数来做为衡量直线优劣的指标，也即. 朴素的二元线性回归：梯度下降法 Missing \\end{aligned} \\begin{aligned}\\frac{\\partial L}{\\partial w}=&amp;\\sum_{i=1}^{n}2(wx_i+b-y_i)x_i\\&amp;=2\\sum_{i=1}^{n}w(x_i)^2+bx_i-x_iy_i\\\\frac{\\partial L}{\\partial b}=&amp;\\sum_{i=1}^{n}2(wx_i+b-y_i)=0\\&amp;\\Rightarrow b=\\frac{\\sum_{i=1}^{n}y_i-wx_i}{n}\\\\frac{\\partial L}{\\partial w}=&amp;2\\sum_{i=1}^{n}w(x_i)^2+(\\overline y-w\\overline x)x_i-x_iy_i\\&amp;=2\\sum_{i=1}^{n}[w(x_i)^2+\\overline y x_i - w \\overline x x_i -x_iy_i]=0\\&amp;\\Rightarrow w=\\frac{\\sum_{i=1}^{n}[x_iy_i-x_i\\overline y]}{\\sum_{i=1}^{n} [(x_i)^2-\\overline x x_i]}=\\frac{\\sum_{i=1}^{n}x_iy_i-\\frac{1}{n}\\sum_{i=1}^{n}x_i\\sum_{i=1}^{n} y_i}{\\sum_{i=1}^{n} (x_i)^2-\\frac{1}{n}\\sum_{i=1}^{n} x_i \\sum_{i=1}^{n}x_i}\\&amp;=\\frac{\\sum_{i=1}^{n}(x_i-\\overline x)(y_i-\\overline y)}{\\sum_{i=1}^{n}(x_i-\\overline x)^2}\\\\end{aligned} 注意: 2.1 最小二乘法 对该模型最原始计算方法为最小二乘法，给定训练数据如下 则有 2.1.1 最小二乘法的概率角度的视角 设误差服从正态分布，那么有~，则有~, 公式建模 极大似然估计： 3. 优化 优化一般有两种，一种是正规方程组，一种是梯度下降法。已知损失函数 正规方程组: 对损失函数求导，即有, 令该式子为0则得 梯度下降：选择批量大小为, 那么有 正规方程组需要保证没有特征之间没有相关性，另外也无法应用于大规模的线性回归，而梯度下降需要选择合适的学习率，适合大规模场景下的线性回归，同时，随机梯度下降无法保证得到的解一定是最优，但正规方程组可以保证解为最优。 4. 拓展 4.1 岭回归 由于正规方程组需要保证可逆，对于有个样本，有个属性的数据，如果，那么不可逆。岭回归通过增加L2正则化来保证可逆。具体来说损失函数如下 加入的正则化有两个效果，一个是保证可逆，另一个是抑制过拟合。 如果样本数据过少导致线性回归拟合较差，则考虑采用岭回归。如何输入特征的维度很高,而且是稀疏线性关系的话， 岭回归就不太合适,考虑使用Lasso回归。L2正则假设参数的先验分布是Gaussian分布，可以保证模型的稳定性，也就是参数的值不会太大或太小. L2范数是各参数的平方和再求平方根，我们让L2范数的正则项最小，可以使的每个元素都很小，都接近于0。但它不会是每个元素为0，而只是接近于0。越小的参数说明模型越简单，越简单的模型越不容易产生过拟合现象。L2不能控制feature的“个数”，但是能防止模型overfit到某个feature上 4.2 Lasso回归 Lasso 回归的本质是 线性回归 + L1 正则化。 L1正则化(Lasso回归)可以使得一些特征的系数变小,甚至还使一些绝对值较小的系数直接变为0，从而增强模型的泛化能力 。对于高的特征数据,尤其是线性关系是稀疏的，就采用L1正则化(Lasso回归),或者是要在一堆特征里面找出主要的特征，那么L1正则化(Lasso回归)更是首选了。L1正则假设参数的先验分布是Laplace分布，可以保证模型的稀疏性，也就是某些参数等于0, L1正则化是L0正则化的最优凸近似，比L0容易求解，并且也可以实现稀疏的效果, L1是控制feature“个数”的，并且鼓励模型在少量几个feature上有较大的权重。 4.3 局部加权线性回归 在线性回归中， 由于最终拟合出来的曲线是一条直线，其拟合能力极为有限（也可以解释为线性回归所求的是具有最小均方误差的无偏估计），因此很容易造成欠拟合现象， 而针对这个问题，有人提出了局部线性回归(LWR)。 在LWR中， 其损失函数为： 矩阵表示 此时，使用回归方程求得： 而通常， 服从高斯分布， 在目标区域附近指数型衰减; 其中， k 值越小，敏感半径越小。值决定了线性回归的拟合半径 4.3 ElasticNet回归 ElasticNet回归本质上是线性回归 + L1正则化 + L2 正则化，损失函数变为： Reference","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"linear regression","slug":"linear-regression","permalink":"http://yourthomaslee.github.io/tags/linear-regression/"}]},{"title":"Machine learning foundation 0 - concepts","slug":"Machine learning foundation 0 - concepts","date":"2023-02-08T02:40:05.000Z","updated":"2023-02-08T15:36:01.758Z","comments":true,"path":"2023/02/08/Machine learning foundation 0 - concepts/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/08/Machine%20learning%20foundation%200%20-%20concepts/","excerpt":"","text":"基础概念 任务：给定一定量的数据，利用模型归纳、总结、学习数据中的规律和知识，应用到新数据的观察、评估、预测中 学习：如果一个系统能够通过执行某个过程改进它的性能， 这就是学习（Herbert A. Simon） 统计学习：从给定的、有限的、用于学习的训练数据集合(training data)出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间(hypothesis space); 应用某个评价准则(evaluation criterion)，从假设空间中选取一个最优模型，使它对已知的训练数据及位置的测试数据在给定评价准则下有最优的预测；最优模型的选取由算法实现。 其重要性在于（1）可以处理海量数据；（2）被证明是计算机智能化的有效手段；（3）是计算机学科发展的重要组成部分； 统计学习分类：从任务上来说，一般包括监督学习、无监督学习、强化学习。有时还包括半监督学习、主动学习；[李航， 统计学习方法(2rd)] 标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。监 督学习的本质是学习输入到输出的映射的统计规律。 无监督学习是指从无标注数据中学习预测模型的机器 学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。无 监 督 学 习的 本 质 是 学 习 数 据 中 的 统 计规 律 或 潜 在 结 构 强化学习(reinforcement learning)是指智能系统在与环境的连续互动中学习 最优行为策略的机器学 习问题。假设智能 系统与环境的互动基于马尔可 夫决策过 程(Markov decision process)，智能系统能观测到的是与环境互动得到的数据序列。 强化学习的本质是学习最优的序贯决策。强化学习的目标就是在所有可能的策略中选出价值函数最大的策略，而在实际 学习中往往从具体的策略出发，不断优化己有策略。 半监督学习(semi-supervised learning) 是指利用标注数据和未标注数据学习预 测模型的机器学 习问题。通常有少量标注数据、大量未标注数据，因为标注数据的构 建 往 往 需 要 人 工， 成 本 较 高 ， 未 标 注 数 据 的 收 集 不 需 太 多 成 本 。 半 监 督 学 习 旨 在 利 用 未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习 效果。 主动学习(active learning)是指机器不断主动给出实例让教师进行标注，然后利 用标注数据学习预测模型的机器学习问题。通常的监督学习使用给定的标注数据，往 往是随机得到的，可以看作是“ 被动学习”，主动学习的目标是找出对学习最有帮助的 实例让教师标注，以较小的标注代价，达到较好的学习效果。 从模型的角度上说，可以分为 概率模型（决策树、朴素贝叶斯、隐马尔科夫模型、条件随机场、概率潜在语义分析、高斯混合模型等）和非概率模型（感知机、支持向量机、近邻、AdaBoost、均值聚类、潜在语义分析以及神经网络）； 线性模型（感知机、线性支持向量机、近邻、均值聚类、潜在语义分析）和非线性模型（核支持向量机、AdaBoost、神经网络）； 参数化模型（感知机、朴素贝叶斯、逻辑回归、均值聚类、高斯混合模型等等）和非参数化模型（决策树、支持向量机、AdaBoos、近邻、语义分析和狄利克雷分配） 按算法分类则可以分为在线学习(online learning)和批量学习(batch learning); 按技巧分类则有贝叶斯学习（其 主 要 想 法 是 ， 在 概 率模 型 的 学 习 和 推 理 中 ， 利 用 贝 叶斯定理，计算在给定数据条件 下模型的条件概率，即后验概率，并应用这个原理进 行模型的估计，以及对数据的预测。将模型、未观测要素及其参数用变量表示，使用 模型的先验分布是贝叶斯学习的特点）、核方法（使用核函数表示和学习非线性模型的一种机器学习方 法）。 统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下： 得到一个有限的训练数据集合； 确定包含所有可能的模型的假设空间，即学习模型的集合； 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）； 实现求解最优模型的算法，即学习的算法（优化算法）； 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）； 利用学习的最优模型对新数据进行预测或分析； [由于李航的泛化下界分析内容没有写成闭包，此处暂时不进行深入学习，后续再复习] 后续部分内容将分模型进行学习和串联。 鸡肋信息： 机器学习理论： Guarantees in Machine learning pen-and-paper exercises in machine learning： https://github.com/michaelgutmann/ml-pen-and-paper-exercises","categories":[],"tags":[{"name":"machine learning concepts","slug":"machine-learning-concepts","permalink":"http://yourthomaslee.github.io/tags/machine-learning-concepts/"}]},{"title":"Leetcode 1604. Alert Using Same Key-Card Three or More Times in a One Hour Period","slug":"Leetcode 1604","date":"2023-02-07T02:40:05.000Z","updated":"2023-02-07T15:10:40.190Z","comments":true,"path":"2023/02/07/Leetcode 1604/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/07/Leetcode%201604/","excerpt":"","text":"Problem description can be found at link My solution: 12345678910111213141516171819202122232425262728293031class Solution {public: struct op{ string name; int time; }; static bool comp(op&amp; a, op&amp; b){ if(a.name &lt; b.name){ return true; }else if(a.name == b.name){ return a.time &lt; b.time; }else return false; } vector&lt;string&gt; alertNames(vector&lt;string&gt;&amp; keyName, vector&lt;string&gt;&amp; keyTime) { vector&lt;op&gt; x; op t; for(int i = 0; i &lt; keyName.size(); ++i){ t.name = keyName[i]; t.time = stoi(keyTime[i].substr(0, 2)) * 60 + stoi(keyTime[i].substr(3, 2)); x.emplace_back(t); } sort(x.begin(), x.end(), comp); vector&lt;string&gt; ans; for(int i = 2; i &lt; x.size(); ++i){ if(ans.size() &gt; 0 &amp;&amp; x[i].name == ans[ans.size() - 1]) continue; if(x[i].name == x[i - 2].name &amp;&amp; abs(x[i].time - x[i - 2].time) &lt;= 60) ans.emplace_back(x[i].name); } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"}]},{"title":"Note - An attention free transformer","slug":"Note-An attention free transformer","date":"2023-01-17T02:40:05.000Z","updated":"2023-02-07T15:08:41.515Z","comments":true,"path":"2023/01/17/Note-An attention free transformer/","link":"","permalink":"http://yourthomaslee.github.io/2023/01/17/Note-An%20attention%20free%20transformer/","excerpt":"","text":"Paper address: https://arxiv.org/pdf/2105.14103.pdf Related codes: https://github.com/BlinkDL/RWKV-LM Have not updated yet Concepts: a model with parameter training on dataset using stochastic gradient descent(SGD) : a batch of size from dataset at step with is the predictive distribution of the current model, where is the sequence of data the model was trained on before training step $ D_{ho} ={ (x_{ho}, y_{ho}) } {i=1}^{n{ho} } x_{ho}y_{ho}p_{true}(x′, y′)D$. Intuition: Previous online batch selection methods aim to select points that minimize the training set loss. Instead, we aim to select points that minimize the loss on a holdout set. We aim to acquire the point that would minimize the negative log-likelihood/cross-entropy loss on the holdout set: $ arg \\min {(x,y)\\in B_t} - \\log p(y{ho}|x_{ho};D_t \\cup (x, y))$ [get similar distribution as holdout set] Inference: For a model using a point estimate of (such as an MLE or MAP), rather than a distribution over , the holdout loss factorises and (up to a constant factor) forms a Monte Carlo approximation of the expected loss under : , where denotes the cross-entropy loss: , $$ \\log p(y_{ho}|x_{ho};D_t \\cup (x, y)) = \\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x,x_{ho};D_t)}[Bayes; rule]\\ =\\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x;D_t)}[conditional; independence; rule]\\ \\propto L[y|x;D_t] - L[y|x;D_{ho},D_t]\\ \\sim L[y|x;D_t] - L[y|x;D_{ho}]\\ \\Rightarrow \\arg \\max {(x,y) \\in B_t} L[y|x;D_t] - L[y|x;D{ho}]\\quad[training; loss - ;irreducible; holdout; loss] $$ Algorithm: Exploring: why not design a new simpler loss based on rough set thoery? it seems RHOLOSS is still a little expensive in implementation and computation. Actually this work provides a good way to think about the training sample selection problem. There are still room for some more further researches in computation simplicity and cost aspects","categories":[],"tags":[{"name":"transfomer","slug":"transfomer","permalink":"http://yourthomaslee.github.io/tags/transfomer/"},{"name":"language model","slug":"language-model","permalink":"http://yourthomaslee.github.io/tags/language-model/"}]},{"title":"Curriculum vitae - Baizhen Li","slug":"Curriculum Vitae - Baizhen Li","date":"2022-12-26T13:54:13.432Z","updated":"2023-02-07T14:33:52.665Z","comments":true,"path":"2022/12/26/Curriculum Vitae - Baizhen Li/","link":"","permalink":"http://yourthomaslee.github.io/2022/12/26/Curriculum%20Vitae%20-%20Baizhen%20Li/","excerpt":"","text":"Contact information: Bricklees [at] alumni [dot] tongji [dot] edu [dot] cn || baizhen9406 [at] 163 [dot] com Education Tongji UNIVERSITY 06/2018 - 03/2021 M.E., Computer Technology. GPA: 87/100 Thesis: Research on dialogue state tracking algorithm based on cross-layer fusion Awards and honors: National Scholarship(2020), Second Prize of the 15th China Post-graduate Mathematical Contest in Modelling, Outstanding Dissertation Award YANTAI UNIVERSITY 06/2013 - 07/2017 B.E., Computer Science and Technology. GPA: 79/100 Thesis: Research on knowledge acquisition algorithms: a discernibility matrix approach Awards and honors: Outstanding Dissertation Award, Third Prize of LAN QIAO International Collegiate Programming Contest Experiences I. Research experiences From 08/2019 to 12/2020, I participated in “Research on the Refined Description and Interpretability of Targets under Surveillance Video”(National natural science foundation of China, No. 61976160). I was in charge of models that provide task-oriented description of a picture collected from surveillance video while working as a researcher under the direction of professor Zhihua Wei and associate professor Lijun Sun. From 06/2018 to 07/2019, I took part in \"Topic Analysis Technology based on Natural Language Processing” (application research cooperated with the key lab of information network security, China ministry of public security, No. C18608). I created topic analysis-based detection techniques for illicit websites detection while working as a researcher and developer under the direction of professor Zhihua Wei and associate professor Lijun Sun. From 03/2014 to 06/2017, I participated in “Knowledge Space Research based on Granular Computing Method” (national natural science foundation of China youth science fund project, No. 61403329). I created two more effective rough sets-based knowledge discovery algorithms as a research assistant under the direction of associate professor Nan Zhang. II. Work/Internship experiences BAIDU CHINA CO., LTD. 03/2021 – 05/2022 As an engineer, I was in charge of the real-time bidding system’s cost-per-thousand-impression calibration(CTIA) module. By tweaking the algorithm’s parameters and state estimates, I improved the proportional-integral-derivative (PID) control algorithm’s performance in CTIA. HAIYIZHI INFORMATION TECHNOLOGY CO., LTD. 06/2020 – 09/2020 I created a robot that serves as the customer support representative in the postal service’s online chat. After that, I used a non-autoregressive dialog state tracking model to reduce the inference latency for dialog state tracking. Publications [1] Baizhen Li, Yibin Zhan, Zhihua Wei, Shikun Huang, Lijun Sun: Improved non-autoregressive dialog state tracking model. CCRIS 2021: 199-203 [2] Baizhen Li, Zhihua Wei, Duoqian Miao, Nan Zhang, Wen Shen, Chang Gong, Hongyun Zhang, Lijun Sun: Improved general attribute reduction algorithms. Inf. Sci. 536: 298-316 (2020) [3] Baizhen Li, Wei Chen, Zhihua Wei, Hongyun Zhang, Nan Zhang, Lijun Sun: Quick Maximum Distribution Reduction in Inconsistent Decision Tables. IJCRS 2020: 169-182 [4] Nan Zhang, Baizhen Li, Zhongxi Zhang, Yanyan Guo: A Quick Algorithm for Binary Discernibility Matrix Simplification using Deterministic Finite Automata. Inf. 9(12): 314 (2018)","categories":[],"tags":[]},{"title":"Note - Prioritized training on points that are learnable worth learning and not yet learnt","slug":"Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt","date":"2022-07-22T02:40:05.000Z","updated":"2022-12-27T03:36:11.314Z","comments":true,"path":"2022/07/22/Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/22/Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt/","excerpt":"","text":"This paper introduce RHO_LOSS, which selects points that are learnable, worth learning, and not yet learnt. RHO-LOSS trains in far fewer steps than prior art, improves accuracy, and speeds up training on a wide range of datasets, hyperparameters, and architectures (MLPs, CNNs, and BERT) Code: https://github.com/OATML/RHO-Loss Concepts: a model with parameter training on dataset using stochastic gradient descent(SGD) : a batch of size from dataset at step with is the predictive distribution of the current model, where is the sequence of data the model was trained on before training step $ D_{ho} ={ (x_{ho}, y_{ho}) } {i=1}^{n{ho} } x_{ho}y_{ho}p_{true}(x′, y′)D$. Intuition: Previous online batch selection methods aim to select points that minimize the training set loss. Instead, we aim to select points that minimize the loss on a holdout set. We aim to acquire the point that would minimize the negative log-likelihood/cross-entropy loss on the holdout set: $ arg \\min {(x,y)\\in B_t} - \\log p(y{ho}|x_{ho};D_t \\cup (x, y))$ [get similar distribution as holdout set] Inference: For a model using a point estimate of (such as an MLE or MAP), rather than a distribution over , the holdout loss factorises and (up to a constant factor) forms a Monte Carlo approximation of the expected loss under : , where denotes the cross-entropy loss: , $$ \\log p(y_{ho}|x_{ho};D_t \\cup (x, y)) = \\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x,x_{ho};D_t)}[Bayes; rule]\\ =\\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x;D_t)}[conditional; independence; rule]\\ \\propto L[y|x;D_t] - L[y|x;D_{ho},D_t]\\ \\sim L[y|x;D_t] - L[y|x;D_{ho}]\\ \\Rightarrow \\arg \\max {(x,y) \\in B_t} L[y|x;D_t] - L[y|x;D{ho}]\\quad[training; loss - ;irreducible; holdout; loss] $$ Algorithm: Exploring: why not design a new simpler loss based on rough set thoery? it seems RHOLOSS is still a little expensive in implementation and computation. Actually this work provides a good way to think about the training sample selection problem. There are still room for some more further researches in computation simplicity and cost aspects","categories":[],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"http://yourthomaslee.github.io/tags/deep-learning/"},{"name":"training sample selection","slug":"training-sample-selection","permalink":"http://yourthomaslee.github.io/tags/training-sample-selection/"}]},{"title":"Note-Trainable learning rate","slug":"Note-Trainable-learning-rate","date":"2022-07-19T09:26:53.000Z","updated":"2022-12-27T03:38:45.291Z","comments":true,"path":"2022/07/19/Note-Trainable-learning-rate/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/19/Note-Trainable-learning-rate/","excerpt":"","text":"Problem: selecting an appropriate learning rate is a challenge considering different model structures and datasets. Work: we propose an algorithm for automatically adjusting the learning rate during the gradient descent (line search method) Given the weights’ gradients, one could estimate if an overestimation or an underestimation of learning rate could further reduce the task loss by casting the learning rate as an extra trainable parameter. Problem Statement: the gradient descent framework (GD). vanilla form: , where is learning rate, is loss function and is the model parameters at iteration . In vanilla GD, Is treated as a hyperparameter and does not contribute to the loss. We introduce an augmented loss term , where we consider as the learnable variable. . Something noticing is that minimizing is equivalent to finding the optimal step-size for current . Naive GD-TLR: A straightforward idea is to apply GD over : , where hyperparameter Controls the updates of the initial learning rate Disadvantages: the addition of requires an extra forward-backward pass in order to compute the introduction of a GD step for creates the extra hyperparameter Efficient GD-TLR: let Denotes a standard feed-forward network of Layers, where and denote the non-linear activation and linear transformation corresponding to layer respectively. For the convenience of writing, we just consider the linearity of a single layer , where is the input from the previous layer, is the matrix of parameters, is the output. (, ) denotes the variables after GD update. So we have First-order gradient and insight: Assuming that corresponds to a specific layer, the gradient of the augmented loss compute as: the learning rate gradient can be expressed as the inner product of consecutive gradients , as a result we can rewrite equation (2) as $ \\frac{\\partial L_\\alpha}{\\partial \\alpha}|{a=\\alpha_t} = -&lt;\\triangledown L(w_t), \\triangledown L(w{t - 1})&gt; = -&lt;g_t, g_{t-1}&gt; $. The derived gradient (take indicator ind for simplifing) has an intuitive interpretation: Ind &gt; 0: the learning rate should be increased Ind &lt; 0: the learning rate should be decreased Ind = 0: either we reached a converged state of gradient directions are perpendicular. Second-order gradient: a newton-based method requires Hessian computations/approximations of the network’s weights, and the problem at hand has an intuitive analytical form, using only first-order weight gradients, as following suggests: $$ \\frac{\\partial^2L}{\\partial \\alpha^2}|{\\alpha=\\alpha_t}=\\frac{4}{\\alpha}&lt;g_t, g_t-g{t-1}&gt;=\\frac{4}{\\alpha_t}(||g_t||^2-&lt;g_t,g_{t-1}&gt;) \\eta_t = \\frac{\\alpha_t}{\\max(4&lt;g_t, g_t-g_{t-1}), c^{-1}&lt;g_t, g_{t-1}&gt;)} $$ where we form an overall bound on the update of which imposes smoother behavior (c was set as 1/4 in paper) Efficient GD-TLR Input: number of iterations , initial weights , learning rate , hyperparameter Output: optimized weights step 1: initialize = 0 step 2: for to do step 3: single forward-backward pass: step 4: compute step 5: update alpha according to Equation 2 and 3 [ ] step 6: update w: ; step 7: ; step 8: end for Exploring problem： the analysis in appendices, may be we will explore it next time I read it. Interested in automatical layer-wise learning rate in the future research the performance and the disadvantage of the algorithm. I think there is still necessity of experiment","categories":[],"tags":[{"name":"trainable learning rate","slug":"trainable-learning-rate","permalink":"http://yourthomaslee.github.io/tags/trainable-learning-rate/"}]},{"title":"Notes-mitigating neural network overconfidence with logit normalization","slug":"Note-mitigating neural network overconfidence with logit-normalization","date":"2022-07-11T08:49:33.000Z","updated":"2022-12-27T03:34:16.757Z","comments":true,"path":"2022/07/11/Note-mitigating neural network overconfidence with logit-normalization/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/11/Note-mitigating%20neural%20network%20overconfidence%20with%20logit-normalization/","excerpt":"introduce Logit Normalization (LogitNorm), a simple fix to the cross-entropy loss (by enforcing a constant vector norm on the logits in training), to deal with overfitting or overconfidence for both in- and out-of-distribution inputs.","text":"introduce Logit Normalization (LogitNorm), a simple fix to the cross-entropy loss (by enforcing a constant vector norm on the logits in training), to deal with overfitting or overconfidence for both in- and out-of-distribution inputs. Problem: we find that even when most training examples are classified to their correct labels, the softmax cross-entropy loss can continue to increase the magnitude of the logit vectors. The growing magnitude during training thus leads to the overconfidence issue, despite having no improvement on the classification accuracy. Work: To mitigate the issue, our key idea behind LogitNorm is to decouple the influence of output’s norm from the training objective and its optimization. This can be achieved by normalizing the logit vector to have a constant norm dur- ing training. In effect, our LogitNorm loss encourages the direction of the logit output to be consistent with the corre- sponding one-hot label, without exacerbating the magnitude of the output. Trained with normalized outputs, the network tends to give conservative predictions and results in strong separability of softmax confidence scores between ID and OOD inputs Codes: https://github.com/hongxin001/logitnorm_ood Core equation: to make sure that the logit vector is a unit vector, it alleviate some challenges in optimization, or rather, let optimization does more things useful! where is logit vector, is the Euclidean norm of the logit vector, and denotes the quantity of different class labels. Comment: This work restricts the numerical bound of logit vector during optimization, and it results better model performance in classification task. Exploring problem： Can we get the better performance if we use label smoothing? what is the difference between LayerNorm and LogitNorm? Is there any other efficient way to implement LogitNorm? Is this work compatible to the paper “Long-Tail Learning via Logit Adjustment” (https://arxiv.org/pdf/2007.07314.pdf)?","categories":[],"tags":[{"name":"overfitting","slug":"overfitting","permalink":"http://yourthomaslee.github.io/tags/overfitting/"},{"name":"logit normalization","slug":"logit-normalization","permalink":"http://yourthomaslee.github.io/tags/logit-normalization/"}]},{"title":"Hello World","slug":"hello-world","date":"2022-03-20T15:33:35.180Z","updated":"2022-03-20T15:33:34.000Z","comments":true,"path":"2022/03/20/hello-world/","link":"","permalink":"http://yourthomaslee.github.io/2022/03/20/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new \"My New Post\" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"dynamic programming","slug":"dynamic-programming","permalink":"http://yourthomaslee.github.io/tags/dynamic-programming/"},{"name":"combination","slug":"combination","permalink":"http://yourthomaslee.github.io/tags/combination/"},{"name":"interesting problems","slug":"interesting-problems","permalink":"http://yourthomaslee.github.io/tags/interesting-problems/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"},{"name":"array","slug":"array","permalink":"http://yourthomaslee.github.io/tags/array/"},{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"linear regression","slug":"linear-regression","permalink":"http://yourthomaslee.github.io/tags/linear-regression/"},{"name":"machine learning concepts","slug":"machine-learning-concepts","permalink":"http://yourthomaslee.github.io/tags/machine-learning-concepts/"},{"name":"transfomer","slug":"transfomer","permalink":"http://yourthomaslee.github.io/tags/transfomer/"},{"name":"language model","slug":"language-model","permalink":"http://yourthomaslee.github.io/tags/language-model/"},{"name":"deep learning","slug":"deep-learning","permalink":"http://yourthomaslee.github.io/tags/deep-learning/"},{"name":"training sample selection","slug":"training-sample-selection","permalink":"http://yourthomaslee.github.io/tags/training-sample-selection/"},{"name":"trainable learning rate","slug":"trainable-learning-rate","permalink":"http://yourthomaslee.github.io/tags/trainable-learning-rate/"},{"name":"overfitting","slug":"overfitting","permalink":"http://yourthomaslee.github.io/tags/overfitting/"},{"name":"logit normalization","slug":"logit-normalization","permalink":"http://yourthomaslee.github.io/tags/logit-normalization/"}]}