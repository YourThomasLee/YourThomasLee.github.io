{"meta":{"title":"Thomas Lee(李柏珍,Baizhen Li)","subtitle":"抱残守缺","description":"个人博客试验田1号","author":"Thomas Lee (李柏珍,Baizhen Li)","url":"http://YourThomasLee.github.io","root":"/"},"pages":[],"posts":[{"title":"zbl - the goal of my life","slug":"Zbl-The goal of life","date":"2023-05-21T14:26:53.000Z","updated":"2023-06-26T15:32:52.460Z","comments":true,"path":"2023/05/21/Zbl-The goal of life/","link":"","permalink":"http://yourthomaslee.github.io/2023/05/21/Zbl-The%20goal%20of%20life/","excerpt":"","text":"前言 我已经毕业了两年多了，我开这个帖子主要用来记录一些内心的片段，无意于指点江山，但于我自己，着眼于积累并梳理一些矛盾的想法，使得内在更加协调 角色 我将自己定义为发展观点下的完美主义现实践行者。 完美主义本身是一种纯粹视角下对事物进行假定和并在此基础上定义最终极状态，从而在活动终点所在对当前的所有活动进行最重要、最根本的评估。这里简单的进行一个假设，当一个生命个体不受任何的束缚，那么这样的一个状态下个人能够得到的发展应该是怎样的，这个角色下最终会到达的地方应该是怎样的，他的死亡或者说活动的终止应该是以什么理由等等。我曾经做过很多这样的假设，在给定时间跨度下，完美主义就可以足够具体并具有执行价值（这里强调下，此处的完美主义并非是全方面的完美，也并非面向大众的完美，而是面向个体在给定时间跨度下的目标设定结果，之所以强调完美，是因为强调对审美或者目标本身的严苛和对目标不懈的追求）。这个特性使我从根本上与他人区别开来，多数人们为了活着而活着，而我为了生命终点（死亡）而活着。 由于完美主义存在很大程度的空想性质，同时在漫长的时间跨度下，很多的评估角度存在不切实际的副作用，在这种情况下，强调发展观点就变得异常重要，一方面这用来去弥补完美主义的缺点，另一方面是因为该观点贯穿活动的所有过程中，并在整体进程中起到的方向引导和动作评估，这里举个例子用来说明发展观点提供的作用：无法控制上课时候玩手机时间导致学习投入不足进而影响成绩。我所观察到的大多数人会选择把手机放远或者不带手机去教室，发展观点将会反对这种做法，首先发展的对象目标是个体，不带手机去教室是一种通过否定外界物质存在情况进而使得问题存在条件不成立对问题进行规避，发展观点将强调个体内在的自我反省和斗争，通过对自我的梳理进而增强个体自我的控制能力，进而实现手机在身边上课时间不进行娱乐活动的目标。发展观点的缺点在于见效缓慢，对于很多人来说，思考与自省是一种结果不确定的活动，一种可能无效并且速度慢的手段一定不会被许多人接受，因此该类观点注定小众。 现实践行者强调的是根据现实情况进行策略和动作的调整，前30年我一直在做的是完美主义和发展观点的建设，这个方面是我目前做的最不足的方面，因此在此不过多解说。这里想要说明的内容是，现实践行强调的是现实为重，在特殊情况下甚至可以短暂的否定目标以实现短期目标，存在的问题是完美主义和发展观点的地位问题，我的阶段性的答案是，现实践行针对的是短期具体的问题，对于完美主义和发展观点的损害不可以连续在三个问题上起作用。 生活 目标 在中国会有种很奇怪的情形，当你在街拉住一个人，然后很平静的问，你的人生目标是什么？你的生活目标是什么？大多数的情况他们会很诧异的看着你，然后犹豫下，眼睛望下天，然后回答道，其实我没有什么目标。接着为了保护下自己，让自己不显得那么弱势，又或许会补充道，我没有什么伟大或者宏大的目标，我就像开开心心的生活。这样的对话我问过我的朋友，问过我很喜欢的女孩子，问过我的老乡，回答的风格或许让我觉得他们纯然天真，或许又让我觉得俗气（说到最后可能就是我想多赚点钱）。 让我时常觉得痛苦的并不是他们的回答，而是他们的态度，他们的眼睛那诧异又不知所措的光，而后又随意或许无意的话语，需要人生目标吗？另一方面他们或许有那么些觉得似乎应该又有个目标好，但也不想费心，于是先把人生目标抬高，就像人把那些光辉的品性都给神，供奉起来，这样大家可以尽情的肮脏，不需要人生目标，不需要意义。 这些话语流露出的这样的默许和预设，令我觉得，哪怕和他们一起交流讨论下人生目标都是奢望，我于是陷入一个孤岛，最好闭上嘴巴，免得惹得更多人不快。 我觉得每个人都应该有自己的人生目标，如果人生只是一条固定长度的线段，一个聪明的人应该能意识道这是一个容器，不应该让这个容器都被文化填满，而应该涂上自己的颜色，否则你如何成为你呢，你只是社会的一个小细胞罢了，让自由之风劲吹，让我从芸芸众生无表情的路人甲乙逃出，单独去往即使意味着独行的幽径把，让我成为lbz吧，即使这个名字是我从路人甲乙中那里接来，我亦可以为它涂上独特的色彩，我如此呼唤着。 我认为人的人生目标应该来源于过去，所有过去经历的一切，构成我的痛苦和快乐，这些必然满是矛盾，指明着个人颜色和人生轨迹的诸多方向，个人最终极的目标应该是能够统一过去一切的痛苦和快乐，使得这些所有的情绪能够被另外一种东西凌驾于之下，快乐与痛苦协调一致为这种东西指路，而这种东西又同时不断消解过去到现在累计的快乐与痛苦，我将这种状态描述为和谐，正如自由描述人与人的发展不再局限于剥削和被剥削那样的情形。 我希望有人能够认同，人至少还是需要目标的，正如人的一天不可能什么情绪都没有，只要有情绪，就有了动力去平复不适去激励低压状态，再宏观些，过去的痛苦和快乐就需要去调理，从这些情绪中觉察出的道路就是人生目标的方向。我想我的不幸就是，我不该记得那么多。小王子里所说，真正的问题不在于长大，而在于遗忘，这或许是芸芸众生的苦恼，对于我而言，我却希望忘记得多一些，这样我可以在我喜欢的女孩子对我眨着亮晶晶的眼睛时没有那么多的顾虑，可以曾经抚养过我的爷爷奶奶一个他们喜欢的故事，也可以融入大多数到我的朋友的群体中。对于看到许多问题却不能解决这些问题的我，许多时候这样的想法反复出现。我的理想携我走出曾经的黑暗到达新的境地，又在我想要停留的时候将我从想要得到的事物中抽离。如此犹豫，我想我大概快老了，但在此之前，我还可以再将自己打碎再重新构建自我一次，让我去追随我的目标吧，既然看到了问题，就不能看着问题不断变糟。 为什么我要追求人生目标 将我与大部分人区别的因素，是我在信念层面曾经真正的死去，当人在信念上死去，就必须重新在信念上活过来，因而较他人更加渴盼着信念和精神的完满。 我出生在中国的南方农村贫穷地区，信息鼻塞文化观念陈旧，在那里小孩的人生被设定为长大出去务工挣些钱娶妻买房，在这条道路上好好读书就是为了去拿一份好工作，谈这些只是想说明，如果你真的在农村里遇到很痛苦的事情，绝不会又名为希望的光透过云层照到你的身上。当然，幼年的我其实也从来不会考虑这般的事情，所有的人们最初的模样和对世界的认识都被环境所定义，我并不属于例外。糟糕的是，我的运气不太好，在捉襟见肘的经济条件下，我的家庭还充斥着父亲和爷爷那一辈的矛盾，父母外出务工，我和哥哥在爷爷奶奶的照顾下长大。我上初中以前，算是个胖子，身体不算好，每次生病我都会想身体好了要多开心的玩，和多数人一样实际是身体好了便很快忘记，中国地大物博，在培养忍耐品性有独到的方面。我的幼年和其他人一样不谙世事，从不考虑自己对世界的认识有什么问题，只有当有问题才急忙忙装模做样的反思考虑要怎么办，但一个装睡的人要是频频被烦扰直到知晓装睡也毫无意义时候，便只能无奈的睁开眼睛。 关于死亡这个命题，最开始出现在我的人生中是小学，我被大哥欺负，各种打骂同时被抢占电视和被强迫分配农活，而爷爷奶奶留给我的记忆是你们的事情按理要你们的父母来负责或者你更懂事，你不要和你哥一般见识（在我看来有一定偏心的可能，毕竟那时候哥哥的学业要比我好许多，我直到现在仍然是个懒散性子，没有特别强烈的动机）。总结起来，我身上的压力大概有那么几方面：生活环境不安定，我的长辈存在冲突，不时会将我也牵扯进去；我的身体不好，生理上有若干的问题；家庭关系问题，兄弟之间无法和睦的相处，长辈也不能给予公正处理，追究起来牵扯代间矛盾和家庭责任纠纷；经济问题，匮乏的物质资源等等。这些问题在我的高中阶段集中爆发，半吊子的我初三努力一年考入县重点高中后，第一次真正的离开我的家乡，环境与文化的抽离就让我如同鱼儿离水一般，陷入短暂的窒息。我的朋友们分散到了各个遥远的班级，而此时，我的父母正在吵架吵得不可开交，就连我要交学费都要踢个三四回合的皮球到最后爷爷奶奶看不下去出来说话才作罢，同时我暗恋同班的一个同学，但如我这般的背景可想而知只是煎熬与伤痛，我虽然苦苦挣扎，但也没有得到任何的结果。当你的环境能够为你提供保护，做一只变色龙是每一个人成本最低收益最高的选择，但是当你的环境是一团火海，变色就变得毫无意义，攻击将从四面八方袭来，肉体的灼烧与精神的煎熬将会使人扭曲并一点点摧毁人的所有，我之所以没有提前终止自己的故事，一是因为我接触不到舒服的死亡途径，二则是在我看来，死掉就能解脱实在是一种伪命题，没有人能证明死掉后就舒服了，万一是一个新的地狱，那不如就在这里，开始宣判进行全面的战争。我为了对抗所有的困境，在变色龙角色的死亡的同时，对自我的情绪进行全面的释放，并有意鼓励培养一些情绪建立起信念的根基，为了对抗恶龙，只有先变成恶龙本身，我最后变成了恶龙，之后再利用建立根基的规则一点点抹去了恶龙的角色。这些都是不太相关的东西，不便多提。 当我从变色龙变成恶龙，再从恶龙变回我自己之后，我便拥有了与大多数人全然不同的视角，我思考许多事情开始变得叛逆，从根本上说，我所认为世界的原本，和周围环境的人所看到的原本开始格格不入，从某种意义上说，在精神世界我被非自愿的剥夺了一切亲情友情乃至爱情，世俗潮流的许多观念对我再构不成牵制，友情亲情爱情许多时候只是容器，它们的内容从不是潮流所宣传那般美好，它们之所以是当前看起来那般，不过是掺杂了太多机心有太多想要从众夺取利益的人站在背后。当我拥有了一定程度上独立于环境的框架后，我便能从漫长时间中感知到那个问题，你要如何度过你的一生，我无法接受顺随潮流看着在一个机构剥夺一个人的人生目标和其他的价值，远古时候我们本是为了更好的生活才聚在一起彼此互相帮助，到现在却因为机构本身的发展以及构成机构运转机制本身的人们的利益，将个人几乎所有的价值都异化为人是为了社会发展而存在。当我面对一个个说我什么也不想做，只是为了拿到更多的钱保障自己或许不确定的为来时候，我感到愤怒同时也感到无奈，这些人已经被窃取到一无所有了，但他们浑然不知，而这些浑然不知的人们，可怜又可恨的贱卖自己的人生，恶化着周围的环境阻碍着意识到这一切的我去寻找自己的未来。 我将顺从自己的内心，面对这些不公平不合理的现象与环境，在我的权利和能力范围内尽可能的说不，在现阶段我会尽可能的折中，但我绝不会一直这样服从，践行价值，才是人生的意义所在。 总结下，为什么我需要人生目标，因为我在无的程度要比我见到的那些被牵制的人高，对于我而言，目前来说没有我欣赏的朋友，没有我真正能依靠的亲人，也没有我认为能够相伴一生的恋人，既然如此，国家层面的所有牵制措施与社会的压制措施统统对我无效，当我没有一切的牵制，只剩纯然的是非曲直的价值判断后，。我不是圣人，钱确实很好，但到底只是行使支配社会资源的手段，我抵达这个社会的目的，可不是为了挣钱，是为了我自己的价值，这一点稀薄的价值，对于一个虚无空荡荡的容器而言，可要比那些钱重要许多。 我的人生目标 我的人生目标是什么，时至今日，我想我应该问自己一千遍以上这个问题，我不停的清醒然后堕落沉沦，然后再苏醒过来，如此反复，得到无数的答案然后再一一否定掉，最后我渐渐明确我自己的未来和方向。如果说人生的前进有方向，那么一定指向自我的圆满。我玩了大概2000场的王者荣耀的游戏，每一场对战我都会想，游戏就像人生，这场游戏我要赢。无论是基于经验或是从众，一场游戏赢了才会开心，才有意义。类比到人生就是我一定要成功，这样人生才会开心。令我迷惑或者迷惘的是，我许多时候打完游戏赢了，等级也越来越高，不断的去改变我的目标参加游戏，从一开始我只要赢，到我的段位要比别人高，到最后我想要呈现精彩的比赛水平打的尽可能的精彩，我始终不能真切平稳的感到开心，即使我达到设定的目标，赢了不一定开心，段位比别人高了也感觉虚无，呈现精彩的对局水平也不足以保证胜率和知足，我渐渐清晰，我参与游戏真正感到快乐永远是我自己展现了自己较好的水平，并通过自己的表现赢得对局，游戏的开心永远是自己能够左右对局或者在走向影响对局的路上。回到人生，我觉得人生的目标在不同的阶段会有不同的体现，而这些目标永远都是在追求更多的支配权和自由，对于我，我想我一直追寻的是自我的支配或者和谐。具体概括点说，我一直追求统一过去现在和自我目标的真理，藉由理解这个真理，达成自我的和谐和完满。我绝不仅仅是追求世俗意义上的成功，同时追求着达成成功的途径和方式，只有践行我所理解的道达到我所想要达到的地方，我的人生才会真正的感到快乐，这就是我的目标。 关于爱情 我相信、渴盼同时也恐惧爱情。我读过许多武侠、都市、魔幻还有一些经典文学作品，几乎所有作品都描述过其绝美的一面，但这些都有一个重要的前提，构成爱情的两个个体具有纯然美好的性情。 我理想的配偶： 理解价值和我的目标：时至今日，我遇到了若干我动心的女性，她们或有姣好的容颜或有温婉的性情，但我最后还是决定抛却或者放弃许多，继续前进。这样的选择，最根本的原因便是我觉得绝大多数人无法感知自己的角色或个性，无法感知也就无法定义角色，所有的性格品质统统来源于环境和经历，困扰我的一个问题是：如果两个人相遇，然后一方对另一方疯狂献殷勤表示好意，而后两人决定在一起好好生活，我们的精神将置放于何处，爱情的精髓又在哪里呢？我的同龄人们崇尚着简单就是好的原则你爱我我爱你的故事难以为我所接受，如果爱情不是因为我们各自的形状而在一起，只是因为遇到了彼此好像觉得不错这种理由，这将毁掉现阶段我的精神框架。但我觉得我并没有从深层次去理解爱情，时至今日仍然不能十分肯定的回答这些问题。我听过太多因为玩得开心在一起然后在一起后心底又抱着戒备推进着双方的关系的故事，甚至于那些已经结婚许久的上一辈和同龄人向我透露在婚姻中责任分担的顾虑（绝不可把责任最后放在我身上），有些人开心有些人难过，结果全靠上帝掷骰子，我觉得恐惧，如果身边几乎所有人都是抱着这样不认真的态度去对待自己和另一方，以一种懵懂的心态进入另一个生活阶段，这于现阶段的我而言，是不可接受的。首先我理解爱情的意义或者目标一定是为了让对方变得更加完整，在一起共享比一个人更加美好的生活，我会试探我的同龄人们，几乎所有人都会说，哎呀那确实很好，但是blabla，如上文所提人生目标一样，我的朋友们总有各种理由，你知道那些东西太遥远了，我只求今日开心如此这般，每当我听到这些言语，我都开始闭嘴，因为我知道，要让别人认同一个看起来好的目标都是件十分费事的事情，绝大多数人已经丧失了对长时期价值的感知与把握，丧失了对自我个性的感知，也难以界定好与不好，为了活着而活着，大家都只是在一个又一个的国家和社会给的选择题中来定义自我。我最后在十分的孤单中明了佛家中所言慧与定的关系，《大学》中言及在明明德的道路，恐怕对于绝大多数人而言，首先要提升慧这个东西。回到我的理想配偶的定义，我希望她至少追求一个好的目标，这样我们至少能畅谈价值和理想，我相信只要有共同的目标认识，爱情的一切美好与生活的和谐都能从这个地方衍生出来。我或许最后也不能够达成我这样的追求，但我现在还不够老，就让我再空想一段时间吧","categories":[],"tags":[{"name":"life","slug":"life","permalink":"http://yourthomaslee.github.io/tags/life/"},{"name":"value","slug":"value","permalink":"http://yourthomaslee.github.io/tags/value/"}]},{"title":"Note - A survey on bayesian deep learning","slug":"Note -  A survey on bayesian deep learning","date":"2023-05-13T02:40:05.000Z","updated":"2023-06-10T09:34:42.807Z","comments":true,"path":"2023/05/13/Note -  A survey on bayesian deep learning/","link":"","permalink":"http://yourthomaslee.github.io/2023/05/13/Note%20-%20%20A%20survey%20on%20bayesian%20deep%20learning/","excerpt":"","text":"1. 背景 A comprehensive artificial intelligence system needs to not only perceive the environment with different ‘senses, but also infer the world’s conditional (or even causal) relations and corresponding uncertainty. In this general framework, the perception of text or images using deep learning can boost the performance of higher-level inference and in turn, the feedback from the inference process by probabilistic graphical models with their Bayesian nature is able to enhance the perception of text or images 深度学习在感知能力上为复杂的任务提供了一个良好的工具, 能够在许多复杂任务上提供性能上的提升, 但在高层次的推理和灵活性上, 基于贝叶斯的概率图模型仍然非常出色. 将二者结合起来的称为贝叶斯深度学习, 贝叶斯深度学习具有如下优势[1]: 良好的准确率 to achieve high accuracy in recommender systems 能够处理以图片等的非线性控制系统 dealing with the control of non-linear dynamical systems with raw images as input 提供了一个统合概率图模型和深度学习的框架 provides a principled way of unifying deep learning and PGM, another benefit comes from the implicit regularization built in BDL. 提供了参数的不确定性视角，包括感知的不确定性，任务相关推理的不确定性和感知与任务信息传递的不确定性 provides a principled bayesian approach of handling parameter uncertainty: 1) uncertainty on the neural network parameters; 2) uncertainty of the task-specific parameters; 3) uncertainty of exchanging information between the perception component and the task-specific component.[1] 贝叶斯深度学习的缺点是: 算法复杂度高 it is non-trivial to design an efficient bayesian formulation of neural networks with reasonable time complexity 必须仔细设计信息交换模块 to ensure efficient and effective information exchange between the perception component and the task-specific component[1] 依赖于高维数据和有效的不确定性模型 information exchange between the perception task and the inference task, conditional dependencies on high-dimensional data, and effective modeling of uncertainty 参考的github库: https://github.com/js05212/BayesianDeepLearning-Survey 说明: 这篇论文提供了一个贝叶斯深度学习框架, 但是在hinge part上并没有一个比较清晰的归纳, 都是借助例子来说明. 在表示学习和任务相关的部分, 归纳了一下经典的技术, 可以一看. 2. 贝叶斯深度学习基础 深度学习通产认为是多于两层的神经网络. 在此文中, 可以先了解一些简单的多层感知机(Multilayer perceptrons, MLP)来去建立直接的印象. 2.1 多层感知机 实际上, 多层感知机是一系列的非线性变换. 假设我们需要训练多层感知机去实现一个M维向量映射到D维向量的回归任务. 假设原始的输入(0层感知机 [ 0-th layer of perceptron ] 的输入), 用表示输入矩阵的行. 想要拟合的向量为, 用表示矩阵的行. 训练层的感知机的学习任务可以表示为以下优化问题 此处是一个位级别映射函数, 表示一个Frobenius norm(一个范数). 训练一般基于链式求导得到梯度使用随机梯度下降算法实现. 2.2 自动编码器(Auto-encoders, AE) 自动编码器是通过全连接网络对输入进行编码并将其重构表示为更为紧凑/低维的输出(An autoencoder (AE) is a feedforward neural network to encode the input into a more compact representation and reconstruct the input with the learned representation. ) 在最简单的形式中, 一个自动编码器就是一个多层感知机加一个瓶颈（bottleneck）层. 在这里我们介绍以这个多层降噪自动编码器(denosing AE), 也称作堆叠降噪自动编码器(stacked denoising autoencoders, SDAE). SDAE是一个在给定含有噪声的输入前提下预测无噪声的输入神经网络, 其结构可见下面的图片 SDAE主要做以下优化: $$ \\min_{W_l, b_l} ||X_c-X_L||F^2 + \\lambda \\sum_l ||W_l||^2_F\\ subject ;to; X_l=\\sigma(X{l-1}W_l+b_l),; l=1,\\cdots,L-1\\ X_L=X_{L-1}W_L+b_L $$ 这里分别是不含噪声和含噪声的输入. 中间层将用来作为原始数据的表示输入到网络中. 自动编码器的目标就是寻找复杂输入背后的简洁表示。 2.3 卷积神经网络(Convolutional neural networks, CNN) CNN可以被认为是MLP的一种变体. 与AE不同的是, 这个网络一开始就是设计用来做降维. 卷积神经网络包含两个关键的概念: 卷积和池化. 特征图是线性变换和激活函数的输入, 它可以是原始图像或者上一层网络的输出. 对于给定输入, 权重和偏置, 层网络的特征图可以按以下方式获得 最大池化(Max-pooling): 对一个小区域进行下采样, 生成更小规格的特征图. 2.4 循环神经网络(Recurrent neural network) 循环神经网络（vanilla recurrent neural network）: 给定前一时刻的状态和当前时刻的输入，那么 其中，为当前状态的估计，为当前时刻的输出，为权重向量，为对应的偏置。 门机制循环神经网络（gated recurrent neural network）：RNN可能出现的问题是梯度爆炸和消失问题，考虑到这个情况，门机制循环神经网络被提出，其中比较经典的工作是LSTM（long short-term memory model） 其中， 表示两个向量间的位乘法 3 概率图模型(probabilistic graphical models, PGM) 概率图模型使用图来表示随机变量和他们之间的关系, 概率图模型主要有两种, 一种是有向概率图(贝叶斯网络, bayesian networks), 另外一种是无向概率图(马尔科夫随机场, markcov random fields). 一个典型的概率图模型是潜狄利克雷分布(latent dirichlet allocation, LDA), 这个通常会用来分析字, 话题和文档的生成. 通常一个概率图模型会伴随着一个对应的随机变量生成过程. 对于LDA, 其过程如下 严格来说，寻找参数的值的过程被称为学习(learning)，寻找隐变量的过程被称为推导(inference) 对于概率图模型, 其学习和推断也有相应的算法和工具. 其中最有效的也许是最大后验估计(maximum a posteriori probability), MAP能够提供一个有效的点估计, 但他不能将贝叶斯理论中的不确定性考虑并发挥作用, 在这方面, 可以考虑使用变分推断(variational inference)和马尔科夫链门特卡罗(Markov chain monte carlo, MCMC) 4 贝叶斯深度学习 贝叶斯深度学习的基本框架 通常由两个部分组成，感知组件和任务处理组件。通常来说感知组件会被建模成概率公式，设计成链状的变量概率图并使用网络实现。而对于任务处理组件则通常依赖于具体的任务，例如，它可以使一个传统的贝叶斯网络，或者是一个随机过程。 有三类变量：感知变量(perception variables, )，信息交换变量(hinge variables, )，任务变量(task variables, ) 有监督学习 无监督学习 ; 对于一般有三种设定，方差为0，方差为一个超参数，方差为一个分布，其灵活性和复杂度依次递增，目前得到最好效果的是超参数设定（说明学习算法有待改进） 学习算法：实际的学习算法必须符合 1. 可以在线学习； 2. 线性复杂度。第一条否定了传统的变分推断算法和MCMC算法，通常需要使用它们的在线版本呢。除了MAP推断，大多数随机梯度算法由于不符合bayesian的设定不能够使用 4.1 感知组件 最完美的情况一般是感知模块被设计陈一个概率或者贝叶斯网络，为了兼容后续的任务导向组件。此处主要介绍部分典型的感知组件 受限波兹曼机（Restricted Boltzman Machine, RBM）是一类特殊的不使用反向传播的贝叶斯网络，变量被设定成为二元的。定义能量为, 其中代表可观测的神经元，被定义为隐藏的神经元。 是可训练的参数。基于能量函数，可以定义以下条件分布 RBM使用“Contrastive Divergence”进行训练。 Probabilistic Generalized SDAE Variational Autoencoders Natural-Parameter Networks 4.4 任务导向组件 一般的 Bayesian Networks Bidirectional Inference Networks Stochastic Process 5. 具体的贝叶斯深度学习模型和应用 5.1 推荐系统中的有监督贝叶斯深度学习 5.2 话题模型中无监督贝叶斯深度学习 5.3 控制论中的贝叶斯深度表示学习 5.4 其他应用 the predictive distribution: . Deep learning normally refers to neural networks with more than two layers. deep learning (深度学习) 中常见的一些组件: autoencoders(自动编码器): convolution neural networks(卷积神经网络): recurrent neural networks(循环神经网络): transformer: probabilistic graphical model(概率图模型, PGM)常见的一些组件: directed PGM: bayesian networks, LDA undirected PGM: Markov random fields the process of finding the parameters is called learning and the process finding the latent variables given the parameters is called inference[1], 如果包含隐藏节点, 那就是推断, 如果没有, 那就是学习. maximum posterior (MAP): probabilistic matrix factorization (PMF) variational inference markov chain monte carlo 贝叶斯深度学习的基本框架: structure: consists of two parts - the task-specific component and the perception component. elements: three sets of variables, perception variables, hinge variables, and task variables. I.I.D. Requirement: the connections between hinge variables and the perception component should be i.i.d. for convenience of parallel computation in the perception component. uncertainty of exchanging information between the perception component and the task-specific component, which can be represented by the conditional density [1] 对应的范例有: stacked denoising autoencoders(SDAE) bayesian SDAE(recommender system) marginalized SDAE(recommender system) relational stacked denoising autoencoder model(RSDAE) deep poisson fator analysis with sigmoid belief networks bayesian deep learning for control. [1] 提供大规模性质的核心技术有: stochastic optimization variance reduction doubly stochastic variational inference scalable MCMC algorithms 对于复杂任务, 有三类不确定性是需要考虑的: Uncertainty on the neural network parameters. Uncertainty on the task-specific parameters Uncertainty of exchanging information between the perception component and the task-specific component. Reference: [1] Wang H, Yeung D Y. Towards Bayesian deep learning: A framework and some existing methods[J]. IEEE Transactions on Knowledge and Data Engineering, 2016, 28(12): 3395-3408. [2] Wilson A G , Izmailov P . Bayesian Deep Learning and a Probabilistic Perspective of Generalization[J]. 2020. [3] Wang H, Yeung D Y. A survey on Bayesian deep learning[J]. ACM Computing Surveys (CSUR), 2020, 53(5): 1-37.","categories":[],"tags":[{"name":"bayesian deep learning","slug":"bayesian-deep-learning","permalink":"http://yourthomaslee.github.io/tags/bayesian-deep-learning/"}]},{"title":"Note-Beyond the granularity-Multi-perspective dialogue collaborative selection for dialogue state tracking","slug":"Note-Beyond the granularity_Multi-Perspective dialogue collaborative selection for dialogue state tracking","date":"2023-04-19T14:26:53.000Z","updated":"2023-06-10T09:34:42.775Z","comments":true,"path":"2023/04/19/Note-Beyond the granularity_Multi-Perspective dialogue collaborative selection for dialogue state tracking/","link":"","permalink":"http://yourthomaslee.github.io/2023/04/19/Note-Beyond%20the%20granularity_Multi-Perspective%20dialogue%20collaborative%20selection%20for%20dialogue%20state%20tracking/","excerpt":"","text":"Problem: existing models use whole dialogue history for updating all dialogue state. The authors believe updating different slots in different turns requires different dialogue history, and using consistent dialogue contents leads to insufficiency or redundant information for different slots, which degrades the performance of dialogue state tracking models. Work: The authors devise DiCoS-DST to dynamically select the relevant dialogue contents to each slot for state tracking. The model evaluates the turn-level utterance of dialogue history from three perspective explicit connection to the slot name relevance to the current turn dialogue implicit mention oriented reasoning based on three types evaluation the model decides to select dialogue contents which are fed to state generator. Detail Information: In DST, the definition of granularity ( turns utterance before) is the number of dialogue turns spanning from a certain dialogue state in the dialogue to the current dialogue state. For previous research, models set the granularity of all slots as a fixed number, i.e., , where denotes the number of all slots, represents the turns of dialogue and is a constant or hyper-parameter. This paper proposes a model . there are three parts for modeling different perspectives consideration. (slot name,dialogue history,): devise an SN-DH module to touch on the relation of the dialogue history and the slot name, which directly reflects the relevance. (current turn, dialogue history): propose a CT-DH module to explore the dependency between each turn in the dialogue history and current turn dialogue (current_turn, co-references): propose an Implicit Mention Oriented Reasoning module to tackle the implicit mention(co-references) problems that commonly exists in complex dialogues. the model can be represented as the process follows flow process: 123456789graph LREncoder--&gt;State_Update_PredictorState_Update_Predictor--&gt;SN-DHState_Update_Predictor--&gt;CT-DHState_Update_Predictor--&gt;Implicit_Mention_oriented_ReasoningSN-DH--&gt;set_of_selected_dialogue_turnsCT-DH--&gt;set_of_selected_dialogue_turnsImplicit_Mention_oriented_Reasoning--&gt;set_of_selected_dialogue_turnsset_of_selected_dialogue_turns--&gt;State_Generator Information encoding process: the authors employ the representation of the previous turn dialogue state concatenated to the representation of each turn dialogue utterances as input: $$ E_t = [CLS]t \\oplus B{T-1}\\oplus [SEP]\\oplus D_t(1\\leq t \\leq T) $$ where $[CLS]tB{T-1} = B_{T-1}^1\\oplus \\cdots \\oplus B_{T-1}^JB_{T-1}^j = [SLOT]{T-1}^j\\oplus S_j\\oplus [VALUE]{T-1}^j \\oplus V_{T-1}^j[SLOT]{T-1}^j[VALUE]{T-1}^jT-1tD_t = R_t\\oplus;\\oplus U_t [SEP]R_tU_tR_tU_t[SEP]$ is a special token used to mark the end of a dialogue turn. SN-DH: To Be Continue","categories":[],"tags":[{"name":"Natural language processing","slug":"Natural-language-processing","permalink":"http://yourthomaslee.github.io/tags/Natural-language-processing/"},{"name":"dialogue state tracking","slug":"dialogue-state-tracking","permalink":"http://yourthomaslee.github.io/tags/dialogue-state-tracking/"},{"name":"dialogue history","slug":"dialogue-history","permalink":"http://yourthomaslee.github.io/tags/dialogue-history/"}]},{"title":"Deep learning foundation 1 - framework","slug":"Deep learning 1 - activation function","date":"2023-04-12T02:40:05.000Z","updated":"2023-06-10T09:34:42.951Z","comments":true,"path":"2023/04/12/Deep learning 1 - activation function/","link":"","permalink":"http://yourthomaslee.github.io/2023/04/12/Deep%20learning%201%20-%20activation%20function/","excerpt":"","text":"Activation function 激活函数的根本目的是增加非线性，能够通过梯度下降有选择的观察某一个区域的特征。主要的问题： 非线性：非线性主要解决的还是线性表示能力有限的问题，扩大模型的建模能力，但随机的非线性大概率对于提升模型的表现是不具备建设性的，因此这是一个不准确的说法，准确的说应该是梯度下降选择出来的非线性变换。这引申出的问题两个 不同激活函数的非线性的特点是什么，对神经网络的影响是什么 为什么梯度+非线性能达到好的效果，是否存在更好的方案呢？我想这个问题是开放性的，一定可以探究下 优化算法匹配度：和梯度下降算法有良好的匹配度意味着在不同的架构上收敛速度（梯度传播速度， 梯度计算速度两方面）上较快，这里面就是从梯度下降算法框架中构件的角度来考虑激活函数 1. Sigmoid 公式​ 优点：良好的生物解释，从完全不激活(0)到完全饱和的激活(1)，可以直接映射为概率 缺点： 梯度消失(初始化小于1): （1）损失函数有梯度传递，但是由于sigmoid函数导数最大为1/4，层以后梯度至少变为原来的，对多层的神经网络训练无法提供支持;（2）当神经元的值在接近0或1出时会饱和，梯度几乎为0，为了防止饱和，必须对初始化权重留意，不宜过大，否则容易梯度消失网络就不学习了. 梯度爆炸（初始化&gt;1)， sigmoid导数最大为1/4，所以时候才可能出现梯度爆炸 非0均值：因为输出都为正，对下一层求导的局部梯度也是正，因为，会造成捆绑效应和梯度方向一致，梯度方向一致之后，使得优化变得困难和低效 2. Tanh 公式, 将数值区域从[0,1]扩张大[-1,+1]区间，输出零中心，增快收敛。但仍然有幂函数，计算成本高 3. Relu 公式. 在正区间解决了梯度消失的问题，快收敛，计算成本低。缺点是对学习率很敏感，太大会出现很多死神经元。 4. Leaky Relu &amp; SELU &amp; ELU Leaky Relu: . 分段逼近，快速收敛，但效果不稳定。属于解决死亡神经元的尝试工作之一 ELU: SELU: ELU结合了ReLU和sigmoid，具备两者的优点：(1) 在输入正半轴为线性，无饱和性，使其可以缓解梯度消失问题；(2) 在输入负半轴具有软饱和性，其下边界为 −α ，软饱和性一方面可以解决ReLU中神经元永久性dead问题，另一方面可以使ELU对输入噪声具有更强的鲁棒性；(3) 输出的均值接近0，可以缓解均值不为0带来的输出分布变化问题，加快模型收敛。 ELU在输入负半轴采用指数的形式，这导致ELU相比ReLU存在计算复杂度较高的缺点。 SELU和ELU具有同样的特点。理论上ELU优于ReLU，但在推荐实际应用场景没有得到充分证明，可能和推荐领域网络深度不深有关系，在视觉领域网络层数深，相比ReLU、Leaky ReLU，ELU可以在网络收敛性上有优势。 5. Maxout 公式, 具备relu所有的优点，没有死神经元。缺点是参数量增加了一倍。 6. Softplus 7. softmax softmax激活函数是sigmoid激活函数的扩展， 通常用于多分类网络最后的输出层。softmax通过指数归一化方式，可以强化各项之间的区分度。 6. GELU 以往的激活函数为神经网络进入了非线性（binary threshold, sigmoid, ReLU, ELU, 及特点和优劣），另外神经网络中需要在网络层中加入一些noise,或通过加入dropout等方式进行随机正则化。以往的非线性和随机正则化这两部分基本都是互不相关的，因为辅助非线性变换的那些随机正则化器是与输入无关的。 GELU将非线性与随机正则化结合，将非线性与依赖输入数据分布的随机正则化器相结合在一个激活函数的表达中。与以往dropout指定随机概率值或ReLU根据输入值的正负进行mask的方式不同，GELU根据当前input大于其余inputs的概率进行随机正则化，即为在mask时依赖输入的数据分布。 Trick：对公式中的正态分布的累积分布函数进行了tanh三阶多项式近似，取得了相较于swish用sigmoid近似更好的效果。 其中 trick和建议：1. 数据符合高斯分布的累积分布函数的近似表示是非常重要的； 2. 建议优化器与momentum一起使用","categories":[],"tags":[{"name":"deep learning concepts","slug":"deep-learning-concepts","permalink":"http://yourthomaslee.github.io/tags/deep-learning-concepts/"},{"name":"activation function","slug":"activation-function","permalink":"http://yourthomaslee.github.io/tags/activation-function/"}]},{"title":"Leetcode 1590. Make Sum Divisible by P","slug":"Leetcode 1590","date":"2023-03-11T02:40:05.000Z","updated":"2023-03-11T03:24:18.494Z","comments":true,"path":"2023/03/11/Leetcode 1590/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/11/Leetcode%201590/","excerpt":"","text":"The problem description can be found at the link solution: 12345678910111213141516171819202122class Solution {public: int minSubarray(vector&lt;int&gt;&amp; nums, int p) { int x = 0; for (auto num : nums) { x = (x + num) % p; } if (x == 0) { return 0; } unordered_map&lt;int, int&gt; index; int y = 0, res = nums.size(); for (int i = 0; i &lt; nums.size(); i++) { index[y] = i; // f[i] mod p = y，因此哈希表记录 y 对应的下标为 i y = (y + nums[i]) % p; if (index.count((y - x + p) % p) &gt; 0) { res = min(res, i - index[(y - x + p) % p] + 1); } } return res == nums.size() ? -1 : res; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"number theory","slug":"number-theory","permalink":"http://yourthomaslee.github.io/tags/number-theory/"}]},{"title":"Leetcode 2379. Minimum Recolors to Get K Consecutive Black Blocks","slug":"Leetcode 2379","date":"2023-03-11T02:40:05.000Z","updated":"2023-03-11T02:44:09.773Z","comments":true,"path":"2023/03/11/Leetcode 2379/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/11/Leetcode%202379/","excerpt":"","text":"The problem description can be found at the link My solution: 123456789101112131415161718class Solution {public: int minimumRecolors(string blocks, int k) { int l = 0, r = k - 1, state = 0; for(int i = l; i &lt; k; ++i) if(blocks.at(i) == 'W') state ++; int ans = state; for(int i = k; i &lt; blocks.size(); ++i){ if(blocks.at(i) == blocks.at(i - k)) continue; else{ if(blocks.at(i) == 'W') state++; else state--; } ans = min(state, ans); } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"easy level","slug":"easy-level","permalink":"http://yourthomaslee.github.io/tags/easy-level/"},{"name":"sliding windows","slug":"sliding-windows","permalink":"http://yourthomaslee.github.io/tags/sliding-windows/"}]},{"title":"Leetcode exercise for offer 47. 礼物的最大价值 LCOF","slug":"Leetcode exercise for offer 47","date":"2023-03-08T02:40:05.000Z","updated":"2023-03-08T07:00:06.756Z","comments":true,"path":"2023/03/08/Leetcode exercise for offer 47/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/08/Leetcode%20exercise%20for%20offer%2047/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314151617181920212223class Solution {public: int maxValue(vector&lt;vector&lt;int&gt;&gt;&amp; grid) { for(int i = 0; i &lt; grid.size(); ++i){ for(int j = 0; j &lt; grid[i].size(); ++j){ if(i == 0) { if(j == 0) continue; else{ grid[i][j] += grid[i][j - 1]; continue; } } if(j == 0) grid[i][j] += grid[i - 1][j]; else{ grid[i][j] += max(grid[i - 1][j], grid[i][j - 1]); } //cout&lt;&lt;grid[i][j]&lt;&lt;\" \"; } //cout&lt;&lt;endl; } return grid[grid.size() - 1][grid[grid.size() - 1].size() - 1]; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"dynamic programming","slug":"dynamic-programming","permalink":"http://yourthomaslee.github.io/tags/dynamic-programming/"}]},{"title":"Leetcode 1096. Brace Expansion II","slug":"Leetcode 1096","date":"2023-03-07T02:40:05.000Z","updated":"2023-03-07T02:48:27.553Z","comments":true,"path":"2023/03/07/Leetcode 1096/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/07/Leetcode%201096/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Solution {public: vector&lt;string&gt; braceExpansionII(string expression) { vector&lt;char&gt; op; vector&lt;set&lt;string&gt;&gt; stk; // 弹出栈顶运算符，并进行计算 auto ope = [&amp;]() { int l = stk.size() - 2, r = stk.size() - 1; if (op.back() == '+') { stk[l].merge(stk[r]); } else { set&lt;string&gt; tmp; for (auto &amp;left : stk[l]) { for (auto &amp;right : stk[r]) { tmp.insert(left + right); } } stk[l] = move(tmp); } op.pop_back(); stk.pop_back(); }; for (int i = 0; i &lt; expression.size(); i++) { if (expression[i] == ',') { // 不断地弹出栈顶运算符，直到栈为空或者栈顶不为乘号 while (op.size() &amp;&amp; op.back() == '*') { ope(); } op.push_back('+'); } else if (expression[i] == '{') { // 首先判断是否需要添加乘号，再将 { 添加到运算符栈中 if (i &gt; 0 &amp;&amp; (expression[i - 1] == '}' || isalpha(expression[i - 1]))) { op.push_back('*'); } op.push_back('{'); } else if (expression[i] == '}') { // 不断地弹出栈顶运算符，直到栈顶为 { while (op.size() &amp;&amp; op.back() != '{') { ope(); } op.pop_back(); } else { // 首先判断是否需要添加乘号，再将新构造的集合添加到集合栈中 if (i &gt; 0 &amp;&amp; (expression[i - 1] == '}' || isalpha(expression[i - 1]))) { op.push_back('*'); } stk.push_back({string(1, expression[i])}); } } while (op.size()) { ope(); } return {stk.back().begin(), stk.back().end()}; }}; the explanation of solution can be found at link","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"stack","slug":"stack","permalink":"http://yourthomaslee.github.io/tags/stack/"},{"name":"hard level","slug":"hard-level","permalink":"http://yourthomaslee.github.io/tags/hard-level/"}]},{"title":"Leetcode 1653. Minimum Deletions to Make String Balanced","slug":"Leetcode 1653","date":"2023-03-06T02:40:05.000Z","updated":"2023-03-06T11:19:04.919Z","comments":true,"path":"2023/03/06/Leetcode 1653/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/06/Leetcode%201653/","excerpt":"","text":"Problem description can be found at link My solution: 1234567891011121314151617class Solution {public: int minimumDeletions(string s) { // b a vector&lt;int&gt; a(s.size(), 0); for(int i = s.size() - 1; i &gt;= 0; i--){ if(s.at(i) == 'a') a[i] = 1; if(i &lt; s.size() - 1) a[i] += a[i + 1]; } int cnt_b = 0, ans = s.size(); for(int i = 0; i &lt; s.size(); ++i){ if(s[i] == 'b') cnt_b ++; ans = min(cnt_b + a[i] - 1, ans); } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"}]},{"title":"Machine learning foundation 2 - Part 1. feature engineering","slug":"Machine learning foundation 2.1 - feature engineering","date":"2023-03-04T03:40:05.000Z","updated":"2023-03-06T14:57:10.306Z","comments":true,"path":"2023/03/04/Machine learning foundation 2.1 - feature engineering/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/04/Machine%20learning%20foundation%202.1%20-%20feature%20engineering/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 特征的评估 特征处理 特征归一化(normalization)： 为了消除数据特征之间的量纲影响，需要对特征进行归一化处理，使得指标处于同一数值量级，不同指标之间具有可比性。 线性函数归一化(Min-Max scaling)： , 将结果映射到[0,1]范围 零均值归一化(Z-Score normalization): 将数据映射到均值为0、标准差为1的分布上。对于梯度下降类算法，该归一化能够加速收敛。 类别特征编码： 序号编码：处理类别间具有大小关系的数据。例如成绩，可以分为 低、中、高三档，并且存在“高&gt;中&gt;低”的排序关系，序号编码会按照大小关系对 类别型特征赋予一个数值ID。 独热编码(one-hot encoding): 独热编码通常用于处理类别间不具有大小关系的特征。 二进制编码：二进制编码主要分为两步，先用序号编码给每个类别赋予一个类别ID，然后 将类别ID对应的二进制编码作为结果。本 质上是利用二进制对ID进行哈希映射，节省存储空间。 其他编码： Helmert contrast, Sum Contrast, Polynomial Contrast, Backward difference contrast 组合特征：一阶离散特征两两组合，构成高阶组合特征，提高复杂关系的拟合能力。对于寻找组合特征的方式，可以考虑决策树。 特征选择 主成分分析(Principal components analysis, PCA): 直觉：找到数据中的主成分，并利用这些主成分表征原始数据，从而达到 降维的目的。在信号处理领域，信号具有较大方差，噪声具有较小方差，信号与噪声之比 称为信噪比。信噪比越大意味着数据的质量越好，反之，信噪比越小意味着数据 的质量越差。由此引出PCA的目标，即最大化投影方差，也就是让数据在主轴上投影的方差最大。 过程：给定一组特征, 中心化后为. 已知向量内积在几何上可以表示位第一个向量投影到第二个向量上的长度，因此向量在单位向量上的投影坐标可以表示为, 所以目标是找到一个投影方向使得所有在其上的投影方差尽可能大。已知投影后均值, 因此方差可以表示为, , 其中 为样本协方差，由于是单位向量， 有, 因此需要求解如下最大化问题 引入拉格朗日乘子，并对求导令其为0， 可以推导出, 因此投影后的方差就是协方差矩阵的特征值。我们要找到最大的方差就是协方差矩阵最大特征值，最佳投影方向就是最大特征值所对应的特征向量， 次佳投影方向位于最佳投影方向的正交空间中，是第二大特征值对应的特征向量， 以此类推。至此，我们得到以下求解方法 对样本数据进行中心化处理 求样本协方差矩阵，对协方差矩阵进行特征值分解，将特征值从大到小排列 取特征值前大的特征向量， 通过映射将维向量映射到维 定义降维后的信息占比为 线性判别分析(Linear discriminant analysis, LDA): 从简单的二分类问题出发， 有两个类别的样本，两类的均值分别为, 我们希望投影之后两类的中心距离尽可能大，距离表示为， 其中为两类的中心在投影后的向量，, 要优化的问题为 两类中心的距离最大化不能够保证两类边界的样本的可区分，LDA的中心思想是最大化类间距离和最小化类内距离。因此引入新的最大化目标 其中为单位向量，分别表示两类投影后的方差 等距映射 局部线性嵌入 拉普拉斯特征映射 局部保留投影 数据分析领域中最为人称道的七种降维方法 降维方法PCA, isomap, lle, autoencoder等的实现","categories":[],"tags":[{"name":"feature engineering","slug":"feature-engineering","permalink":"http://yourthomaslee.github.io/tags/feature-engineering/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://yourthomaslee.github.io/tags/machine-learning/"}]},{"title":"Leetcode 982. Triples with Bitwise AND Equal To Zero","slug":"Leetcode 982","date":"2023-03-04T02:40:05.000Z","updated":"2023-03-04T02:20:48.063Z","comments":true,"path":"2023/03/04/Leetcode 982/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/04/Leetcode%20982/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314151617181920class Solution {public: int countTriplets(vector&lt;int&gt;&amp; nums) { vector&lt;int&gt; cnt(1 &lt;&lt; 16); for (int x: nums) { for (int y: nums) { ++cnt[x &amp; y]; } } int ans = 0; for (int x: nums) { for (int mask = 0; mask &lt; (1 &lt;&lt; 16); ++mask) { if ((x &amp; mask) == 0) { ans += cnt[mask]; } } } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hard level","slug":"hard-level","permalink":"http://yourthomaslee.github.io/tags/hard-level/"},{"name":"binary operation","slug":"binary-operation","permalink":"http://yourthomaslee.github.io/tags/binary-operation/"}]},{"title":"Leetcode 1487. Making File Names Unique","slug":"Leetcode 1487","date":"2023-03-03T02:40:05.000Z","updated":"2023-03-03T02:13:32.691Z","comments":true,"path":"2023/03/03/Leetcode 1487/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/03/Leetcode%201487/","excerpt":"","text":"The problem description can be found at the link My solution: 123456789101112131415161718192021222324252627282930313233343536class Solution {public: vector&lt;string&gt; getFolderNames(vector&lt;string&gt;&amp; names) { set&lt;string&gt; st; unordered_map&lt;string, int&gt; counter; vector&lt;string&gt; ans; string p; int i; for(auto x: names){ if(st.find(x) != st.end()){ //重复需要后缀 i = 1; if(counter.find(x) == counter.end()) i = 1; else i = counter[x]; while(true){ p = x + \"(\" + to_string(i) + \")\"; if(st.find(p) != st.end()) { i++; continue; } else{ counter[x] = i; st.insert(p); ans.emplace_back(p); break; } } } else{ st.insert(x); ans.emplace_back(x); } } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"string","slug":"string","permalink":"http://yourthomaslee.github.io/tags/string/"}]},{"title":"Note-Combining modular skills in multitask learning","slug":"Note-Combining modular skills in multitask learning","date":"2023-03-02T09:26:53.000Z","updated":"2023-03-05T02:03:26.045Z","comments":true,"path":"2023/03/02/Note-Combining modular skills in multitask learning/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/02/Note-Combining%20modular%20skills%20in%20multitask%20learning/","excerpt":"","text":"The core problems this paper want to answer are: how to decide skills that are relevant to the specific task? how to be parameter-efficient at the same time when the modules are good enough to cope with tasks? Existing methods and its shortages: Pervious settings where the skills relevant for each task are know a prior or settings where parameters or representations are entangled mixture of shared and task-specific knowledge. The former method requires expert knowledge, whereas the latter leaves multitask models vulnerable to distribution shifts and hence hinders them from quickly adapting to new tasks. Mainstream methods can be divided into two groups: hard sharing methods may exhaust model capacity (explosion in parameter count) and lead to interference among the task-specific gradients and softly sharing methods suffer during few-shot adaptation to new tasks as it may overfit the training task distribution due to entangling knowledge across tasks. The authors assume that each task is associated with a subset of latent discrete skills from a inventory and skills correspond to parameter-efficient model parameterisations, and propose a method to solve problems mentioned above a task-skill allocation matrix, which indicates which subset of skills are active for which task and can be learned using stochastic gradient descend a coreresponding set of parameter-efficient adaptations of model, a subset of which are superimposed to a base model according to the active skills. Problem description The goal of multitask learning in modelling a set of tasks $\\mathcal{T}=(\\mathcal{T}_1, \\mathcal{T}2,\\cdots,\\mathcal{T}{|\\mathcal T|})$ is two-fold: increasing sample efficiency on each seen task by borrowing statistical strength from the others; attaining systematic generalisation, the ability to adapt robustly to new tasks, possibly based on a few target-domain examples. In supervised learning, each task is associated with a dataset Missing or unrecognized delimiter for \\left\\mathcal{D}_i \\triangleq\\left{\\left(\\mathbf{x}_1, y_1\\right), \\ldots,\\left(\\mathbf{x}_n, y_n\\right)\\right} and a loss function , where each is an input and each is a label. In reinfocement learning, each task is characterised by an initial state distribution , a transition distribution and a loss function , where is a state, is an action, and is the temporal horizon of each episode. Thus, each task defines a Markov decision process. The autors posit that there exists a (possibly small) fixed inventory of skills $\\mathcal {S} = (\\mathcal S 1, \\cdots, \\mathcal {S}{|\\mathcal S|})|\\mathcal S| \\ll |\\mathcal T|\\sum_{\\mathcal T_i}\\sum_{(\\mathbf x, y)\\in \\mathcal T_i} \\log p(y| \\mathbf x, Z, \\Phi, \\mathcal T_i)p(Z|\\alpha)p(\\Phi)$ with respect to two distinct sets of parameters: a matrix : a matrix of soft partitions of skills across tasks, which is regularised by a prior with hyper-parameter . Each cell is a binary scalar indicating if module is active for a certain task . : a matrix of skill-specific parameters for a given neural architecture, which are composed according to the active skills. [ is the dimension of the layer parameters]. Soft partition: Modularity at the task level should reflect the fact that tasks fall into a hierarchy where more complex ones subsume simpler ones (e.g., dialogue requires both intention classification and text generation). Hence variable-size subsets of skills should be allowed. The authors assume that the matrix representing task-skill allocations is a soft partition: each cell is a binary scalar indicating if module is active for a certain task . For the learnibility of parameters, the authors implement it as a collection of continuously relaxed Bernoulli distributions through a Gumbel-sigmoid, which ensures stochasticity while allowing for differentiable sampling: the author also provide an inductive bias to encourage the model to learn a low-entropy, highly-sparse allocation matrix. A possible inductive biase consists of adding an Indian Buffet Process(IBP) Prior to , as IBP is the natural prior for binary matrices representating soft partitions. In particular, this assumes that the -th task is associated with skills used by previous tasks with probability (i.e., in proportion to their ‘popularity’) and new skills, where is the count of tasks for which skill $\\mathcal{S}j\\alpha$ \\log p(Z|\\alpha) = &amp;|\\mathcal S| \\log \\alpha - \\sum{h = 1}^{2^{|\\mathcal T|} - 1}\\log Z_h! - \\alpha \\sum_{\\mathcal T_i}H_{\\mathcal T_i} \\ &amp;+ \\sum_{\\mathcal S_j}[\\log(|\\mathcal T| - m_{\\mathcal S_j})! + \\log (m_{\\mathcal S_j} - 1)! -\\log (|\\mathcal T|)!)] $$ Where is the -th harmonic number (调和数字) and is the number of skills possessing the history (the binary vector of their corresponding column in the matrix ). While training a neural network, the prior probability in above equation can be taken into account in the form of a regulariser substracted to the main loss function. Skill-specific parameters: Given the matrix row for task and a matrix of skill-specific parameters , where is the dimension of the layer parameters, the aggregate of the parameters of active skills is superimposed to a base parameterisation shared across tasks. For instance, may be either the initialisation from a pre-trained model or learned from scratch: Note that we normalise the rows of the task-skill allocation matrix prior to composition because the variable number of active skills per task would otherwise affect the norm of the combined parameters , thus making training unstable. 用来指明任务和维度之间的关系，主要用来学习和记忆不同任务专用的维度 Two-speed Learning Rate: The authors also experiment with setting the learning rate for higher than for . Intuitively, by accelerating learning of the soft partition matrix, to minimise the loss it becomes more convenient to discover better task-skill allocations over settling for general-purpose parameters that are agnostic with respect to the subset of active skills. 对于门机制的学习率，作者认为加速门的学习有益于尽快降低损失并探究更好的门值，因此设置得比任务网络更加高。 Parameter efficiency: the authors explor parameter-efficient implementations of that only add a negligible amount of parameters to the base model. In particular, the authors contemplate both sparse and low-rank approximations Sparse approximations: Lottery ticket sparse fine-tuning learns a highly sparse vector of differences with respect to a base model . In paper’s setting, this amounts to identifying a binary matrix indexing non-zero entries in . can be infered by selecting the top- Entries in based on their change in magnitude after a few early episodes. the advantage of LT-SFT over other methods is that it is architecture-agnostic. However, it suffers from high space complexity during the early phase of training. Low-rank approximation: Low-rank adapters factories each weight of the linear projections inside self-attention layers as a multiplication between two low-rank matrices. Hence, a linear projection is implemented as , where , and is the rank. Hence, .","categories":[],"tags":[{"name":"multitask learning","slug":"multitask-learning","permalink":"http://yourthomaslee.github.io/tags/multitask-learning/"},{"name":"modular skills","slug":"modular-skills","permalink":"http://yourthomaslee.github.io/tags/modular-skills/"}]},{"title":"Leetcode 0502 Binary Number to String LCCI","slug":"Leetcode m0502","date":"2023-03-02T02:40:05.000Z","updated":"2023-03-02T01:43:04.101Z","comments":true,"path":"2023/03/02/Leetcode m0502/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/02/Leetcode%20m0502/","excerpt":"","text":"The problem description can be found at the link 这道题给我的知识点是利用乘法得到小数点左侧的最高位 My solution: 1234567891011121314class Solution {public: string printBin(double num) { string res = \"0.\"; while (res.size() &lt;= 32 &amp;&amp; num != 0) { num *= 2; int digit = num; res.push_back(digit + '0'); num -= digit; } return res.size() &lt;= 32 ? res : \"ERROR\"; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"easy level","slug":"easy-level","permalink":"http://yourthomaslee.github.io/tags/easy-level/"},{"name":"binary number","slug":"binary-number","permalink":"http://yourthomaslee.github.io/tags/binary-number/"}]},{"title":"Leetcode 17.05. Find Longest Subarray LCCI","slug":"Leetcode m1705","date":"2023-03-02T02:40:05.000Z","updated":"2023-03-11T04:01:07.835Z","comments":true,"path":"2023/03/02/Leetcode m1705/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/02/Leetcode%20m1705/","excerpt":"","text":"The problem description can be found at the link Solution: 1234567891011121314151617181920212223class Solution {public: vector&lt;string&gt; findLongestSubarray(vector&lt;string&gt;&amp; array) { unordered_map&lt;int, int&gt; val2idx; int val = 0;// letter - number int l = -1, r = -1; val2idx[0] = -1; for(int i = 0; i &lt; array.size(); ++i){ val += isdigit(array.at(i)[0]) ? -1 : 1; auto it = val2idx.find(val); if( it != val2idx.end()){ //cout&lt;&lt;i&lt;&lt;\":\"&lt;&lt;it-&gt;second&lt;&lt;\" -&gt; \"&lt;&lt; i&lt;&lt;endl; if(i - it-&gt;second &gt; r - l) l = it-&gt;second, r = i; } if(val2idx.find(val) == val2idx.end()) val2idx[val] = i; } if(l == -1 &amp;&amp; r == -1) return vector&lt;string&gt;(); else{ return vector&lt;string&gt;(array.begin() + l + 1, array.begin() + r + 1); } }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"sliding windows","slug":"sliding-windows","permalink":"http://yourthomaslee.github.io/tags/sliding-windows/"}]},{"title":"Note - An attention free transformer","slug":"Note-An attention free transformer","date":"2023-03-02T02:40:05.000Z","updated":"2023-06-10T09:34:42.781Z","comments":true,"path":"2023/03/02/Note-An attention free transformer/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/02/Note-An%20attention%20free%20transformer/","excerpt":"","text":"Paper address: https://arxiv.org/pdf/2105.14103.pdf Related codes: https://github.com/BlinkDL/RWKV-LM This paper presents alternative way to attention modelling and the result of this way gets competitive performance in some tasks Attention free transformer eliminates the need for dot product self attention Multi-Head Attention (MHA) Given an input sequence , and the number of heads , MHA performs a scaled dot product attention for each head , defined as , where are linear transformations for head , and is non-linearity by default set as the softmax function. Are dimensions for key and value. Attention Free Transformer(AFT) - full version it is a plugin replacement of MHA without the need of changing other architectural aspects of transformers. Given the input , AFT first linearly transforms them into , then , where is the element-wise product; is the nonlinearity applied to the query with default being sigmoid; is the learned pair-wise biases. For each position , AFT performs a weighted average of values based on the weight computed by (query), (key) and (the learned bias), the result of which is combined with the query with element-wise multiplication. ![计算方法](…/images/dot-production free attention.png) AFT-local version in this version, position bias are limited by as , which means AFT-local doesn’t model patterns with long distance. AFT-simple completely abandon the position biase so we get AFT-simple For the position bias, it can be more space-efficient by parameterization. For AFT-full and AFT-local, the authors adopt a factorized form of as , where is a small embedding dimension. This simple factorization not only greatly reduces the parameter counts( vs. )","categories":[],"tags":[{"name":"transfomer","slug":"transfomer","permalink":"http://yourthomaslee.github.io/tags/transfomer/"},{"name":"attention mechanism","slug":"attention-mechanism","permalink":"http://yourthomaslee.github.io/tags/attention-mechanism/"}]},{"title":"Leetcode 2373. Largest Local Values in a Matrix","slug":"Leetcode 2373","date":"2023-03-01T02:40:05.000Z","updated":"2023-03-01T01:53:21.477Z","comments":true,"path":"2023/03/01/Leetcode 2373/","link":"","permalink":"http://yourthomaslee.github.io/2023/03/01/Leetcode%202373/","excerpt":"","text":"The problem description can be found at the link My solution: 123456789101112131415161718192021222324class Solution {public: int findMax(vector&lt;vector&lt;int&gt;&gt;&amp; m, int p, int q){ int ans = 0; for(int i = p; i &lt; p + 3; ++i){ for(int j = q; j &lt; q + 3; ++j){ ans = max(m[i][j], ans); } } return ans; } vector&lt;vector&lt;int&gt;&gt; largestLocal(vector&lt;vector&lt;int&gt;&gt;&amp; grid) { vector&lt;vector&lt;int&gt;&gt; ans; if(grid.size() &lt; 3 || grid[0].size() &lt; 3) return ans; for(int i = 0; i + 2 &lt; grid.size(); ++i){ vector&lt;int&gt; tmp; for(int j = 0; j + 2 &lt; grid.size(); j++){ tmp.emplace_back(findMax(grid, i, j)); } ans.emplace_back(tmp); } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"array","slug":"array","permalink":"http://yourthomaslee.github.io/tags/array/"},{"name":"easy level","slug":"easy-level","permalink":"http://yourthomaslee.github.io/tags/easy-level/"}]},{"title":"Control theory - 0 Concepts","slug":"Control theory 0 - concepts","date":"2023-02-28T04:38:49.000Z","updated":"2023-02-28T12:28:46.100Z","comments":true,"path":"2023/02/28/Control theory 0 - concepts/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/28/Control%20theory%200%20-%20concepts/","excerpt":"","text":"开环控制：指无反馈信息的系统控制方式。当操作者启动系统，使之进入运行状态后，系统将操作者的指令一次性输向受控对象。 闭环控制：也叫反馈控制，指作为被控的输出以一定方式返回到作为控制的输入端，并对输入端施加控制影响的一种控制关系。 The framework of modern control theory can be split into following groups: Certain systems’ control linear systems theory(mathematical model) optimal control theory(control methods) Uncertain systems’ control optimal estimation theory(estimation methods) system identification theory(model identification) adaptive control theory(control methods)","categories":[],"tags":[{"name":"control theory","slug":"control-theory","permalink":"http://yourthomaslee.github.io/tags/control-theory/"}]},{"title":"Leetcode 2363. Merge Similar Items","slug":"Leetcode 2363","date":"2023-02-28T02:40:05.000Z","updated":"2023-02-28T02:12:21.027Z","comments":true,"path":"2023/02/28/Leetcode 2363/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/28/Leetcode%202363/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314151617class Solution {public: vector&lt;vector&lt;int&gt;&gt; mergeSimilarItems(vector&lt;vector&lt;int&gt;&gt;&amp; items1, vector&lt;vector&lt;int&gt;&gt;&amp; items2) { map&lt;int, int&gt; m; for(auto it: items1){ m[it[0]] += it[1]; } for(auto it: items2){ m[it[0]] += it[1]; } vector&lt;vector&lt;int&gt;&gt; ans; for(auto it: m){ ans.emplace_back(vector&lt;int&gt;{it.first, it.second}); } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"},{"name":"easy level","slug":"easy-level","permalink":"http://yourthomaslee.github.io/tags/easy-level/"}]},{"title":"Leetcode 1144. Decrease Elements To Make Array Zigzag","slug":"Leetcode 1144","date":"2023-02-27T02:40:05.000Z","updated":"2023-03-01T01:54:09.781Z","comments":true,"path":"2023/02/27/Leetcode 1144/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/27/Leetcode%201144/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122class Solution {public: int help(vector&lt;int&gt;&amp; nums, int pos) { int res = 0; for (int i = pos; i &lt; nums.size(); i += 2) { int a = 0; if (i - 1 &gt;= 0) { a = max(a, nums[i] - nums[i - 1] + 1); } if (i + 1 &lt; nums.size()) { a = max(a, nums[i] - nums[i + 1] + 1); } res += a; } return res; } int movesToMakeZigzag(vector&lt;int&gt;&amp; nums) { return min(help(nums, 0), help(nums, 1)); }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"greedy algorithm","slug":"greedy-algorithm","permalink":"http://yourthomaslee.github.io/tags/greedy-algorithm/"}]},{"title":"Note - Reinforcement learning and feedback control","slug":"Note-Reinforcement learning and feedback control","date":"2023-02-27T02:40:05.000Z","updated":"2023-02-28T04:26:27.579Z","comments":true,"path":"2023/02/27/Note-Reinforcement learning and feedback control/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/27/Note-Reinforcement%20learning%20and%20feedback%20control/","excerpt":"","text":"Paper address: reinforcement learning and feedback control: using natural decision methods to design optimal adaptive controllers The relationship between reinforcement and control: reinforcement learning is direct adaptive optimal control Useful concepts: Adaptive control and optimal control represent different philosophies for designing feedback controllers. Optimal controllers are normally designed offline by solving hamilton-jacobi-bellman (HJB) equations, for example, the Riccati equation, using complete knowledge of the system dynamics. Determining optimal control policies for nonliear systems requires the offline solution of nonlinear HJB equations, which are often difficult or impossible to solve. Adaptive controllers learn online to control unknow systems using data measured in real time along the systems trajectories. Adaptive controllers are not usually designed to be optimal in the sense of minimizing user-prescribed preformance functions. Indirect adaptive controllers use system identification techniques to first identify the system parameters and then use the obtained model to solve optimal design equations. Adaptive controllers may satisfy certain inverse optimality conditions.","categories":[],"tags":[{"name":"reinforcement learning","slug":"reinforcement-learning","permalink":"http://yourthomaslee.github.io/tags/reinforcement-learning/"},{"name":"optimal control","slug":"optimal-control","permalink":"http://yourthomaslee.github.io/tags/optimal-control/"},{"name":"adaptive control","slug":"adaptive-control","permalink":"http://yourthomaslee.github.io/tags/adaptive-control/"}]},{"title":"Leetcode 1255. Maximum Score Words Formed by Letters","slug":"Leetcode 1255","date":"2023-02-26T02:40:05.000Z","updated":"2023-02-27T04:04:27.838Z","comments":true,"path":"2023/02/26/Leetcode 1255/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/26/Leetcode%201255/","excerpt":"","text":"The problem description can be found at the link My solution: 123456789101112131415161718192021222324252627282930313233343536class Solution {public: int checkWord(string&amp; w, map&lt;char, int&gt;&amp; m, vector&lt;int&gt;&amp; scores){ int score = 0; for(int i = 0; i &lt; w.size(); ++i){ if(m.find(w[i]) == m.end() || m[w[i]] == 0) { for(int j = i - 1; j &gt;= 0; j--){ m[w[j]]++; } return -1; } m[w[i]]--; score += scores[w[i] - 'a']; } return score; } int maxScore(vector&lt;string&gt;&amp; words, map&lt;char, int&gt;&amp; m, vector&lt;int&gt;&amp; score, int i = 0){ if(i == words.size()) return 0; int ans = 0; int step = checkWord(words[i], m, score); if(step &gt; 0) { ans = max(ans, step + maxScore(words, m, score, i + 1)); for(auto x: words[i]) m[x]++; } ans = max(ans, maxScore(words, m, score, i + 1)); return ans; } int maxScoreWords(vector&lt;string&gt;&amp; words, vector&lt;char&gt;&amp; letters, vector&lt;int&gt;&amp; score) { map&lt;char, int&gt; m; for(auto l: letters){ m[l]++; } return maxScore(words, m, score, 0); }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hard level","slug":"hard-level","permalink":"http://yourthomaslee.github.io/tags/hard-level/"},{"name":"deep first search","slug":"deep-first-search","permalink":"http://yourthomaslee.github.io/tags/deep-first-search/"}]},{"title":"Leetcode 2357. Make Array Zero by Subtracting Equal Amounts","slug":"Leetcode 2357","date":"2023-02-24T02:40:05.000Z","updated":"2023-02-24T01:41:30.164Z","comments":true,"path":"2023/02/24/Leetcode 2357/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/24/Leetcode%202357/","excerpt":"","text":"The problem description can be found at the link My solution: 123456789101112131415161718192021222324252627282930class Solution {public: int minimumOperations(vector&lt;int&gt;&amp; nums) { int min_val = -1; for(int i = 0; i &lt; nums.size(); ++i){ if(nums[i] &gt; 0){ if(min_val == -1) min_val = nums[i]; else min_val = min(min_val, nums[i]); } } if(min_val == -1) return 0; for(int i = 0; i &lt; nums.size(); ++i){ if(nums[i] &gt; 0) nums[i] -= min_val; } return 1 + minimumOperations(nums); }};//后来发现直接用集合统计不同数字作为答案class Solution {public: int minimumOperations(vector&lt;int&gt;&amp; nums) { set&lt;int&gt; a; for(auto x: nums){ if(x &gt; 0) a.insert(x); } return a.size(); }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"},{"name":"easy level","slug":"easy-level","permalink":"http://yourthomaslee.github.io/tags/easy-level/"}]},{"title":"Leetcode 1238. Circular Permutation in Binary Representation","slug":"Leetcode 1238","date":"2023-02-23T02:40:05.000Z","updated":"2023-02-23T02:15:24.705Z","comments":true,"path":"2023/02/23/Leetcode 1238/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/23/Leetcode%201238/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213class Solution {public: vector&lt;int&gt; circularPermutation(int n, int start) { vector&lt;int&gt; ans(pow(2,n),0); ans[0] = start; int i = 0; for(i = 1; i &lt; ans.size(); i ++) { ans[i] = ans[i - 1]^(i&amp;(-i)); } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"binary operation","slug":"binary-operation","permalink":"http://yourthomaslee.github.io/tags/binary-operation/"}]},{"title":"Leetcode 1238. Circular Permutation in Binary Representation","slug":"Leetcode 1247","date":"2023-02-23T02:40:05.000Z","updated":"2023-02-25T12:34:12.297Z","comments":true,"path":"2023/02/23/Leetcode 1247/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/23/Leetcode%201247/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314151617181920class Solution {public: int minimumSwap(string s1, string s2) { int xy = 0, yx = 0; int n = s1.size(); for (int i = 0; i &lt; n; i++) { char a = s1[i], b = s2[i]; if (a == 'x' and b == 'y') { xy++; } if (a == 'y' and b == 'x') { yx++; } } if ((xy + yx) % 2 == 1) { return -1; } return xy / 2 + yx / 2 + xy % 2 + yx % 2; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"greedy algorithm","slug":"greedy-algorithm","permalink":"http://yourthomaslee.github.io/tags/greedy-algorithm/"}]},{"title":"Computational advertising 2 - Ranking models","slug":"Computional advertising 2 - 3 ranking models","date":"2023-02-21T14:40:05.000Z","updated":"2023-02-23T02:15:11.437Z","comments":true,"path":"2023/02/21/Computional advertising 2 - 3 ranking models/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/21/Computional%20advertising%202%20-%203%20ranking%20models/","excerpt":"","text":"[TOC] 1. 排序层 排序层中一般包含粗排、精排、重排、混排不同的模块，以下分块进行说明 粗排：粗排的原因是有时候召回的结果还是太多，精排层速度还是跟不上，所以加入粗排。粗排可以理解为精排前的一轮过滤机制，减轻精排模块的压力。粗排介于召回和精排之间，要同时兼顾精准性和低延迟。目前粗排一般也都模型化了，其训练样本类似于精排，选取曝光点击为正样本，曝光未点击为负样本。但由于粗排一般面向上万的候选集，而精排只有几百上千，其解空间大很多。粗排阶段的架构设计主要是考虑三个方面，一个是根据精排模型中的重要特征，来做候选集的截断，另一部分是有一些召回设计，比如热度或者语义相关的这些结果，仅考虑了item侧的特征，可以用粗排模型来排序跟当前User之间的相关性，据此来做截断，这样是比单独的按照item侧的倒排分数截断得到更加个性化的结果，最后是算法的选型要在在线服务的性能上有保证，因为这个阶段在pipeline中完成从召回到精排的截断工作，在延迟允许的范围内能处理更多的召回候选集理论上与精排效果正相关。 精排层：是我们学习推荐入门最常常接触的层，我们所熟悉的算法很大一部分都来自精排层。这一层的任务是获取粗排模块的结果，对候选集进行打分和排序。精排需要在最大时延允许的情况下，保证打分的精准性，是整个系统中至关重要的一个模块，也是最复杂，研究最多的一个模块。精排是推荐系统各层级中最纯粹的一层，他的目标比较单一且集中，一门心思的实现目标的调优即可。最开始的时候精排模型的常见目标是ctr,后续逐渐发展了cvr等多类目标。精排和粗排层的基本目标是一致的，都是对商品集合进行排序，但是和粗排不同的是，精排只需要对少量的商品(即粗排输出的商品集合的topN)进行排序即可。因此，精排中可以使用比粗排更多的特征，更复杂的模型和更精细的策略（用户的特征和行为在该层的大量使用和参与也是基于这个原因）。精排层模型是推荐系统中涵盖的研究方向最多，有非常多的子领域值得研究探索，这也是推荐系统中技术含量最高的部分，毕竟它是直接面对用户，产生的结果对用户影响最大的一层。目前精排层深度学习已经一统天下了，精排阶段采用的方案相对通用，首先一天的样本量是几十亿的级别，我们要解决的是样本规模的问题，尽量多的喂给模型去记忆，另一个方面时效性上，用户的反馈产生的时候，怎么尽快的把新的反馈给到模型里去，学到最新的知识。 重排：常见的有三种优化目标：Point Wise、Pair Wise 和 List Wise。重排序阶段对精排生成的Top-N个物品的序列进行重新排序，生成一个Top-K个物品的序列，作为排序系统最后的结果，直接展现给用户。重排序的原因是因为多个物品之间往往是相互影响的，而精排序是根据PointWise得分，容易造成推荐结果同质化严重，有很多冗余信息。而重排序面对的挑战就是海量状态空间如何求解的问题，一般在精排层我们使用AUC作为指标，但是在重排序更多关注NDCG等指标。重排序在业务中，获取精排的排序结果，还会根据一些策略、运营规则参与排序，比如强制去重、间隔排序、流量扶持等、运营策略、多样性、context上下文等，重新进行一个微调。重排序更多的是List Wise作为优化目标的，它关注的是列表中商品顺序的问题来优化模型，但是一般List Wise因为状态空间大，存在训练速度慢的问题。由于精排模型一般比较复杂，基于系统时延考虑，一般采用point-wise方式，并行对每个item进行打分。这就使得打分时缺少了上下文感知能力。用户最终是否会点击购买一个商品，除了和它自身有关外，和它周围其他的item也息息相关。重排一般比较轻量，可以加入上下文感知能力，提升推荐整体算法效率。比如三八节对美妆类目商品提权，类目打散、同图打散、同卖家打散等保证用户体验措施。重排中规则比较多，但目前也有不少基于模型来提升重排效果的方案。 混排：多个业务线都想在Feeds流中获取曝光，则需要对它们的结果进行混排。比如推荐流中插入广告、视频流中插入图文和banner等。可以基于规则策略（如广告定坑）和强化学习来实现。 经典的排序模型的演进可以分为两条路线，一条是组合特征的挖掘，另外一条则是通过各种方法引入更多有效的信息到embedding，以下分点进行阐述。 2. 特征交叉 2.1. GBDT + LR 协同过滤和矩阵分解存在的劣势就是仅利用了用户与物品相互行为信息进行推荐， 忽视了用户自身特征， 物品自身特征以及上下文信息等，导致生成的结果往往会比较片面。 而这次介绍的这个模型是2014年由Facebook提出的GBDT+LR模型， 该模型利用GBDT自动进行特征筛选和组合， 进而生成新的离散特征向量， 再把该特征向量当做LR模型的输入， 来产生最后的预测结果， 该模型能够综合利用用户、物品和上下文等多种不同的特征， 生成较为全面的推荐结果， 在CTR点击率预估场景下使用较为广泛。 逻辑回归模型优点： LR模型形式简单，可解释性好，从特征的权重可以看到不同的特征对最后结果的影响。 训练时便于并行化，在预测时只需要对特征进行线性加权，所以性能比较好，往往适合处理海量id类特征，用id类特征有一个很重要的好处，就是防止信息损失（相对于范化的 CTR 特征），对于头部资源会有更细致的描述 资源占用小,尤其是内存。在实际的工程应用中只需要存储权重比较大的特征及特征对应的权重。 方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值(大于某个阈值的是一类，小于某个阈值的是一类) 局限性 表达能力不强， 无法进行特征交叉， 特征筛选等一系列“高级“操作（这些工作都得人工来干， 这样就需要一定的经验， 否则会走一些弯路）， 因此可能造成信息的损失 准确率并不是很高。因为这毕竟是一个线性模型加了个sigmoid， 形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布 处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据， 如果想处理非线性， 首先对连续特征的处理需要先进行离散化（离散化的目的是为了引入非线性），如上文所说，人工分桶的方式会引入多种问题。 LR 需要进行人工特征组合，这就需要开发者有非常丰富的领域经验，才能不走弯路。这样的模型迁移起来比较困难，换一个领域又需要重新进行大量的特征工程。 GBDT模型中可以把树的生成过程理解成自动进行多维度的特征组合的过程，能够有效解决有效特征的搜索问题，同时也有一些局限性， 对于海量的 id 类特征，GBDT 由于树的深度和棵树限制（防止过拟合），不能有效的存储；另外海量特征在也会存在性能瓶颈，当 GBDT 的 one hot 特征大于 10 万维时，就必须做分布式的训练才能保证不爆内存。所以 GBDT 通常配合少量的反馈 CTR 特征来表达，这样虽然具有一定的范化能力，但是同时会有信息损失，对于头部资源不能有效的表达。模型的总体结构长下面这样： 训练时，GBDT 建树的过程相当于自动进行的特征组合和离散化，然后从根结点到叶子节点的这条路径就可以看成是不同特征进行的特征组合，用叶子节点可以唯一的表示这条路径，并作为一个离散特征传入 LR 进行二次训练。 比如上图中， 有两棵树，x为一条输入样本，遍历两棵树后，x样本分别落到两颗树的叶子节点上，每个叶子节点对应LR一维特征，那么通过遍历树，就得到了该样本对应的所有LR特征。构造的新特征向量是取值0/1的。 比如左树有三个叶子节点，右树有两个叶子节点，最终的特征即为五维的向量。对于输入x，假设他落在左树第二个节点，编码[0,1,0]，落在右树第二个节点则编码[0,1]，所以整体的编码为[0,1,0,0,1]，这类编码作为特征，输入到线性分类模型（LR or FM）中进行分类。 预测时，会先走 GBDT 的每棵树，得到某个叶子节点对应的一个离散特征(即一组特征组合)，然后把该特征以 one-hot 形式传入 LR 进行线性加权预测。 这个方案应该比较简单了， 下面有几个关键的点我们需要了解： 通过GBDT进行特征组合之后得到的离散向量是和训练数据的原特征一块作为逻辑回归的输入， 而不仅仅全是这种离散特征 建树的时候用ensemble建树的原因就是一棵树的表达能力很弱，不足以表达多个有区分性的特征组合，多棵树的表达能力更强一些。GBDT每棵树都在学习前面棵树尚存的不足，迭代多少次就会生成多少棵树。 RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。 在CRT预估中， GBDT一般会建立两类树(非ID特征建一类， ID类特征建一类)， AD，ID类特征在CTR预估中是非常重要的特征，直接将AD，ID作为feature进行建树不可行，故考虑为每个AD，ID建GBDT树。 非ID类树：不以细粒度的ID建树，此类树作为base，即便曝光少的广告、广告主，仍可以通过此类树得到有区分性的特征、特征组合 ID类树：以细粒度 的ID建一类树，用于发现曝光充分的ID对应有区分性的特征、特征组合 2.2 Factorization machine(FM) 参见召回层部分的FM部分内容 2.3 Neural Factorization Machines (NFM) NFM(Neural Factorization Machines)是2017年由新加坡国立大学的何向南教授等人在SIGIR会议上提出的一个模型，传统的FM模型仅局限于线性表达和二阶交互， 无法胜任生活中各种具有复杂结构和规律性的真实数据， 针对FM的这点不足， 作者提出了一种将FM融合进DNN的策略，通过引进了一个特征交叉池化层的结构，使得FM与DNN进行了完美衔接，这样就组合了FM的建模低阶特征交互能力和DNN学习高阶特征交互和非线性的能力，形成了深度学习时代的神经FM模型(NFM)。 NFM的公式： $$ \\hat{y}{N F M}(\\mathbf{x})=w{0}+\\sum_{i=1}^{n} w_{i} x_{i}+f(\\mathbf{x}) $$ 我们对比FM， 就会发现变化的是第三项，前两项还是原来的， 因为我们说FM的一个问题，就是只能到二阶交叉， 且是线性模型， 这是他本身的一个局限性， 而如果想突破这个局限性， 就需要从他的公式本身下点功夫， 于是乎，作者在这里改进的思路就是用一个表达能力更强的函数来替代原FM中二阶隐向量内积的部分。 Bi-Interaction Pooling layer: 在Embedding层和神经网络之间加入了特征交叉池化层是本网络的核心创新了，正是因为这个结构，实现了FM与DNN的无缝连接， 组成了一个大的网络，且能够正常的反向传播。假设$\\mathcal{V}{x}是所有特征的集合，那么在特征交叉池化层的操作：$ f{B I}\\left(\\mathcal{V}{x}\\right)=\\sum{i=1}^{n} \\sum_{j=i+1}^{n} x_{i} \\mathbf{v}{i} \\odot x{j} \\mathbf{v}_{j} $$ 表示两个向量的元素积操作，即两个向量对应维度相乘得到的元素积向量（可不是点乘呀），其中第维的操作： $$ \\left(v_{i} \\odot v_{j}\\right){k}=\\boldsymbol{v}{i k} \\boldsymbol{v}_{j k} $$ 详情参见：link 2.4 Attentional Factorization Machines(AFM) 在FM的基础上加上了注意力机制，FM是通过特征隐向量的内积来对交叉特征进行建模，并没有对其进行差异化对待，而AFM就是通过Attention机制来去做交叉特征的差异化 参见：link 2.5 PNN 在特征交叉的相关模型中FM, FFM都证明了特征交叉的重要性，FNN将神经网络的高阶隐式交叉加到了FM的二阶特征交叉上，一定程度上说明了DNN做特征交叉的有效性。但是对于DNN这种“add”操作的特征交叉并不能充分挖掘类别特征的交叉效果。PNN虽然也用了DNN来对特征进行交叉组合，但是并不是直接将低阶特征放入DNN中，而是设计了Product层先对低阶特征进行充分的交叉组合之后再送入到DNN中去。 PNN模型其实是对IPNN和OPNN的总称，两者分别对应的是不同的Product实现方法，前者采用的是inner product，后者采用的是outer product。在PNN的算法方面，比较重要的部分就是Product Layer的简化实现方法，需要在数学和代码上都能够比较深入的理解。 细节参见： link 2.6 Wide &amp; Deep network 在CTR预估任务中利用手工构造的交叉组合特征来使线性模型具有“记忆性”，使模型记住共现频率较高的特征组合，往往也能达到一个不错的baseline，且可解释性强。但这种方式有着较为明显的缺点： 特征工程需要耗费太多精力。 模型是强行记住这些组合特征的，对于未曾出现过的特征组合，权重系数为0，无法进行泛化。 为了加强模型的泛化能力，研究者引入了DNN结构，将高维稀疏特征编码为低维稠密的Embedding vector，这种基于Embedding的方式能够有效提高模型的泛化能力。但是，基于Embedding的方式可能因为数据长尾分布，导致长尾的一些特征值无法被充分学习，其对应的Embedding vector是不准确的，这便会造成模型泛化过度。 wide部分是一个广义的线性模型，输入的特征主要有两部分组成，一部分是原始的部分特征，另一部分是原始特征的交叉特征(cross-product transformation) Deep部分是一个DNN模型，输入的特征主要分为两大类，一类是数值特征(可直接输入DNN)，一类是类别特征(需要经过Embedding之后才能输入到DNN中)，DNN模型随着层数的增加，中间的特征就越抽象，也就提高了模型的泛化能力. 详情参见：link 2.7 Deep &amp; cross network(DCN) Wide&amp;Deep模型的提出不仅综合了“记忆能力”和“泛化能力”， 而且开启了不同网络结构融合的新思路。 所以后面就有各式各样的模型改进Wide部分或者Deep部分， 而Deep&amp;Cross模型(DCN)就是其中比较典型的一个，这是2017年斯坦福大学和谷歌的研究人员在ADKDD会议上提出的， 该模型针对W&amp;D的wide部分进行了改进， 因为Wide部分有一个不足就是需要人工进行特征的组合筛选， 【Cross网络】 这个思路感觉非常Nice。设计该网络的目的是增加特征之间的交互力度。交叉网络由多个交叉层组成， 假设第层的输出向量， 那么对于第层的输出向量表示为： $$ \\mathbf{x}{l+1}=\\mathbf{x}{0} \\mathbf{x}{l}^{T} \\mathbf{w}{l}+\\mathbf{b}{l}+\\mathbf{x}{l}=f\\left(\\mathbf{x}{l}, \\mathbf{w}{l}, \\mathbf{b}{l}\\right)+\\mathbf{x}{l} $$ 可以看到， 交叉层的二阶部分非常类似PNN提到的外积操作， 在此基础上增加了外积操作的权重向量， 以及原输入向量和偏置向量。 详情参见: link 2.8 xDeepFM xDeepFM(eXtreme DeepFM)是2018年中科大联合微软在KDD上提出的一个模型，模型的改进出发点依然是如何更好的学习特征之间的高阶交互作用，从而挖掘更多的交互信息。DCN的交叉网络的结果是输入与某一个向量相乘的结果，这限制了网络对于向量学习中的差异性的追求。设计了新的交叉网络，但时间复杂度很高。 详情参见：link 2.9 Automatic Feature Interaction(AutoInt) AutoInt(Automatic Feature Interaction)是2019年发表在CIKM上的文章，这里面提出的模型，重点也是在特征交互上，而所用到的结构，就是大名鼎鼎的transformer结构 详情参见： link 2.10 FiBiNet FiBiNet的提出动机是因为在特征交互这一方面， 目前的ctr模型要么是简单的两两embedding内积(这里针对离散特征)， 比如FM，FFM。 或者是两两embedding进行哈达玛积(NFM这种)， 作者认为这两种交互方式还是过于简单， 另外像NFM这种，FM这种，也忽视了特征之间的重要性程度。 第一个是大部分模型没有考虑特征重要性，也就是交互完事之后，没考虑对于预测目标来讲谁更重要，一视同仁。 第二个是目前的两两特征交互，大部分依然是内积或者哈达玛积， 作者认为还不是细粒度(fine-grained way)交互。 使用SENet来去调整原始embedding，去拟合对于预测目标的重要性；使用Bilinear-interaction layer去做细粒度的交互。对于Bilinear-interaction layer见如下 这个图其实非常了然了。以往模型用的交互， 内积的方式(FM,FFM)这种或者哈达玛积的方式(NFM,AFM)这种。 详情参见： link 3. embedding信息挖掘 3.1 序列模型 Deep Interest Network(DIN)是2018年阿里巴巴提出来的模型：具体细节见召回部分 DIEN模型的重点就是如何将用户的行为序列转换成与用户兴趣相关的向量，在DIN中是直接通过与target item计算序列中每个元素的注意力分数 DSIN全称是Deep Session Interest Network(深度会话兴趣网络)，重点在这个Session上，这个是在DIEN的基础上又进行的一次演化，这个模型的改进出发点依然是如何通过用户的历史点击行为，从里面更好的提取用户的兴趣以及兴趣的演化过程，这个模型就是从user历史行为信息挖掘方向上进行演化的。 详情参见：link 3.2 多任务学习 ESMM:详情参见link Multi-gate Mixture-of-Experts(MMOE): 详情参见link PLE(Progressive Layered Extraction)：详情参见link","categories":[],"tags":[{"name":"computational advertising","slug":"computational-advertising","permalink":"http://yourthomaslee.github.io/tags/computational-advertising/"},{"name":"ranking models","slug":"ranking-models","permalink":"http://yourthomaslee.github.io/tags/ranking-models/"}]},{"title":"Leetcode 1326. Minimum Number of Taps to Open to Water a Garden","slug":"Leetcode 1326","date":"2023-02-21T02:40:05.000Z","updated":"2023-02-21T01:34:18.666Z","comments":true,"path":"2023/02/21/Leetcode 1326/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/21/Leetcode%201326/","excerpt":"","text":"The problem description can be found at the link My solution: 123456789101112131415161718192021222324class Solution {public: int minTaps(int n, vector&lt;int&gt;&amp; ranges) { vector&lt;int&gt; dp(n + 1, n + 1); int last_state = 0; for(int i = 0; i &lt;= n; ++i){ if(ranges[i] &gt; 0){ for(int j = max(0, i - ranges[i]); j &lt;= min(n, i + ranges[i]); ++j){ if(i - ranges[i] &lt;= 0) last_state = 0; else last_state = dp[i - ranges[i]]; dp[j] = min(dp[j], last_state + 1); } } } int min_state = n; //situation 1: there is no answer =&gt; there must be a position where the value is -1 //situation 2: there is an answer for(int i = 0; i &lt;= n; ++i){ if(dp[i] == n + 1) return -1; //cout&lt;&lt;i&lt;&lt;\" : \"&lt;&lt;dp[i]&lt;&lt;endl; } return dp[n]; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hard level","slug":"hard-level","permalink":"http://yourthomaslee.github.io/tags/hard-level/"},{"name":"dynamic programming","slug":"dynamic-programming","permalink":"http://yourthomaslee.github.io/tags/dynamic-programming/"}]},{"title":"Deep learning foundation 0 - framework","slug":"Deep learning 0 - framework","date":"2023-02-20T02:40:05.000Z","updated":"2023-02-10T16:30:04.182Z","comments":true,"path":"2023/02/20/Deep learning 0 - framework/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/20/Deep%20learning%200%20-%20framework/","excerpt":"","text":"","categories":[],"tags":[{"name":"deep learning framework","slug":"deep-learning-framework","permalink":"http://yourthomaslee.github.io/tags/deep-learning-framework/"}]},{"title":"Leetcode 2347. Best Poker Hand","slug":"Leetcode 2349","date":"2023-02-20T02:40:05.000Z","updated":"2023-02-20T01:02:35.144Z","comments":true,"path":"2023/02/20/Leetcode 2349/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/20/Leetcode%202349/","excerpt":"","text":"The problem description can be found at the link My solution: 123456789101112131415161718192021222324252627282930class Solution {public: bool isFlush(vector&lt;int&gt;&amp; ranks, vector&lt;char&gt;&amp; suits){ for(int i = 0; i + 1 &lt; suits.size(); ++i){ if(suits[i] != suits[i + 1]) return false; } return true; } int checkType(vector&lt;int&gt;&amp; ranks, vector&lt;char&gt;&amp; suits){ map&lt;int, int&gt; m; int ans = 0; for(auto x: ranks){ m[x]++; ans = max(ans, m[x]); } return ans; } string bestHand(vector&lt;int&gt;&amp; ranks, vector&lt;char&gt;&amp; suits) { if(isFlush(ranks, suits)) return \"Flush\"; int type = checkType(ranks, suits); //cout&lt;&lt;type&lt;&lt;endl; switch(type){ case 4: return \"Three of a Kind\"; case 3: return \"Three of a Kind\"; case 2: return \"Pair\"; case 1: return \"High Card\"; default: return \"none\"; } }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"},{"name":"easy level","slug":"easy-level","permalink":"http://yourthomaslee.github.io/tags/easy-level/"}]},{"title":"Leetcode 1792. Maximum Average Pass Ratio","slug":"Leetcode 1729","date":"2023-02-19T02:40:05.000Z","updated":"2023-02-22T01:28:07.510Z","comments":true,"path":"2023/02/19/Leetcode 1729/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/19/Leetcode%201729/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314151617181920212223242526class Solution {public: double maxAverageRatio(vector&lt;vector&lt;int&gt;&gt;&amp; classes, int extraStudents) { priority_queue&lt;tuple&lt;double, int, int&gt;&gt; pq; for(auto&amp; e : classes) { int a = e[0], b = e[1]; double x = (double) (a + 1) / (b + 1) - (double) a / b; pq.push({x, a, b}); } while (extraStudents--) { auto [_, a, b] = pq.top(); pq.pop(); a++; b++; double x = (double) (a + 1) / (b + 1) - (double) a / b; pq.push({x, a, b}); } double ans = 0; while (pq.size()) { auto [_, a, b] = pq.top(); pq.pop(); ans += (double) a / b; } return ans / classes.size(); }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"interesting problem","slug":"interesting-problem","permalink":"http://yourthomaslee.github.io/tags/interesting-problem/"},{"name":"priority_queue","slug":"priority-queue","permalink":"http://yourthomaslee.github.io/tags/priority-queue/"}]},{"title":"Computational advertising 2 - 1 feature engineering","slug":"Computional advertising 2 - 1 feature extraction","date":"2023-02-18T14:40:05.000Z","updated":"2023-02-18T15:14:08.740Z","comments":true,"path":"2023/02/18/Computional advertising 2 - 1 feature extraction/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/18/Computional%20advertising%202%20-%201%20feature%20extraction/","excerpt":"","text":"本部分将说明如何找到并抽取有用的特征","categories":[],"tags":[{"name":"computational advertising","slug":"computational-advertising","permalink":"http://yourthomaslee.github.io/tags/computational-advertising/"},{"name":"feature engineering","slug":"feature-engineering","permalink":"http://yourthomaslee.github.io/tags/feature-engineering/"}]},{"title":"Leetcode 1237. Find Positive Integer Solution for a Given Equation","slug":"Leetcode 1237","date":"2023-02-18T02:40:05.000Z","updated":"2023-02-20T01:07:30.600Z","comments":true,"path":"2023/02/18/Leetcode 1237/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/18/Leetcode%201237/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425262728class Solution {public: vector&lt;vector&lt;int&gt;&gt; findSolution(CustomFunction&amp; customfunction, int z) { vector&lt;vector&lt;int&gt;&gt; ans; list&lt;vector&lt;int&gt;&gt; l, n; set&lt;vector&lt;int&gt;&gt; visited; l.push_back(vector&lt;int&gt;{1, 1}); while(l.size() &gt; 0){ n.clear(); for(auto x: l){ if(visited.find(x) != visited.end()) continue; else visited.insert(x); int val = customfunction.f(x[0], x[1]); if(val &lt; z){ n.push_back(vector&lt;int&gt;{x[0] + 1, x[1]}); n.push_back(vector&lt;int&gt;{x[0], x[1] + 1}); } else if(val == z){ ans.emplace_back(x); } } l.clear(); l = n; } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"breath-first-search","slug":"breath-first-search","permalink":"http://yourthomaslee.github.io/tags/breath-first-search/"}]},{"title":"Computational advertising 2 - Recall models","slug":"Computional advertising 2 - 2 Recall models","date":"2023-02-17T14:40:05.000Z","updated":"2023-02-21T15:29:55.993Z","comments":true,"path":"2023/02/17/Computional advertising 2 - 2 Recall models/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/17/Computional%20advertising%202%20-%202%20Recall%20models/","excerpt":"","text":"[TOC] 1. 召回层 召回层的主要目标时从推荐池中选取几千上万的item，送给后续的排序模块。由于召回面对的候选集十分大，且一般需要在线输出，故召回模块必须轻量快速低延迟。由于后续还有排序模块作为保障，召回不需要十分准确，但不可遗漏（特别是搜索系统中的召回模块）。 如果没有召回层，每个User都能和每一个Item去在线排序阶段预测目标概率，理论上来说是效果最好，但是是不现实的，线上不延迟允许，所以召回和粗排阶段就要做一些候选集筛选的工作，保证在有限的能够给到排序层去做精排的候选集的时间里，效果最大化。另一个方面就是通过这种模型级联的方式，可以减少用排序阶段拟合多目标的压力，比如召回阶段我们现在主要是在保证Item质量的基础上注重覆盖率多样性，粗排阶段主要用简单的模型来解决不同路的召回和当前用户的相关性问题，最后截断到1k个以内的候选集，这个候选集符合一定的个性化相关性、视频质量和多样性的保证，然后做ranking去做复杂模型的predict。 1.1 召回技术的分类 目前基本上采用多路召回解决范式，分为非个性化召回和个性化召回。个性化召回又有content-based、behavior-based、feature-based等多种方式。 召回主要考虑的内容有： 考虑用户层面：用户兴趣的多元化，用户需求与场景的多元化：例如：新闻需求，重大要闻，相关内容沉浸阅读等等 考虑系统层面：增强系统的鲁棒性；部分召回失效，其余召回队列兜底不会导致整个召回层失效；排序层失效，召回队列兜底不会导致整个推荐系统失效 系统多样性内容分发：图文、视频、小视频；精准、试探、时效一定比例；召回目标的多元化，例如：相关性，沉浸时长，时效性，特色内容等等 可解释性推荐一部分召回是有明确推荐理由的：很好的解决产品性数据的引入； 从策略上说，一般可以分为三种![image.png](/Users/thomaslee/Desktop/人工智能应用/2. 搜推广系统架构/assets/image-20220927100212-71gng0e.png) 推荐系统的核心是感知用户的兴趣，在召回模块上，可以通过如何建模兴趣来对现有的技术进行归纳和总结。 非个性化： 热门召回：热门、高分、好评、高赞等 高效率召回：高CTR、高完播、高人均时长 运营策略：榜单、片单、最新上架等 个性化召回 基于内容或用户标签进行召回 标签召回：演员、导演、标签、类目等等 知识图谱：构建内容之间的联系 多模态理解：标题理解、首图理解、视频理解 基于交互： User-based: u2u2i Item-based: slim, swing 基于特征和向量 线性模型： FM、FFM 深度模型： DNN: DSSM双塔(EBR, MOBIUS), youtubeDNN 序列模型：Mind, SDM, CMDM, BERT4Rec 图模型： DeepWalk, Node2Vec, EGES, PingSage(GraphSage) 基于社交关系链：好友点赞、通信录好友、关注关系等 1.2 召回模型的评估 评估一个召回模型有如下角度 召回率：在模型召回预测的物品中，预测准确的物品占用户实际喜欢的物品的比例。对用户 u 推荐 N 个物品记为 R(u), 令用户 u 在测试集上喜欢的物品集合为， 那么召回率定义为： 精确率：推荐的物品中，对用户准确推荐的物品占总推荐物品的比例。精确率定义为： 。如要确保召回率高，一般是推荐更多的物品，期望推荐的物品中会涵盖用户喜爱的物品。而实际中，推荐的物品中用户实际喜爱的物品占少数，推荐的精确率就会很低。故同时要确保高召回率和精确率往往是矛盾的，所以实际中需要在二者之间进行权衡。 新颖度：用推荐列表中物品的平均流行度度量推荐结果的新颖度。 如果推荐出的物品都很热门， 说明推荐的新颖度较低。 由于物品的流行度分布呈长尾分布， 所以为了流行度的平均值更加稳定， 在计算平均流行度时对每个物品的流行度取对数。可以参考O’scar Celma 的博士论文 \"Music Recommendation and Discovery in the Long Tail \" 覆盖率：推荐系统能够推荐出来的物品占总物品集合的比例。覆盖率反映了推荐算法发掘长尾的能力， 覆盖率越高， 说明推荐算法越能将长尾中的物品推荐给用户。 ，其中 |I| 表示所有物品的个数；系统的用户集合为; 推荐系统给每个用户推荐一个长度为 N 的物品列表. 覆盖率表示最终的推荐列表中包含多大比例的物品。如果所有物品都被给推荐给至少一个用户， 那么覆盖率是100%。 1.3 召回模型的训练问题 训练数据选择问题：一般会用“用户点击”实例做为正例，“曝光未点击”实例做为负例，来训练模型。也都是用“用户点击”实例做为正例，但是怎么选择负例，这里面有不少学问 Sample selection bias问题：我们先来看下不同阶段模型面对的输入数据情况，对于召回模型来说，它面临的输入数据，是所有物料库里的物品；对于粗排模型来说，它面对的输入数据，是各路召回的结果；对于精排模型来说，它面临的输入是粗排模型的输出结果。如果我们仍然用“曝光未点击”实例做为召回和粗排的负例训练数据，你会发现这个训练集合，只是全局物料库的一小部分，它的分布和全局物料库以及各路召回结果数据，这两个召回和粗排模型面临的实际输入数据，分布差异比较大，所以根据这种负例训练召回和粗排模型，效果如何就带有疑问，我们一般把这个现象称为“Sample Selection Bias”问题。可选的负例选择方法 曝光未点击数据：这个数据还是需要的，只是要和其它类型的负例选择方法，按照一定比例进行混合，来缓解Sample Selection Bias问题 全局随机选择负例：在原始的全局物料库里，随机抽取做为召回或者粗排的负例。从道理上讲，这个肯定是完全符合输入数据的分布一致性的，但是，一般这么选择的负例，因为和正例差异太大，导致模型太好区分正例和负例，所以模型能学到多少知识是成问题的。 Batch内随机选择负例：就是说只包含正例，训练的时候，在Batch内，选择除了正例之外的其它Item，做为负例。这个本质上是：给定用户，在所有其它用户的正例里进行随机选择，构造负例。 曝光数据随机选择负例：在给所有用户曝光的数据里，随机选择做为负例。这个我们测试过，在某些场景下是有效的。 基于Popularity随机选择负样例：全局随机选择，但是越是流行的Item，越大概率会被选择作为负例。目前不少研究证明了，负例采取Popularity-based方法，对于效果有明显的正面影响。它隐含的假设是：如果一个例子越流行，那么它没有被用户点过看过，说明更大概率，对当前的用户来说，它是一个真实的负例。同时，这种方法还会打压流行Item，增加模型个性化程度。 基于Hard选择负样例：它是选择那些比较难的例子，做为负例。因为难区分的例子，很明显给模型带来的loss和信息含量比价多，所以从道理上讲是很合理的。但是怎样算是难的例子，可能有不同的做法，有些还跟应用有关。 论文Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations iwtbs：借Youtube论文，谈谈双塔模型的八大精髓问题 训练模式： point-wise [Embedding-based retrieval in Facebook search]: 把召回看做简单的二分类任务{-1, +1}，控制正负样本比例为1：2或1：3 pair-wise [Sampling-bias-corrected neural model for large corpus item]：扩大正样本和负样本之间的距离。精简版的排序模型 list-wise：一个用户、一个正样本和多个负样本。鼓励正样本分数尽可能的大，负样本分数尽可能小。softmax函数产出预测，使用交叉熵损失函数 正负样本选择：50%负样本是全体物品，50%使没通过排序的物品 正样本：用户点击的物品。正样本中存在少部分物品占据大部分点击的问题，导致正样本大部分是热门物品，解决的方法之一是过采样冷门物品，降采样热门物品。 负样本 没有被召回的：从全体物品中抽样。负样本抽样概率公式打压热门程度（,为点击次数） batch内负样本：所有样本都是正样本，正样本做其他人的负样本。存在热门样本过多次成为负样本，过度打压热门样本。修正方式为训练相似度计算为其中概率与点击次数正相关 召回但是被粗排、精排淘汰的： 被粗排淘汰的物品（比较困难） 精排分数靠后的物品（非常困难） 曝光但是未点击的：不适合用作召回负样本，只适合用作排序训练样本。根本原因在于它不能界定用户是否感兴趣的标志，不点击也可能有兴趣。 线上更新：增量更新可能有偏差，另外样本按时间顺序到来，容易损害模型的泛华能力（陷入局部最优然后跳不出来？）全量更新打乱一天的数据进行训练效果更好。 全量更新：基于已有的模型在新的数据上跑一个epoch更新所有参数，包括用户和物品的embedding、网络的参数等等。 增量更新：最近一小时的数据，只用来更新embedding，网络参数锁定 2. 基于交互的召回模型 基于交互行为的召回模型主要分为两种，userCF和itemCF两种，二种都是通过行为来捕捉相似性。userCF先要找到与user1行为相似的user2，选取user2行为序列中user1没有见过的item作为候选结果; itemCF则找到与item交互的user集合作为向量去计算item间的相似度。相似性常见的度量方法有： 杰卡德相似系数：Jaccard 系数是衡量两个集合的相似度一种指标，计算公式如下： ，其中 N(u)， 分别表示用户 u 和用户 v 交互物品的集合。对于用户 u 和 v ，该公式反映了两个交互物品交集的数量占这两个用户交互物品并集的数量的比例。 余弦相似度：余弦相似度衡量了两个向量的夹角，夹角越小越相似。.设用户和物品数量分别为 m,n，交互矩阵就是一个 m 行 n 列的矩阵。矩阵中的元素均为 0/1。若用户 i 对物品 j 存在交互，那么 Ai,j=1，否则为 0 。那么，用户之间的相似度可以表示为： 皮尔逊相关系数：在用户之间的余弦相似度计算时，将用户向量的内积展开为各元素乘积和： ，其中， 分别表示用户 u 和用户 v 对物品 i 是否有交互(或具体评分值)。皮尔逊相关系数与余弦相似度的计算公式非常的类似，如下： ，其中， 分别表示用户 u 和用户 v 对物品 i 是否有交互(或具体评分值)； 分别表示用户 u 和用户 v 交互的所有物品交互数量或者评分的平均值； 以上相似度可以适用的场景 Jaccard 相似度表示两个集合的交集元素个数在并集中所占的比例 ，所以适用于隐式反馈数据（0-1）。 余弦相似度在度量文本相似度、用户相似度、物品相似度的时候都较为常用。 皮尔逊相关度，实际上也是一种余弦相似度。不过先对向量做了中心化，范围在−1到1。相关度量的是两个变量的变化趋势是否一致，两个随机变量是不是同增同减。不适合用作计算布尔值向量（0-1）之间相关度。 以下具体看各种不同类型的CF UCF：思路是找到相似用户对不同物品的喜好，并加权得到物品的分数$\\sum_{u_j} sim(u_i, u_j) Like(u_j, item)\\sim(u_i, u_j) = \\frac{|I_i \\cap I_j|}{\\sqrt {|I_i||I_j|}}\\ sim(u_i, u_j) = \\frac{\\sum_{i\\in {I_i \\cap I_j}\\frac{1}{log{(1 + n_i)}}}}{\\sqrt {|I_i||I_j|}}[n_l\\text{为物品热度系数， 打压热门物品对相似度贡献]}$ 其中为用户对物品的评分。 ICF：如果喜欢两个item的受众重叠较大，那么相似度大(集合). , 为喜欢物品的用户集合 热门物品打压：，调节参数用来调整热门物品的打压力度 活跃用户的惩罚：对于异常活跃的用户，在计算物品之间的相似度时，在召回处的影响会被扩大必须被校正，。 Swing：两个物品的相似度由喜欢物品的用户之间的相似度来衡量 为同时喜欢两个物品的用户集合. 表示用户喜欢的物品集合。surprise算法是基于交互数据的聚类方法解决数据稀疏的问题，旨在帮助用户找到互补商品。互补相关性主要从三个层面考虑，类别层面，商品层面和聚类层面。具体可以参考link Matrix factorization(MF): 利用矩阵乘法构建两个embedding，具体信息可以参照link 二者比较： userCF需要user行为较为丰富，itemCF则需要item被交互行为比较丰富，所以对于新闻类等item实时性要求高的场景，由于冷启item很多，会偏向考虑userCF 多数情况下user量大于推荐池的item数量，也就是userCF的存储压力和向量检索压力要大于itemCF，同时user向量要比item向量稀疏，相似度计算准确性不如itemCF 协同过滤算法的缺点： 大部分user只对很少一部分item有行为，导致user和item的行为矩阵系数，相似度计算不准确 user和item量巨大，存储压力较大 交互不足导致item向量的个性化可能不足，热门item和大多数item都相似，导致马太效应 3. 基于特征的召回 基于特征的召回模型回转到利用各个维度的特征建模物品和点击之间的关系，对于这类模型，可以分为线性模型和深度模型。线性模型主要包含逻辑回归、因子分解机等。 3.1 线性模型 3.1.1 逻辑回归 逻辑回归模型相关的知识参见机器学习知识分类下的模型章节 3.1.2 因子分解机 (factorization machine, FM) FM 模型的公式定义如下： $$ \\hat{y}(\\mathbf{x}):=w_{0}+\\sum_{i=1}^{n} w_{i} x_{i}+\\sum_{i=1}^{n} \\sum_{j=i+1}^{n}\\left\\langle\\mathbf{v}{i}, \\mathbf{v}{j}\\right\\rangle x_{i} x_{j} $$ 其中，表示特征的序号，表示特征的数量；表示第 个特征的值。分别表示特征 对应的隐语义向量（Embedding向量）， $\\left\\langle\\mathbf{v}{i}, \\mathbf{v}{j}\\right\\rangle:=\\sum_{f=1}^{k} v_{i, f} \\cdot v_{j, f}；w_0,w_i\\in \\mathbb{R}$ 均表示需要学习的参数。 在 FM 的表达式中，前两项为特征的一阶交互项。将其拆分为用户特征和物品特征的一阶特征交互项，如下： 其中， 表示用户相关特征集合，表示物品相关特征集合。 观察 FM 的二阶特征交互项，可知其计算复杂度为 。为了降低计算复杂度，按照如下公式进行变换。 $$ \\begin{aligned} &amp; \\sum_{i=1}^{n} \\sum_{j=i+1}^{n}\\left\\langle\\mathbf{v}{i}, \\mathbf{v}{j}\\right\\rangle x_{i} x_{j} \\ =&amp; \\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n}\\left\\langle\\mathbf{v}{i}, \\mathbf{v}{j}\\right\\rangle x_{i} x_{j}-\\frac{1}{2} \\sum_{i=1}^{n}\\left\\langle\\mathbf{v}{i}, \\mathbf{v}{i}\\right\\rangle x_{i} x_{i} \\ =&amp; \\frac{1}{2}\\left(\\sum_{i=1}^{n} \\sum_{j=1}^{n} \\sum_{f=1}^{k} v_{i, f} v_{j, f} x_{i} x_{j}-\\sum_{i=1}^{n} \\sum_{f=1}^{k} v_{i, f} v_{i, f} x_{i} x_{i}\\right) \\ =&amp; \\frac{1}{2} \\sum_{f=1}^{k}\\left(\\left(\\sum_{i=1}^{n} v_{i, f} x_{i}\\right)^{}\\left(\\sum_{j=1}^{n} v_{j, f} x_{j}\\right)-\\sum_{i=1}^{n} v_{i, f}^{2} x_{i}^{2}\\right) \\ =&amp; \\frac{1}{2} \\sum_{f=1}^{k}\\left(\\left(\\sum_{i=1}^{n} v_{i, f} x_{i}\\right)^{2}-\\sum_{i=1}^{n} v_{i, f}^{2} x_{i}^{2}\\right) \\end{aligned} 公式变换后，计算复杂度由降到。由于需要将模型用在召回，故将二阶特征交互项拆分为用户和物品项。有： $$ 其中， 表示用户相关特征集合，表示物品相关特征集合。 基于 FM 召回，我们可以将 $\\hat{y}(\\mathbf{x}):=w_{0}+\\sum_{i=1}^{n} w_{i} x_{i}+\\sum_{i=1}^{n} \\sum_{j=i+1}^{n}\\left\\langle\\mathbf{v}{i}, \\mathbf{v}{j}\\right\\rangle x_{i} x_{j}$作为用户和物品之间的匹配分。 FM 用于召回 对于 FM 的一阶、二阶特征交互项，已将其拆分为用户项和物品项。 对于同一用户，即便其与不同物品进行交互，但用户特征内部之间的一阶、二阶交互项得分都是相同的。 这就意味着，在比较用户与不同物品之间的匹配分时，只需要比较：（1）物品内部之间的特征交互得分；（2）用户和物品之间的特征交互得分。 FM 的一阶特征交互 将全局偏置和用户一阶特征交互项进行丢弃，有： 一阶 FM 的二阶特征交互 将用户特征内部的特征交互项进行丢弃，有： 二阶 合并 FM 的一阶、二阶特征交互项，得到基于 FM 召回的匹配分计算公式： $$ \\text{MatchScore}{FM} = \\sum{t \\in I} w_{t} x_{t} + \\frac{1}{2} \\sum_{f=1}^{k}\\left(\\left(\\sum_{t \\in I} v_{t, f} x_{t}\\right)^{2} - \\sum_{t \\in I} v_{t, f}^{2} x_{t}^{2}\\right) + \\sum_{f=1}^{k}\\left( {\\sum_{u \\in U} v_{u, f} x_{u}}{\\sum_{t \\in I} v_{t, f} x_{t}} \\right) $$ 在基于向量的召回模型中，为了 ANN（近似最近邻算法） 或 Faiss 加速查找与用户兴趣度匹配的物品。基于向量的召回模型，一般最后都会得到用户和物品的特征向量表示，然后通过向量之间的内积或者余弦相似度表示用户对物品的兴趣程度。 基于 FM 模型的召回算法，也是向量召回算法的一种。所以下面，将 $\\text{MatchScore}{FM}化简为用户向量和物品向量的内积形式，如下：$ \\text{MatchScore}{FM} = V_{item} V_{user}^T $$ 用户向量： 用户向量由两项表达式拼接得到。第一项为常数，第二项是将用户相关的特征向量进行 sum pooling 。 物品向量： 第一项表示物品相关特征向量的一阶、二阶特征交互。第二项是将物品相关的特征向量进行 sum pooling 。 FM的优缺点：工程成本低，上线快。由于候选集巨大，对于实时性的要求更高。很多高级的召回算法（e.g., 基于GNN的召回算法），由于计算复杂，无法线上实时生成user embedding，只能退而离线生成user embedding，不仅降低了用户覆盖率，而且对于用户实时兴趣的捕捉大打折扣。FM召回，只需要把一系列的feature embedding相加，就可以对任何用户在线生成最新的user embedding，从而可以基于用户最新的兴趣，从千万量级候选item中完成实时召回。 参考资料 [1] 美团技术团队, 深入FFM原理与实践, 2016 [2] 大规模FM模型, AlphaFM, 2021 [3] FM原始论文, Factorization Machine, 2010 [4] 知乎推荐算法瑞士军刀, 因子分解机, 2021 3.2 深度模型 深度模型中，经典的模型有item2vec召回、Youtube DNN召回、双塔召回、图召回、序列召回、树模型召回等等 3.2.1 item2vec召回 3.2.1.1 基础item2vec召回 Item2Vec 的原理十分十分简单，它是基于 Skip-Gram 模型的物品向量训练方法(word2vec参见自然语言处理章节相关内容)，但又存在一些区别，如下： 词向量的训练是基于句子序列（sequence），但是物品向量的训练是基于物品集合（set）。 因此，物品向量的训练丢弃了空间、时间信息。 Item2Vec 论文假设对于一个集合的物品，它们之间是相似的，与用户购买它们的顺序、时间无关。当然，该假设在其他场景下不一定使用，但是原论文只讨论了该场景下它们实验的有效性。由于忽略了空间信息，原文将共享同一集合的每对物品视为正样本。目标函数如下： , 对于窗口大小 K，由设置的决定。 在 Skip-Gram 模型中，提到过每个单词 有2个特征表示。在 Item2Vec 中同样如此，论文中是将物品的中心词向量 ui 作为物品的特征向量。作者还提到了其他两种方式来表示物品向量：add：; concat：. 论文： 1603.04259 Item2Vec: Neural Item Embedding for Collaborative Filtering 3.2.1.2 Airbnb召回方案 Airbnb 于2018年发表了一篇论文，主要介绍了 Airbnb 在 Embedding 技术上的应用，并获得了 KDD 2018 的 Best Paper。相应的思路是基于点击序列去学习一个embedding并用与召回和排序 房源Embeddings 是基于用户的点击 session 学习得到的，用于表示房源的短期实时性特征。给定数据集 ，其中包含了 个用户的 个点击 session（序列）。 每个 session ，包含了 个被用户点击过的 listing ids 。 对于用户连续两次点击，若时间间隔超过了30分钟，则启动新的 session。 在拿到多个用户点击的 session 后，可以基于 Word2Vec 的 Skip-Gram 模型来学习不同 listing 的 Embedding 表示。最大化目标函数 ： 概率 是基于 soft-max 函数的表达式。表示在一个 session 中，已知中心 listing 来预测上下文 listing 的概率： $$ \\mathbb{P}\\left(l_{i+j} \\mid l_{i}\\right)=\\frac{\\exp \\left(\\mathbf{v}{l{i}}^{\\top} \\mathbf{v}{l{i+j}}^{\\prime}\\right)}{\\sum_{l=1}^{|\\mathcal{V}|} \\exp \\left(\\mathbf{v}{l{i}}^{\\top} \\mathbf{v}_{l}^{\\prime}\\right)} $$ 其中， $ \\mathbf{v}{l{i}} 表示 l_i 的向量， |\\mathcal{V}| $ 表示全部的物料库的数量。 考虑到物料库 过大，模型中参数更新的时间成本和 成正比。为了降低计算复杂度，要进行负采样。负采样后，优化的目标函数如下： $$ \\underset{\\theta}{\\operatorname{argmax}} \\sum_{(l, c) \\in \\mathcal{D}{p}} \\log \\frac{1}{1+e^{-\\mathbf{v}{c}^{\\prime^{\\prime}} \\mathbf{v}{l}}}+\\sum{(l, c) \\in \\mathcal{D}{n}} \\log \\frac{1}{1+e^{\\mathbf{v}{c}^{\\prime} \\mathbf{v}_{l}}} $$​ 至此，对 Skip-Gram 模型和 NEG 了解的同学肯定很熟悉，上述方法和 Word2Vec 思想基本一致。 下面，将进一步介绍 Airbnb 是如何改进 Listing Embedding 的学习以及其他方面的应用。 （1）正负样本集构建的改进：使用 booked listing 作为全局上下文 booked listing 表示用户在 session 中最终预定的房源，一般只会出现在结束的 session 中。 Airbnb 将最终预定的房源，始终作为滑窗的上下文，即全局上下文。如下图：如图，对于当前滑动窗口的 central listing，实线箭头表示context listings，虚线（指向booked listing）表示 global context listing。 booked listing 作为全局正样本，故优化的目标函数更新为： $\\underset{\\theta}{\\operatorname{argmax}} \\sum_{(l, c) \\in \\mathcal{D}_p} \\log \\frac{1}{1+e^{-\\mathbf{v}c^{\\prime} \\mathbf{v} l}}+\\sum{(l, c) \\in \\mathcal{D}_n} \\log \\frac{1}{1+e^{\\mathbf{v}_c^{\\prime} \\mathbf{v} l}}+\\log \\frac{1}{1+e^{-\\mathbf{v}_c^{\\prime} \\mathbf{v}_b}}$ 优化负样本的选择 用户通过在线网站预定房间时，通常只会在同一个 market （将要停留区域）内进行搜索。 对于用户点击过的样本集 $ \\mathcal{D}{p} （正样本集）而言，它们大概率位于同一片区域。考虑到负样本集 \\mathcal{D}{n} $ 是随机抽取的，大概率来源不同的区域。 Airbnb 发现这种样本的不平衡，在学习同一片区域房源的 Embedding 时会得到次优解。 解决办法也很简单，对于每个滑窗中的中心 lisitng，其负样本的选择新增了与其位于同一个 market 的 listing。至此，优化函数更新如下： $$ \\underset{\\theta}{\\operatorname{argmax}} \\sum_{(l, c) \\in \\mathcal{D}{p}} \\log \\frac{1}{1+e^{-\\mathbf{v}{c}^{\\prime^{\\prime}} \\mathbf{v}{l}}}+\\sum{(l, c) \\in \\mathcal{D}{n}} \\log \\frac{1}{1+e^{\\mathbf{v}{c}^{\\prime} \\mathbf{v}{l}}} +\\log \\frac{1}{1+e^{-\\mathbf{v}{c}^{\\prime} \\mathbf{v}{l_b}}} + \\sum{(l, m_n ) \\in \\mathcal{D}{m_n}} \\log \\frac{1}{1+e^{\\mathbf{v}{m_n}^{\\prime} \\mathbf{v}_{l}}} $$ 表示与滑窗中的中心 listing 位于同一区域的负样本集。 （2）listing (房源) Embedding 的冷启动 Airbnb 每天都有新的 listings 产生，而这些 listings 却没有 Embedding 向量表征。 Airbnb 建议利用其他 listing 的现有的 Embedding 来为新的 listing 创建 Embedding。 在新的 listing 被创建后，房主需要提供如位置、价格、类型等在内的信息。 然后利用房主提供的房源信息，为其查找3个相似的 listing，并将它们 Embedding 的均值作为新 listing 的 Embedding表示。 这里的相似，包含了位置最近（10英里半径内），房源类型相似，价格区间相近。 通过该手段，Airbnb 可以解决 98% 以上的新 listing 的 Embedding 冷启动问题。 （3）Listing Embedding 的评估 经过上述的两点对 Embedding 的改进后，为了评估改进后 listing Embedding 的效果。Airbnb 使用了800万的点击 session，并将 Embedding 的维度设为32。评估方法包括：评估 Embedding 是否包含 listing 的地理位置相似性。 理论上，同一区域的房源相似性应该更高，不同区域房源相似性更低。 Airbnb 利用 k-means 聚类，将加利福尼亚州的房源聚成100个集群，来验证类似位置的房源是否聚集在一起。 评估不同类型、价格区间的房源之间的相似性。简而言之，我们希望类型相同、价格区间一致的房源它们之间的相似度更高。 评估房源的隐式特征 Airbnb 在训练房源（listing）的 Embedding时，并没有用到房源的图像信息。对于一些隐式信息，例如架构、风格、观感等是无法直接学习。 为了验证基于 Word2Vec 学习到的 Embedding是否隐含了它们在外观等隐式信息上的相似性，Airbnb 内部开发了一款内部相似性探索工具。大致原理就是，利用训练好的 Embedding 进行 K 近邻相似度检索。 论文：https://dl.acm.org/doi/pdf/10.1145/3219819.3219885 相应学习笔记：https://github.com/datawhalechina/fun-rec/blob/master/docs/ch02/ch2.1/ch2.1.2/Airbnb.md 3.2.3 双塔召回 双塔模型在推荐领域中是一个十分经典的模型，无论是在召回还是粗排阶段，都会是首选。这主要是得益于双塔模型结构，使得能够在线预估时满足低延时的要求。但也是因为其模型结构的问题，使得无法考虑到user和item特之间的特征交叉，使得影响模型最终效果，因此很多工作尝试调整经典双塔模型结构，在保持在线预估低延时的同时，保证双塔两侧之间有效的信息交叉。 速度快：离线构图 + 最近邻检索。可以离线将所有的Item通过Item塔得到其向量，并将Item向量保存在FAISS中。而双塔模型速度快就是因为其能离线将item向量保存在FAISS这样的ANN（Approximate Nearest Neighbor Search）框架中 在Google的双塔召回模型中，重点介绍了两个trick，将user和item侧输出的embedding进行归一化以及对于內积值除以温度系数，实验证明这两种方式可以取得十分好的效果。 余弦相似度： 欧氏距离会随著维度增加而增大。如果使用余弦相似度的话，数值上会保持在-1到1之间，正交时为0，方向相反时候为-1 最后一层L2 normalization: cosine相似度（距离）并不保证传递性，加上归一化后可以将结果映射到欧式空间，保证训练检索的一致性（加强了训练目标）[缺点是缩小了梯度，使得收敛几乎不可能] 和归一化几乎绑定的temperature：如果一个人做过双塔模型，又使用了归一化操作，他一定知道没有temperature模型几乎收敛不了。对 logits 除上一个 temperature 系数的作用是扩大 logits 中每个元素中的上下限, 拉回 softmax 运算的敏感范围。 下面针对于经典双塔模型以及一些改进版本进行介绍。 3.2.3.1 DSSM(Deep Structured Semantic Model)召回 DSSM(Deep Structured Semantic Model)是由微软研究院于CIKM在2013年提出的一篇工作，该模型主要用来解决NLP领域语义相似度任务 ，利用深度神经网络将文本表示为低维度的向量，用来提升搜索场景下文档和query匹配的问题。DSSM 模型的原理主要是：通过用户搜索行为中query 和 doc 的日志数据，通过深度学习网络将query和doc映射到到共同维度的语义空间中，通过最大化query和doc语义向量之 间的余弦相似度，从而训练得到隐含语义模型，即 query 侧特征的 embedding 和 doc 侧特征的 embedding，进而可以获取语句的低维 语义向量表达 sentence embedding，可以预测两句话的语义相似度。模型结构如下所示： 最大的特点就是「user和item是独立的两个子网络」，「User特征」主要包括和用户相关的特征：用户id、手机系统、地域、年龄、历史行为序列等。**「Item特征」**主要包括和Item相关的特征：ItemId、Item类别、Item来源等 近邻快速查找算法： 聚类：聚类边缘的点的最近邻往往会包括相邻聚类的点，如果我们只在类别内搜索，就会遗漏这些近似点。聚类数目的设置需要考究 线性扫描: 逐一对比 KDTree: 二叉树，核心思想是对K维特征空间不断以中值递归切分构造树，每一个节点是一个超矩形，小于节点的样本划分到左子树，大于节点的样本划分到右子树（维数小于20时效率最高，空间维度接近训练实例数效率迅速下降），无法完全解决边缘点 BallTree：在一系列嵌套的超球面上分割数据，即使用超球面而不是超矩形划分区域。在构建数据结构的花费上大过于KDtree，但是在高维甚至很高维的数据上都表现的很高效 Annoy：同样通过建立一个二叉树来使得每个点查找时间复杂度是O(log n)，和kd树不同的是，annoy没有对k维特征进行切分，Annoy的每一次空间划分，可以看作聚类数为2的KMeans过程 NSW(Navigable small world graphs): 基于图存储的数据结构，当我想查找与粉色点最近的一点时，我从任意一个黑色点出发，计算它和粉色点的距离，与这个任意黑色点有连接关系的点我们称之为“友点”（直译），然后我要计算这个黑色点的所有“友点”与粉色点的距离，从所有“友点”中选出与粉色点最近的一个点，把这个点作为下一个进入点，继续按照上面的步骤查找下去。如果当前黑色点对粉色点的距离比所有“友点”都近，终止查找，这个黑色点就是我们要找的离粉色点最近的点 ​ 缺陷： 孤点无法被找到-&gt;所有数据向量节点都必须有友点 近点必须有连线-&gt;所有距离相近（相似）到一定程度的向量必须互为友点 友点数目要控制-&gt;尽量减少每个节点的“友点”数量 HNSW：加入了跳表结构做了进一步优化。最底层是所有数据点，每一个点都有50%概率进入上一层的有序链表。这样可以保证表层是“高速通道”，底层是精细查找。 如果有兴趣深入学习可以参考： https://github.com/facebookresearch/faiss 3.2.3.2 Youtube DNN召回 YouTubeDNN模型是2016年的一篇文章，虽然离着现在有些久远， 但这篇文章无疑是工业界论文的典范， 完全是从工业界的角度去思考如何去做好一个推荐系统，并且处处是YouTube工程师留给我们的宝贵经验。 召回模型的目的是在大量YouTube视频中检索出数百个和用户相关的视频来。这个问题，我们可以看成一个多分类的问题，即用户在某一个时刻点击了某个视频， 可以建模成输入一个用户向量， 从海量视频中预测出被点击的那个视频的概率。 换成比较准确的数学语言描述， 在时刻下， 用户在背景下对每个视频的观看行为建模成下面的公式： 这里的表示用户向量， 这里的表示视频向量， 两者的维度都是， 召回模型的任务，就是通过用户的历史点击和山下文特征， 去学习最终的用户表示向量以及视频的表示向量， 不过这俩还有个区别是本身就是模型参数， 而是神经网络的输出(函数输出)，是输入与模型参数的计算结果。 对应笔记：link 3.2.3.3 SENet召回 SENet由Momenta在2017年提出，当时是一种应用于图像处理的新型网络结构。后来张俊林将SENet引入了精排模型FiBiNET中，其作用是为了将大量长尾的低频特征抛弃，弱化不靠谱低频特征embedding的负面影响，强化高频特征的重要作用。 从上图可以看出SENET主要分为三个步骤Squeeze, Excitation, Re-weight： Squeeze阶段：我们对每个特征的Embedding向量进行数据压缩与信息汇总，即在Embedding维度计算均值：, 其中k表示Embedding的维度，Squeeze阶段是将每个特征的Squeeze转换成单一的数值。 Excitation阶段：这阶段是根据上一阶段得到的向量进行缩放，即将上阶段的得到的 的向量先压缩成长度，然后在映射回到 ，其中表示压缩的程度。这个过程的具体操作就是经过两层DNN。. 该过程可以理解为：对于当前所有输入的特征，通过相互发生关联，来动态地判断哪些特征重要，哪些特征不重要，而这体现在Excitation阶段的输出结果 A，其反应每个特征对应的重要性权重。 Re-weight阶段：是将Excitation阶段得到的每个特征对应的权重 A 再乘回到特征对应的Embedding里，就完成了对特征重要性的加权操作。 SENet模块在最底层就进行了特征的过滤，使得很多无效低频特征即使被过滤掉，这样更多有用的信息被保留到了双塔的最高层，使得两侧的交叉效果很好；同时由于SENet模块选择出更加重要的信息，使得User侧和Item侧特征之间的交互表达方面增强了DNN双塔的能力。 另外还可以通过增加通道的方式来增强两侧的信息交互。即对于user和item两侧不仅仅使用一个DNN结构，而是可以通过不同结构(如FM，DCN等)来建模user和item的自身特征交叉。这样对于user和item侧会得到多个embedding，类似于多兴趣的概念。通过得到的多个user和item的embedding，然后分别计算余弦值再相加(两侧的Embedding维度需要对齐)，进而增加了双塔两侧的信息交互。而这种方法在腾讯进行过尝试，他们提出的“并联”双塔就是按照这样的思路。 3.2.3.3 YoutubeTwoTower召回 文章核心思想 在大规模的推荐系统中，利用双塔模型对user-item对的交互关系进行建模，学习 ，user，context 向量与 item 向量. 针对大规模流数据，提出in-batch softmax损失函数与流数据频率估计方法(Streaming Frequency Estimation)，可以更好的适应item的多种数据分布。 文章主要贡献 提出了改进的流数据频率估计方法：针对流数据来估计item出现的频率，利用实验分析估计结果的偏差与方差，模拟实验证明该方法在数据动态变化时的功效 提出了双塔模型架构：提供了一个针对大规模的检索推荐系统，包括了 in-batch softmax 损失函数与流数据频率估计方法，减少了负采样在每个batch中可能会出现的采样偏差问题。 具体的流程 给定用户 x，基于 softmax 函数从物料库 M 中选中候选物品 y 的概率为： 考虑到相关奖励 ，加权对数似然函数的定义如下： 原表达式 中的分母需要遍历物料库中所有的物品，计算成本太高，故对分母中的物品要进行负采样。为了提高负采样的速度，一般是直接从训练样本所在 Batch 中进行负样本选择。于是有： $$ \\mathcal{P}{B}\\left(y{i} \\mid x_{i} ; \\theta\\right)=\\frac{e^{s\\left(x_{i}, y_{i}\\right)}}{\\sum_{j \\in[B]} e^{s\\left(x_{i}, y_{j}\\right)}} $$ 其中， 表示与样本 同在一个 Batch 的物品集合。举例来说，对于用户1，Batch 内其他用户的正样本是用户1的负样本。 一般而言，负采样分为 Easy Negative Sample 和 Hard Negative Sample。 这里的 Easy Negative Sample 一般是直接从全局物料库中随机选取的负样本，由于每个用户感兴趣的物品有限，而物料库又往往很大，故即便从物料库中随机选取负样本，也大概率是用户不感兴趣的。 在真实场景中，热门物品占据了绝大多数的购买点击。而这些热门物品往往只占据物料库物品的少部分，绝大部分物品是冷门物品。 在物料库中随机选择负样本，往往被选中的是冷门物品。这就会造成马太效应，热门物品更热，冷门物品更冷。 一种解决方式时，在对训练样本进行负采样时，提高热门物品被选为负样本的概率，工业界的经验做法是物品被选为负样本的概率正比于物品点击次数的 0.75 次幂。 前面提到 Batch 内进行负采样，热门物品出现在一个 Batch 的概率正比于它的点击次数。问题是，热门物品被选为负样本的概率过高了（一般正比于点击次数的 0.75 次幂），导致热门物品被过度打压。 在本文中，为了避免对热门物品进行过度惩罚，进行了纠偏。公式如下： 在内积 s(xi,yj) 的基础上，减去了物品 j 的采样概率的对数。 纠偏后，物品 y 被选中的概率为： $$ \\mathcal{P}{B}^{c}\\left(y{i} \\mid x_{i} ; \\theta\\right)=\\frac{e^{s^{c}\\left(x_{i}, y_{i}\\right)}}{e^{s^{c}\\left(x_{i}, y_{i}\\right)}+\\sum_{j \\in[B], j \\neq i} e^{s^{c}\\left(x_{i}, y_{j}\\right)}} $$ 此时，batch loss function 的表示式如下：$$ L_{B}(\\theta):=-\\frac{1}{B} \\sum_{i \\in[B]} r_{i} \\cdot \\log \\left(\\mathcal{P}{B}^{c}\\left(y{i} \\mid x_{i} ; \\theta\\right)\\right) $$ 通过 SGD 和学习率，来优化模型参数 θ ： Normalization and Temperature 最后一层，得到用户和物品的特征 Embedding 表示后，再进行进行 l2 归一化： $$ \\begin{aligned} u(x,\\theta) \\leftarrow u(x, \\theta) / |u(x, \\theta)| {2} v(y, \\theta) \\leftarrow v(y, \\theta) /|/v(y, \\theta)|{2}\\end{aligned} $$ 本质上，其实就是将用户和物品的向量内积转换为了余弦相似度。 对于内积的结果，再除以温度参数 τ： 论文提到，这样有利于提高预测准确度。 从实验结果来看，温度参数 τ 一般小于 1，所以感觉就是放大了内积结果。 具体的细节说明： link 3.2.4 图召回 推荐系统中User和Item相关的行为、需求、属性和社交信息具有天然的图结构，可以使用一张复杂的异构图来表示整个推荐系统。图神经网络模型推荐就是基于这个想法，把异构网络中包含的结构和语义信息编码到结点Embedding表示中，并使用得到向量进行个性化推荐。知识图谱其实是图神经网络的一个比较特殊的具体实例，但是，知识图谱因为编码的是静态知识，而不是用户比较直接的行为数据，和具体应用距离比较远，这可能是导致两者在推荐领域表现有差异的主要原因。 这方面典型的算法有：GraphSAGE、PinSage等。 3.2.4.1 Enhanced Graph Embedding with Side Information(EGES) 相关论文是阿里巴巴在2018年发表于KDD的关于召回阶段的工作，主要内容是基于图嵌入的方法上，通过引入side information来解决超大规模问题下的数据稀疏和冷启动问题。由于用户和项目的数十亿规模，传统的方法已经不能满足于实际的需求，主要的问题体现在三个方面： 可扩展性：现有的推荐方法无法扩展到在拥有十亿的用户和二十亿商品的淘宝中。 稀疏性：存在大量的物品与用户的交互行为稀疏。即用户的交互到多集中于以下部分商品，存在大量商品很少被用户交互。 冷启动：在淘宝中，每分钟会上传很多新的商品，由于这些商品没有用户行为的信息（点击、购买等），无法进行很好的预测。 文章通过用户的行为历史中构造一个item-item 图，然后应用随机游走方法在item-item 图为每个item获取到一个序列，然后通过Skip-Gram的方式为每个item学习embedding(这里的item序列类似于语句，其中每个item类比于句子中每个word)，这种方式被称为图嵌入方法(Graph Embedding)。 [1] *, Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba, 2018 [2] 学习笔记， link 3.2.4.2 PinSage 该论文是斯坦福大学和Pinterest公司与2018年联合发表与KDD上的一篇关于GCN成功应用于工业级推荐系统的工作。基于直推式学习的图卷积网络是通过拉普拉斯矩阵直接为图上的每个节点学习embedding表示，每次学习是针对于当前图上所有的节点。然而在实际的工业场景中，图中的结构和节点都不可能是固定的，会随着时间的变化而发生改变。在这样的场景中，直推式学习的方法就需要不断的重新训练才能够为新加入的节点学习embedding，导致在实际场景中无法投入使用。 在这样的背景下，斯坦福大学提出了一种归纳(inductive)学习的GCN方法——GraphSAGE，即通过聚合邻居信息的方式为给定的节点学习embedding。不同于直推式(transductive)学习，GraphSAGE是通过学习聚合节点邻居生成节点Embedding的函数的方式，为任意节点学习embedding，进而将GCN扩展成归纳学习任务。可以从公式的角度来理解GraphSAGE的具体操作 123&lt;div align=center&gt; &lt;img src=\"https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220423094435223.png\" style=\"zoom:90%;\"/&gt;&lt;/div&gt; 上面这个公式可以非常直观的让我们理解GraphSAGE的原理。 表示图上节点的初始化表示，等同于节点自身的特征。 表示第k层卷积后的节点表示，其来源于两个部分： 第一部分来源于节点v的邻居节点集合，利用邻居节点的第k-1层卷积后的特征进行 （ ）后，在进行线性变换。这里借助图上的边将邻居节点的信息通过边关系聚合到节点表示中(简称卷积操作)。 第二部分来源于节点v的第k-1成卷积后的特征，进行线性变换。总的来说图卷积的思想是在对自身做多次非线性变换时，同时利用边关系聚合邻居节点信息。 最后一次卷积结果作为节点的最终表示，以用于下游任务(节点分类，链路预测或节点召回)。 具体的embedding方法详见： link 3.2.5 序列召回 用户在使用 APP 或者网站的时候，一般会产生一些针对物品的行为，比如点击一些感兴趣的物品，收藏或者互动行为，或者是购买商品等。而一般用户之所以会对物品发生行为，往往意味着这些物品是符合用户兴趣的，而不同类型的行为，可能代表了不同程度的兴趣。比如购买就是比点击更能表征用户兴趣的行为。在召回阶段，如何根据用户行为序列打 embedding，可以采取有监督的模型，比如 Next Item Prediction 的预测方式即可；也可以采用无监督的方式，比如物品只要能打出 embedding，就能无监督集成用户行为序列内容，例如 Sum Pooling。这方面典型的算法有：CBOW、Skip-Gram、GRU、Bert等。 利用用户行为物品序列，打出用户兴趣 Embedding 的做法。但是，另外一个现实是：用户往往是多兴趣的，比如可能同时对娱乐、体育、收藏感兴趣。这些不同的兴趣也能从用户行为序列的物品构成上看出来，比如行为序列中大部分是娱乐类，一部分体育类，少部分收藏类等。那么能否把用户行为序列物品中，这种不同类型的用户兴趣细分，而不是都笼统地打到一个用户兴趣 Embedding 里呢？用户多兴趣拆分就是解决这类更细致刻画用户兴趣的方向。 本质上，把用户行为序列打到多个 embedding 上，实际它是个类似聚类的过程，就是把不同的 Item，聚类到不同的兴趣类别里去。目前常用的拆分用户兴趣 embedding 的方法，主要是胶囊网络和 Memory Network，但是理论上，很多类似聚类的方法应该都是有效的，所以完全可以在这块替换成你自己的能产生聚类效果的方法来做。 这方面典型的算法有：Multi-Interest Network with Dynamic Routing for Recommendation at Tmall等。 3.2.5.1 MIND 阿里团队2019年在CIKM上发的一篇paper，该模型依然是用在召回阶段的一个模型，解决的痛点是之前在召回阶段的模型，作者认为，用一个向量来表示用户的广泛兴趣未免有点太过于单一，论文使用胶囊网络的动态路由机制来做多兴趣的学习（门机制）. 参考link 3.2.5.2 Sequential Deep Matching Model(SDM) SDM是阿里团队在2019年CIKM上的一篇paper。和MIND模型一样，是一种序列召回模型，研究的依然是如何通过用户的历史行为序列去学习到用户的丰富兴趣。SDM模型，是先把用户的历史序列根据交互的时间分成了短期和长期两类，然后从短期会话和长期行为中分别采取相应的措施(短期的RNN+多头注意力， 长期的Att Net) 去学习到用户的短期兴趣和长期行为偏好，并巧妙的设计了一个门控网络有选择的将长短期兴趣进行融合，以此得到用户的最终兴趣向量。长短期兴趣融合门控机制： $$ G_{t}^{u}=\\operatorname{sigmoid}\\left(\\boldsymbol{W}^{1} \\boldsymbol{e}{u}+\\boldsymbol{W}^{2} s{t}^{u}+\\boldsymbol{W}^{3} \\boldsymbol{p}^{u}+b\\right) \\ o_{t}^{u}=\\left(1-G_{t}^{u}\\right) \\odot p^{u}+G_{t}^{u} \\odot s_{t}^{u} $$ 参考：link 3.2.6 树模型召回 协同过滤技术对于用户而言，只能通过他历史行为去构建候选集，并且会基于算力的局限做截断，推荐结果的多样性和新颖性比较局限。已有的方法不方便在用户和物品之间做特征组合，基于此阿里开发了一种可以承载各种深度模型来检索用户潜在兴趣的推荐算法解决方案。这个TDM模型是基于树结构，利用树结构对全量商品进行检索，将复杂度由O(N)下降到O(logN)。这个方法和层次softmax的方法一致，后续有空可以看看，个人感觉比较适合物品直接的关联逻辑比较明确的场景。 参考link","categories":[],"tags":[{"name":"computational advertising","slug":"computational-advertising","permalink":"http://yourthomaslee.github.io/tags/computational-advertising/"},{"name":"recall models","slug":"recall-models","permalink":"http://yourthomaslee.github.io/tags/recall-models/"}]},{"title":"Leetcode 1139. Largest 1-Bordered Square","slug":"Leetcode 1139","date":"2023-02-17T02:40:05.000Z","updated":"2023-02-20T01:09:01.567Z","comments":true,"path":"2023/02/17/Leetcode 1139/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/17/Leetcode%201139/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314151617181920212223242526272829303132333435class Solution {public: int f(int n){ if(n == 0) return 1; if(n == 1) return 4; else return n * 4 + f(n - 2); } int checkMax(vector&lt;vector&lt;vector&lt;int&gt; &gt; &gt;&amp; dp, int i, int j){ int ans = 0; cout&lt;&lt;i&lt;&lt;\" , \"&lt;&lt;j&lt;&lt;\" : \"&lt;&lt;min(dp[i][j][0],dp[i][j][1])&lt;&lt;endl; for(int k = 0; k &lt; min(dp[i][j][0],dp[i][j][1]); ++k){ //端点 if(dp[i - k][j][1] &gt; k &amp;&amp; dp[i][j - k][0] &gt; k) ans = k; } return ans; } int largest1BorderedSquare(vector&lt;vector&lt;int&gt;&gt;&amp; grid) { int r = grid.size(), c = grid[0].size(), ans = -1; vector&lt; vector&lt;vector&lt;int&gt; &gt; &gt; dp(r, vector&lt;vector&lt;int&gt; &gt;(c, vector&lt;int&gt;(2, 0))); for(int i = 0; i &lt; r; ++i){ for(int j = 0; j &lt; c; ++j){ dp[i][j][0] += grid[i][j]; dp[i][j][1] += grid[i][j]; if(i &gt; 0 &amp;&amp; dp[i][j][0]) dp[i][j][0] += dp[i - 1][j][0];//列 if(j &gt; 0 &amp;&amp; dp[i][j][1]) dp[i][j][1] += dp[i][j - 1][1];//行 if(dp[i][j][0] &amp;&amp; dp[i][j][1]){ ans = max(ans, checkMax(dp, i, j)); } } } if(ans &lt; 0) return 0; return f(ans); }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"dynamic programming","slug":"dynamic-programming","permalink":"http://yourthomaslee.github.io/tags/dynamic-programming/"}]},{"title":"Leetcode 2341. Maximum Number of Pairs in Array","slug":"Leetcode 2341","date":"2023-02-16T02:40:05.000Z","updated":"2023-02-20T01:03:17.135Z","comments":true,"path":"2023/02/16/Leetcode 2341/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/16/Leetcode%202341/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314151617class Solution {public: vector&lt;int&gt; numberOfPairs(vector&lt;int&gt;&amp; nums) { map&lt;int, int&gt; m; int ans = 0, s = 0; for(auto x: nums){ if(m.find(x) == m.end()) s++; m[x]++; if(m[x] == 2) { ans ++; m.erase(x); s--; } } return {ans, s}; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"},{"name":"easy level","slug":"easy-level","permalink":"http://yourthomaslee.github.io/tags/easy-level/"}]},{"title":"Machine learning foundation 1 - Part 7. Condition random field","slug":"Machine learning foundation 1.6 - condition random field","date":"2023-02-16T02:40:05.000Z","updated":"2023-02-10T16:35:02.755Z","comments":true,"path":"2023/02/16/Machine learning foundation 1.6 - condition random field/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/16/Machine%20learning%20foundation%201.6%20-%20condition%20random%20field/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 Outline","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"Condition random field","slug":"Condition-random-field","permalink":"http://yourthomaslee.github.io/tags/Condition-random-field/"}]},{"title":"Machine learning foundation 1 - Part 6. Markov chain","slug":"Machine learning foundation 1.5 - Markov chain","date":"2023-02-16T02:40:05.000Z","updated":"2023-02-10T16:34:32.488Z","comments":true,"path":"2023/02/16/Machine learning foundation 1.5 - Markov chain/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/16/Machine%20learning%20foundation%201.5%20-%20Markov%20chain/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 Outline","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"Markov chain","slug":"Markov-chain","permalink":"http://yourthomaslee.github.io/tags/Markov-chain/"}]},{"title":"Leetcode 1250. Check If It Is a Good Array","slug":"Leetcode 1250","date":"2023-02-15T02:40:05.000Z","updated":"2023-02-20T01:06:54.284Z","comments":true,"path":"2023/02/15/Leetcode 1250/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/15/Leetcode%201250/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314class Solution {public: bool isGoodArray(vector&lt;int&gt;&amp; nums) { int divisor = nums[0]; for (int num : nums) { divisor = gcd(divisor, num); if (divisor == 1) { break; } } return divisor == 1; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hard level","slug":"hard-level","permalink":"http://yourthomaslee.github.io/tags/hard-level/"},{"name":"number theory","slug":"number-theory","permalink":"http://yourthomaslee.github.io/tags/number-theory/"}]},{"title":"Leetcode 1124. Longest Well-Performing Interval","slug":"Leetcode 1124","date":"2023-02-14T02:40:05.000Z","updated":"2023-02-20T01:09:44.640Z","comments":true,"path":"2023/02/14/Leetcode 1124/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/14/Leetcode%201124/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425class Solution {public: int longestWPI(vector&lt;int&gt;&amp; hours) { int n = hours.size(); vector&lt;int&gt; s(n + 1); stack&lt;int&gt; stk; stk.push(0); for (int i = 1; i &lt;= n; i++) { s[i] = s[i - 1] + (hours[i - 1] &gt; 8 ? 1 : -1); if (s[stk.top()] &gt; s[i]) { stk.push(i); } } int res = 0; for (int r = n; r &gt;= 1; r--) { while (stk.size() &amp;&amp; s[stk.top()] &lt; s[r]) { res = max(res, r - stk.top()); stk.pop(); } } return res; }}; the explanation of solution can be found at link","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"greedy algorithm","slug":"greedy-algorithm","permalink":"http://yourthomaslee.github.io/tags/greedy-algorithm/"},{"name":"monotonic stack","slug":"monotonic-stack","permalink":"http://yourthomaslee.github.io/tags/monotonic-stack/"}]},{"title":"Machine learning foundation 2 - Part 1. data theory and model evaluation","slug":"Machine learning foundation 2.0 - data theory and model evaluation","date":"2023-02-13T03:40:05.000Z","updated":"2023-03-04T11:09:17.313Z","comments":true,"path":"2023/02/13/Machine learning foundation 2.0 - data theory and model evaluation/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/13/Machine%20learning%20foundation%202.0%20-%20data%20theory%20and%20model%20evaluation/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 过拟合：过拟合是指模型对于训练数据拟合呈过当的情况，反映到评估指标上，就是 模型在训练集上的表现很好，但在测试集和新数据上的表现较差 获得更多训练数据：用更多的训练数据是解决过拟合 问题最有效的手段，因为更多的样本能够让模型学习到更多更有效的特征，减小 噪声的影响。 降低模型的复杂度：在数据较少时，模型过于复杂是产生过拟合的主要因 素，适当降低模型复杂度可以避免模型拟合过多的采样噪声。 正则化方法： 给模型的参数加上一定的正则约束，比如将权值的大小加 入到损失函数中。 集成学习方法：集成学习是把多个模型集成在一起，来降低单一模型的 过拟合风险，如Bagging方法。 欠拟合： 欠拟合指的是 模型在训练和预测时表现都不好的情况。 添加新特征。当特征不足或者现有特征与样本标签的相关性不强时，模 型容易出现欠拟合。通过挖掘“上下文特征”“ID类特征”“组合特征”等新的特征，往 往能够取得更好的效果。 增加模型的学习能力：简单模型的学习能力较差，通过增加模型的复杂度可以使模型拥有更强的拟合能力。 减小正则化系数。正则化是用来防止过拟合的，但当模型出现欠拟合现 象时，则需要有针对性地减小正则化系数。 推荐系统中的模型评估方法 评估方法 优点 缺点 holdout检验 简单直接 单次评估不稳定，会引入未来信息 交叉检验 多次评估，结果稳定准确 无法解决引入未来信息的问题，实现较为复杂 自助法 解决训练样本少的问题 会改变原始数据分布 时间切割法 避免引入未来信息的问题 与线上真实模型更新过程不符 重播 接近线上真实环境，评估结果更加可信 实现非常复杂 分类指标 二分类 混淆矩阵： 整体 正样本 负样本 统计 预测正样本 TP FP PP 预测负样本 FN TN PN 统计 P N 召回率(True Positive Rate)：对于目标类别的分类效果 精确率(Positive Predictive Value): 评估指定类别预测结果的质量 真阴性率(True Negative Rate): 被正确分类的负样本比率 假阳性率(False Positive Rate): 所有负样本被预测为正样本的比率 ROC(Receiver Operating Characteristic)曲线: 以假阳性率为横轴，真阳性率为纵轴，描绘出所有的预测点的，可以理解为曲线上每个点都展示了对于观察目标两个类别的输入概率【假设拿到一个点，这个点的坐标指示了一个概率差 - 样本取自正样本集合的概率 - 取自负样本的概率的差】 AUC(Area under curve)空间：ROC曲线所覆盖的面积被称为AUC空间，用来指明分类器在指定类别上的性能 假设有20个样本点，它的真实标签如上所述，即[p, p, n, …, p, n]。我们知道，机器学习模型对输入样本点做出预测通常返回的一个概率值，它反映的是模型有多大把握将当前样本判定为正样本，下面梳理下ROC曲线的一种计算步骤： Step 1：将模型的输出值按照概率值从高到低排序 Step 2：首先将阈值定义为无穷大，此时所有的概率值均小于无穷大，这意味着模型将所有样本都预测为负样本，则TP和FP为0，根据公式可得TPR和FPR也为0，因此ROC曲线的第一个点必然是坐标原点(0,0) Step 3：将阈值从大到小进行缩减，比如将采样间隔定位0.1，那么可以得到下一个阈值大小为0.9。 ,为正负样本集合，表示预估分数从小到大排序后的排名。 准确率(Accuracy): 评估学习器在所有分类的效果 F1-Score: 也称为Dice系数或Dice相似度。F1分数可以定义为精确率和召回率的调和平均值，其值域为[0, 1]，值通常越大越好：","categories":[],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"http://yourthomaslee.github.io/tags/machine-learning/"},{"name":"data theory","slug":"data-theory","permalink":"http://yourthomaslee.github.io/tags/data-theory/"},{"name":"feature selection","slug":"feature-selection","permalink":"http://yourthomaslee.github.io/tags/feature-selection/"}]},{"title":"Leetcode 1234. Replace the Substring for Balanced String","slug":"Leetcode 1234","date":"2023-02-13T02:40:05.000Z","updated":"2023-02-20T01:07:50.254Z","comments":true,"path":"2023/02/13/Leetcode 1234/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/13/Leetcode%201234/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution {public: bool cmp(map&lt;char, int&gt;&amp; a, map&lt;char, int&gt;&amp; b){ bool ans = true; for(auto x: a){ ans &amp;= (b[x.first] &gt;= x.second); } return ans; } int balancedString(string s) { map&lt;char, int&gt; m; for(auto x:{'Q', 'W', 'E', 'R'}) m[x] = 0; for(auto x: s) m[x]++; int t = 0; for(auto i: {'Q', 'W', 'E', 'R'}){ m[i] = max(m[i] - int(s.size() / 4), 0); t += m[i]; cout&lt;&lt;i&lt;&lt;\": \"&lt;&lt;m[i]&lt;&lt;endl; } if(t == 0) return 0; int ans = s.size(); map&lt;char, int&gt; sm; int l = 0, r = 0; while(r &lt; s.size()){ sm[s[r]]++; if(cmp(m, sm)){ //左边界 while(l + t &lt;= r &amp;&amp; sm[s[l]] &gt; m[s[l]]){ sm[s[l]]--; l++; } cout&lt;&lt;l&lt;&lt;\" -&gt; \"&lt;&lt;r&lt;&lt;\": \"&lt;&lt;s.substr(l, r - l + 1)&lt;&lt;endl; ans = min(r - l + 1, ans); sm[s[l]]--; l++; } if(ans == t) return ans; r += 1; } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"two pointers","slug":"two-pointers","permalink":"http://yourthomaslee.github.io/tags/two-pointers/"}]},{"title":"Computational advertising 1 - guaranteed advertising","slug":"Computional advertising 1 - guaranteed advertising","date":"2023-02-12T14:40:05.000Z","updated":"2023-02-17T11:32:24.057Z","comments":true,"path":"2023/02/12/Computional advertising 1 - guaranteed advertising/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/12/Computional%20advertising%201%20-%20guaranteed%20advertising/","excerpt":"","text":"定向广告实现方式和发展历程： 担保式广告(Guaranteed delivery, GD)：媒体与广告主约定广告位、时间段和投放量，并在此基础上确定合同的综金额以及量未达标情况下的赔偿方案。这种合约仍然主要面向品牌广告主，并且按照千次展示付费(Cost per mille, CPM)的计费模式。其中两个关键问题：一是如何有效的将流量分配到各个合约互相交叉的人群覆盖上；二是要在在线环境下实时的完成每一次展示决策(在线分配问题)。当担保广告迅猛发展，争抢流量变得开始寻常，这催生了竞价广告。 合约广告相关概念 在线广告业务的初始阶段，媒体与广告主的代理商是市场的主要参与者。由广告代理公司和媒体签订协议，确保某些广告位在某时间 段为指定的广告商所占有，同时广告商按整体合同支付广告费用。CPT 结算的广告 位合约方式对技术的依赖性较小，只需要用到简单的广告排期系统。 合约广告的重要形式是按 CPM 计费的展示量合约，售卖的对象己经由“广告位”进化到了“广告 位+人群”，这催生了受众定向技术。在合约广告中，需求方的产品技术并没有太大发展，但从供给方产品和技术的复杂程度来看， CPM 合约甚至比竞价产品系统更加复杂，其复杂性主要来源于如何满足多个合约对投放系统量的要求，这就是合约广告 中重要的在线分配问题。 受众定向方法 市场上一些流行的定向方式如下 在图 4-2 中，水平方向表示的是定向技术在广告信息接收过程中大致起作用的阶段， 而垂直方向为定性的效果评价。 地域定向( geo-targeting ): 这是一种很直觉也很早就被广泛使用的定向方式。 人口属性定向( demographical targeting ): 人口属性的主要标签 包括年龄、性别、受教育程度、收入水平等。 上下文定向( contextual targeting)。根据网页或应用的具体内容来匹配相关的广告. 行为定向(behavioral targeting)根据用户的历史访问行为了解用户兴趣，从而投送相关广告的 精确位直走向( hyper-local targeting ): 移动设备上投放广告时，我们有可能获 得非常精准的地理位置 。 重定向( retargeting)对某个广告主过 去一段时间内的访客投放广告以提升效果 新客推荐定向( look-alike targeting)根据 广告 主提供的种子访客信息，结合广告平台更丰富的数据，为广告主找到行为上相似的潜在客 户 场景定向( scenario targeting)是移动环境下的新问题。你在健身 时、吃饭时、看电视时、开会时，会携带和使 用于机，这些你在使用手机时的背景状态就是场景。移动设备丰富的传感器和状态信息为场景的判断提供了可能。 受众定向产品上最关键的环节就是如何描述用户，也就是如何设计标签体系，这甚至 比受众定向的技术更加重要 。 重点探讨的是驱动直接效果的用户，在这一 目的下，规整 的结构化标签体系其实并不是必需的 。一般来说，标签体系的设计必须要分行业进行，而其 中的关键思路是深入研究该行业的用户决策过程。 展示量合约 展示量合约售卖的是某特定人群上的广告曝光次数，而人群不同于确定的广告位，因此必须在合约中约定投放的量。于是，就产生了流量预测( traffic forecasting)这 一 问题，其在广告产品中有以下 3 个主要用途： 售前指导：在展示量合约广告中，因为要约定曝光总数，所以事先尽可能准确地 预测各人群标签的流量至关重要 。 在线流量分配：由于合约之间在人群选择上会有很 多交集， 当一 次曝光同时满足两个以上合约的要求时，怎样决策将它分配给哪个合约以达 到整体满足所有合约的目的，这是下文将要讨论的在线分配问题 。为了描述这一策略 问题，我们将其简化 为一个二部图( bipartite graph)匹配问题: 二部图的一方表示广告库存的供给节点，每个 节点代表的是所有人群标签都相同的流量集合;二部图的另 一方表示广告合约的需求节点， 每个节点代表的是一个广告合约的人群标签条件。 出价指导：在竞价广告中，由于没有了 量的保证，广告主往往需要根据自己预计 的出价先了解一下可能获得多少流量，以判断自己的出价是否合理。 流量预测对于展示量合约非常重要，不过这本质上还是被动地统计流量情况。在有些 情形下，我们可以主动地影响流量，以利于合约的达成。这一产品策略问题称为流量塑形 ( traffic shaping )。","categories":[],"tags":[{"name":"computational advertising","slug":"computational-advertising","permalink":"http://yourthomaslee.github.io/tags/computational-advertising/"},{"name":"guaranteed advertising","slug":"guaranteed-advertising","permalink":"http://yourthomaslee.github.io/tags/guaranteed-advertising/"}]},{"title":"Leetcode 1138. Alphabet Board Path","slug":"Leetcode 1138","date":"2023-02-12T02:40:05.000Z","updated":"2023-02-20T01:09:21.065Z","comments":true,"path":"2023/02/12/Leetcode 1138/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/12/Leetcode%201138/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution {public: string move(int a, int b, int cc, int d){ string ans; if (a == 5){ ans.push_back('U'); a = 4; b = 0; } bool flag = false; if(cc == 5){ flag = true; cc = 4; d = 0; } int r = abs(cc - a); while(r--){ ans.push_back((cc &lt; a)?'U':'D'); } int c = abs(d - b); while(c--){ ans.push_back((d &gt; b)?'R':'L'); } if(flag) ans.push_back('D'); return ans; } vector&lt;string&gt; b ={\"abcde\", \"fghij\", \"klmno\", \"pqrst\", \"uvwxy\", \"z\"}; string alphabetBoardPath(string target) { int pos = 0, r = 0, c = 0; string ans; for(auto x: target){ pos = x - 'a'; if(x != b[r][c]){ ans += move(r, c, pos / 5, pos % 5); r = pos / 5; c = pos % 5; } ans.push_back('!'); } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"}]},{"title":"Machine learning foundation 1 - Part 5. Model enhancement","slug":"Machine learning foundation 1.4 - model enhancement","date":"2023-02-12T02:40:05.000Z","updated":"2023-02-13T03:23:57.293Z","comments":true,"path":"2023/02/12/Machine learning foundation 1.4 - model enhancement/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/12/Machine%20learning%20foundation%201.4%20-%20model%20enhancement/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 [TOC] 1. 提升方法概述 在概率近似正确(probably approximately correct, PAC)框架中，一个概念，如果存在一个多项式的学习算法能够学习它，并且学习的正确率很高，则称该概念是强可学习的；如果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测略好，那么就称该概念是弱可学习的。 事实上，在PAC学习的框架下，一个概念是强可学习的充分必要条件是这个概念是弱可学习的。 提升方法是从弱学习算法出发，得到一系列弱分类器，然后组合这些弱分类器构成一个强分类器。大多数的提升方法都是改变训练数据的概率分布(训练数据的样本权重)，针对不同的训练数据分布调用共弱学习算法学习一系列的弱分类器。 对于提升方法来说，有两个非常重要的问题需要回答： 在每一轮次如何调整训练数据的权重或概率分布 如何将弱分类器组合称一个强分类器 目前典型的提升方法有adaboost，gbdt，xgboost， light gbm，随机森林等等，以下分点阐述这些算法 2. ada-boost算法 AdaBoost(Adaptive Boosting)算法是一个针对二分类的动态自适应提升方法，该方法是顺序训练M个分类器，每个分类器的样本权重根据上一个分类器的分类正确率进行调整得到，每个分类器的权重由分类器的正确率计算得到，将所有分类器的输出进行线性加权结果输入到sign函数输出预测值。 **优点:**1. 非常容易训练，实现起来比较容易; 2. 泛化错误率低（预测性能好），不易过拟合; 3. 不需要调节很多参数，最多修改一下基础模型的数量; 4. 适用范围广：二分类问题，多分类问题，回归问题 **缺点:**1. 对于离群值比较敏感 算法 2.1 adaboost算法 输入： 输出：最终分类器. Step 1. 初始化训练数据的权值分布. Step 2. 对: Step 2.1. 使用具有权值分布的训练数据集学习，得到基本分类器. Step 2.2. 计算在训练数据集上的分类误差率, 如果, 跳转到Step 2.1，否则往下执行Step 2.3. Step 2.3. 计算的权重系数， Step 2.4. 更新训练数据集的权值分布，, 其中为规范化因子，. Step 3. 构建基本分类器的线性组合，, 得到最终分类器，. 每个分类器权重：， 每个样本的权重更新公式，对于正确样本，. **AdaBoost-前向分步算法理解：**考虑加法模型(additive model), 其中为基函数，的参数，为基函数的系数。在给定训练数据和损失函数的条件下，学习加法模型成为经验风险最小化问题. 前向分布算法(forward stagewise algorithm)求解以上优化问题的想法是：从前完后，每一步只学习一个基函数及其系数，逐步逼近优化目标函数，具体地每步秩序优化如下函数. 算法 2.2. 前向分步算法 输入： 输出：加法模型. Step 1. 初始化 Step 2. 对 Step 2.1 极小化损失函数,得到参数. Step 2.2 更新. Step 3. 得到加法模型. 设定损失函数为，并从前往后分步优化，设定权重参数, 令权重参数更新方式为(TODO:补充权重更新细节). 第步则为, 由于前个分类器已经确定，只剩第个分类器待优化，故优化目标可写为. 在ada boost上进行基分类器的拓展，例如将ada boost中的基分类器替换成二分类树，这可以认为是ada boost的简单拓展；对于回归问题，使用决策树将空间区域划分为若干不相交的区域(每个叶子节点就是对应着一个区域)，而后对于每个区域进行线性回归，则可得提升树的回归算法(残差树)。 3. gbdt算法 gbdt是使用加法模型并使用前向分布算法不断减小训练过程中产生的残差估计值来达到将数据分类或者回归的提升算法，相比于adaboost和残差树，gbdt考虑更加泛化的损失函数情况，因此基于梯度的残差估计值来训练每一个轮次的弱分类器，具有更加广泛的适用性。让损失函数沿着梯度方向的下降，这是gbdt的gb的核心了。 gbdt = 前向分布+梯度提升+cart 回归树 gbdt训练：前向分布训练个分类器(贪心算法)，第一次直接基于原始数据集训练，而后使用 gbdt分类树：cart回归树预测数值，之后增加一层softmax GBDT：是一个加法模型，它串行地训练一组CART回归树，最终对所有回归树的预测结果加和，由此得到一个强学习器，每一颗新树都拟合当前损失函数的负梯度方向。 对于回归任务，它一般使用平方误差作为损失函数， 并使每棵树去拟合标签和训练好的树的残差，拟合残差的原因是它是平方损失函数的负梯度。 GBDT 它的非线性变换比较多，表达能力强，而且不需要做复杂的特征工程和特征变换。 GBDT 的缺点也很明显，Boost 是一个串行过程，不好并行化，而且计算复杂度高，同时不太适合高维稀疏特征； 传统 GBDT 在优化时只用到一阶导数信息。 4. XGboost算法 从一般步骤来审视XGboost的细节 数据： 允许特征出现缺失值 分割点寻找：在特征k上寻找最佳划分点时，不会对该列特征缺失的样本进行遍历，而只对该列特征值为不缺失的样本上对应的特征值进行遍历，通过这个技巧来减少了为稀疏离散特征寻找划分点的时间开销。 节点分裂：在逻辑实现上，为了保证完备性，会将该特征值缺失的样本分别分配到左叶子结点和右叶子结点，两种情形都计算一遍后，选择分裂后增益最大的那个方向（左分支或是右分支），作为预测时特征值缺失样本的默认分支方向。 预测时候：如果在训练中没有缺失值而在预测中出现缺失，那么会自动将缺失值的划分方向放到右子结点。 模型角度：传统GBDT以CART树作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。 学习准则： 损失函数：传统GBDT在损失函数时只用到一阶导数信息，xgboost则对损失函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。同时xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。 xgboost损失函数：为叶子节点集合的基数， 为叶子节点的输出值，期望预测不会被单个叶子结点主导，而是一种综合的结果。 泰勒公式： 优化时候针对每个叶子节点进行优化，最小化损失函数即可（损失函数二阶导大于0，所以必定存在最小值), 解一元二次方程 ，最优损失函数即为 采样：每轮计算可以不使用全部样本，随机抽取部分样本，因此算法鲁棒性更强； 训练的时候只用一部分特征(只考虑一个block,不考虑剩余的Block块即可)； 系数衰减：学习率/步长,为了给后面的训练留出更多的学习空间。 并行：xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构减小计算量，各个特征的增益计算开多线程进行 分割点选择：使用可并行的近似直方图算法，用于高效地生成候选的分割点，无需贪心法枚举所有可能的分割点。 停止生长条件（叶子节点的深度、样本数量和带来的信息增益） 最低增益：当新引入的一次分裂所带来的增益Gain&lt;0时，放弃当前的分裂。这是训练损失和模型结构复杂度的博弈过程。 深度限制：当树达到最大深度时，停止建树，因为树的深度太深容易出现过拟合，这里需要设置一个超参数max_depth。 权重限制：当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值，也会放弃此次分裂。这涉及到一个超参数: 最小样本权重和，是指如果一个叶子节点包含的样本数量太少也会放弃分裂，防止树分的太细。 xgboost是gbdt的一个工程实现，它优化的地方如下： 利用了特征的稀疏性。 数据事先排序并且以 block 形式存储，有利于并行计算。 基于分布式通信框架 rabit，可以运行在 MPI 和 yarn 上。（最新已经不基于 rabit 了） 实现做了面向体系结构的优化，针对 cache 和内存做了性能优化。 XGBoost 的缺点有 算法参数过多：调参复杂，需要对 XGBoost 原理十分清楚才能很好的使用 XGBoost。 只适合处理结构化数据：相对于深度学习算法来说，XGBoost 算法只适 合处理结构化的特征数据，而对于类似图像中的目标检测等任务重的非结构化数据没有很好的处理能力。 不适合处理超高维特征数据：XGBoost 算法对于中低维数据具有很好的处理速度和精度，但是对于例如大规模图像物体识别，或者是推荐算法的某些场景中会出现的超高维特征的数据就无能为力了，这时候我们就需要借助于深度学习等算法。 5. light gbm算法 #TODO 6. 随机森林 直觉： 随机森林是采用有放回采样样本和随机采样特征形成若干个决策树分类器投票预测最终的样本标签值的集成学习方法 优点： 模型较低的方差，较好的泛化性能； 由于随机采样特征，也可以作为特征选择的方法； 由于多个分类器之间独立不相关，并行性能较好，速度较快； 缺点：投票决策导致不能够预测从来没有出现过的标签值，同时预测值的空间为离散的，这导致在回归问题上表现较差；由于没有考虑特征之间的相关性，在有些情况下随机森林的模型效果可能不尽人意 6.1. bagging 给定大小为的样本集合，使用有放回采样方构造个样本集(每个样本集个样例)，使用个样本集训练不同的分类或者回归预测模型，并使用简单投票或者算术平均值求预测值。 6.2. 随机森林 随机森林是 Bagging 的优化版本。其包含的思想在于： 随机选择样本数建立多个训练集并随机选取特征集合，根据多个训练集与特征集合来建立多颗决策树，然后进行投票决策。 随机森林的最终目的是建立颗决策树，而每颗决策树的建立过程如下： 如果训练集大小为，对于每棵树而言，随机且有放回地从训练集中的抽取个训练样本，作为该树的训练集。 如果每个样本的特征维度为，指定一个常数，随机地从个特征中选取个特征子集，每次树进行分裂时，从这个特征中选择最优的 每棵树都尽最大程度的生长，并且没有剪枝过程。 随机森林中的随性性指的是：数据采样的随机性与特征采用的随机性。 这两个随机性的引入对随机森林的分类性能直观重要，它们使得随机森林不容易陷入过拟合，且具有很好的抗噪能力。是随机森林中唯一的一个参数。 减小特征选择个数，树的相关性和分类能力也会相应的降低 增大，两者也会随之增大。 6.3. 如何处理缺失值 首先给缺失值预设一些估计值，例如平均数，中位数，众数； 根据估计的数值，建立随机森林，把所有的数据放进随机森林里面跑一遍。记录每一组数据在决策树中一步一步分类的路径. 判断哪组数据和缺失数据路径最相似，引入一个相似度矩阵，来记录数据之间的相似度，比如有组数据，相似度矩阵大小就是。如果缺失值是类别变量，通过投票得到新估计值，如果是数值型变量，通过加权平均得到新的估计值，如此迭代，直到得到稳定的估计值。 6.4. 什么是 OOB？ OOB 即 out-of-bag ， 又称袋外数据。 这是由于 Bagging 方法会采用 Boostrap 进行抽样， 每次约有 的样本不会出现在抽样后的样本集合中，那么就把这 的样本称为袋外数据 oob(out-of-bag)。由于 oob 没有用于训练决策树，因此可用于后续对该决策树的泛化能力评估。 6.5. 随机森林的优劣 优势: 模型高度并行化, 对于高维数据集的处理能力比较好, 可以处理成千上万的输入变量,并确定出重要的变量, 因此也被认为是不错的降维方法. 能够处理分类和回归两种类型的问题, 表现良好, 由于是集成学习, 方差和偏差都比较小, 泛化性能优越. 对于数据的鲁棒性很强, 可以处理缺失数据/不平衡数据, 无需归一化 劣势: 随机森林在回归问题上较为弱势, 这是因为它不能给出一个连续型的输出.另外随机森林不能够做出超越训练数据集范围的预测, 这可能导致在有特定噪声的数据进行建模时出现过度拟合 黑盒模型, 无法控制模型运行 随机森林模型忽略了属性之间的相关性 常见问题 随机森林, gbdt和xgboost的区别在哪儿 随机森林的集成学习方法是bagging, 但是需要特别注意的是随机森林使用bootstrap有放回采样, 每个基学习器随机选择m()个属性来做输入, 在采样样本的同时也采样特征, 结合集成方法能够降低方差和偏差, 泛华性能优越. 随机森林的优势: 模型高度并行化, 对于高维数据集的处理能力比较好, 可以处理成千上万的输入变量,并确定出重要的变量, 因此也被认为是不错的降维方法. 能够处理分类和回归两种类型的问题, 表现良好, 由于是集成学习, 方差和偏差都比较小, 泛化性能优越. 对于数据的鲁棒性很强, 可以处理缺失数据/不平衡数据, 无需归一化 随机森林的劣势: 随机森林在回归问题上较为弱势, 这是因为它不能给出一个连续型的输出.另外随机森林不能够做出超越训练数据集范围的预测, 这可能导致在有特定噪声的数据进行建模时出现过度拟合 黑盒模型, 无法控制模型运行 随机森林模型忽略了属性之间的相关性 gbdt的集成学习方法是boosting, 因为梯度提升需要按照损失函数的梯度近似的拟合残差, 因此只有回归树. 与传统boosting方法的区别在于, 传统boosting方法是使用样本的权重来做前后模型的结合提升整体模型的效果. 这个梯度代表上一轮学习器损失函数对预测值求导。与Boosting Tree的区别：Boosting Tree的适合于损失函数为平方损失或者指数损失。而Gradient Boosting适合各类损失函数（损失函数为：平方损失则相当于Boosting Tree拟合残差、损失函数为：使用指数损失则可以近似于Adaboost，但树是回归树） XGBoost相对于gbdt好的地方在于使用二阶泰勒展开做优化, 节点分数正则化惩罚, 增益计算不同.","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"model enhancement","slug":"model-enhancement","permalink":"http://yourthomaslee.github.io/tags/model-enhancement/"}]},{"title":"Computational advertising 0 - concepts","slug":"Computional advertising 0 - concepts","date":"2023-02-11T14:40:05.000Z","updated":"2023-02-17T12:30:20.862Z","comments":true,"path":"2023/02/11/Computional advertising 0 - concepts/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Computional%20advertising%200%20-%20concepts/","excerpt":"","text":"[TOC] 1. 广告发展和基础概念 广告与销售的区别： 广告：通过媒介传播企业形象或产品信息，目标寻找潜在用户，在某特定人群的有效到达（reach）或多渠道综合的ROI 销售：面对有较明确需求的客户，提升产品销量，从而提高企业收益，目标是提高收入和利润 定义 1. 广告是由已确定的出资人通过各种媒介进行的有关产品(商品、服务和观点)的，通常是有偿的、有组织的、综合的、劝服性的信息传播活动 需求方=广告主=出资人； 媒介=供给方=媒体 | 代理商；受众 = 媒体的用户 广告分类： 品牌广告：借助媒体快速接触大量用户，以达到宣传品牌形象，提升中长期购买率与利润空间的目的 直接效果广告：利用广告手段马上带来大量的购买或者其它转化行为 广告的根本目的是广告主通过媒体达到低成本(Return of investment, ROI)的用户接触，这里的低成本是相对于市场或销售人员完成的劝服活动成本而言的。具体来说 品牌广告：创建独特的良好的品牌形象，提升较长时期内的离线转化率 效果广告：有短期内明确用户转化行为诉求的广告 互联网的广告：一切付费的信息、产品或服务的传播渠道，都是广告 1.1 在线广告 在线广告的独特性： 技术和计算导向：数字媒体的特点使在线广告可以尽心高精细的受众定向。技术使得广告决策和交易朝着计算驱动的方向发展 效果的可衡量性：广告的点击是效果的直接收集途径 创意和投放方式的标准化：集中投放和精准定向促进了在线广告的标准化 “媒体”概念的差异样化 数据驱动的投放决策 在线广告的表现形式： 类型 说明 横幅广告 文字链广告 富媒体广告 侵入式投入广告素材，包括弹窗、对联、全屏等 视频广告 视频插片广告，信息流视频广告，游戏激励视频广告 交互式广告 社交广告 在社交网络中插入的广告 移动广告 邮件营销广告 通过电子邮件向用户推广信息的一种营销手段 激励广告 激励用户产生转化行为以提高效果，例如移动积分墙，电商返利购买和团购、游戏联运 数字媒体不同于传统媒体的本质特点：可以对不同受众呈现不同的广告创意，而对指定人群展现的广告也叫定向广告。定向广告对计算技术提出两个需求：一是受众定向(audience targeting)，就是通过技术手段标定某个用户的性别、年龄或其他标签，二是广告投放(ad serving)，即将广告投送由直接嵌入页面变为实时响应前端请求并动态决策和返回合适的广告创意。 定向广告实现方式和发展历程： 担保式广告(Guaranteed delivery, GD)：媒体与广告主约定广告位、时间段和投放量，并在此基础上确定合同的综金额以及量未达标情况下的赔偿方案。这种合约仍然主要面向品牌广告主，并且按照千次展示付费(Cost per mille, CPM)的计费模式。其中两个关键问题：一是如何有效的将流量分配到各个合约互相交叉的人群覆盖上；二是要在在线环境下实时的完成每一次展示决策(在线分配问题)。当担保广告迅猛发展，争抢流量变得开始寻常，这催生了竞价广告。 竞价广告(auction-based advertising): 最初产生于搜索广告，在竞价模式下，供给方只向广告主报纸质(单位流量的成本)，但不再给出量的保证。竞价系统下定价机制成为一个重要问题，目前广义第二高价(Generalized second price, GSP)和Vickrey–Clarke–Groves拍卖机制(VCG)是主流方案。竞价和精准人群定向的庞大需求，催生了广告网络(AD Network， ADN)，它批量地运营媒体的广告位，按照人群或上下文标签售卖给需求方并用竞价的方式分配流量，广告网络的结算以按点击计费(Cost per click, CPC)的方式进行，这使得尾部小流量也能够被利用，进一步扩大了广告的市场。另外，流量采买的形式越来越依赖技术手段进行指定人群受众流量的购买保证达成要求。 开放实时竞价(Real time bidding, RTB)：广告网络的竞价过程是内部进行的，无法满足广告主定制化的人群选择和优化要求，例如电商网络召回流失用户和银行通过已有信用卡用户找到相似的潜在用户群，这催生了开放的竞价逻辑，让需求方按自己的人群定义来挑选流量。RTB将竞价过程变为每次将广告展示的上下文页面URL和访客的用户表示等用户标识等信息传给需求方，它完成定制化的人群选择和出价，这催生了新的产品形态：广告交易平台(AD exchange, ADX)，而完成定制化人群标签采买广告的平台就是需求方平台(Demand side platform, DSP)，这种买卖广告的方式也叫程序化交易(Programmatic trade) 以上每一种广告产品基本都有三个组成部分，即面向需求方的接口、面向供给方的接口以及中间的投放系统及匹配策略。 需求方接口：一般来说提供的广告是分层次管理的。层次分为广告主、广告计划（plan)、广告单元(ad group)、广告创意（idea)等几个层级。以下为百度内部系统中的层级 user：账户信息，与plan关系1对N plan：计划，一个账户下可设置多个推广计划。是管理推广的最大单位，一般按产品或地域进行划分，与unit关系1对N unit：单元，每个推广计划多个单元。将意义相近结构相同的关键词放在一起管理，与winfo和idea是一对多的关系 winfo：用户购买的关键词，包括bidword、广告主出价信息，与idea关系M对N idea：展示给网民看的推广内容，包括标题、描述、显示url以及访问url 供给方接口：分为媒体和广告位两个层次，其中媒体可以是网站或者移动应用。这部分更多涉及不同计算实体之间的交互技术，此处不过多赘述。 对于具体的媒体，一般有如下的变现方式可供选择 托管给广告网络(ADN)：在access注册下，按点击结算 接入ADX：通过实时竞价接到dsp，按竞价变现 接入SSP（sell side platform）：广告网络、adx、DSP到媒体的中介方，中介方优化媒体侧的营收，按分成结算 注：ATD(automatic trading desk)：代理交易平台，是广告代理机构内部常见的集中优化并采购程序化媒体的管理平台，非实时结算 2. 广告系统的建模 搜索、推荐与广告系统的区别[2] 目的上来说，广告系统的目标就是为了公司增加收入，它服务的对象主要是广告主，技术上来说是为广告寻找合适的受众。 推荐系统的目标是在“信息过载”的情况下，协助用户高效获取感兴趣的信息。搜索系统的目标是围绕关键词的信息明确问题并找到答案 优化目标上来说，广告系统最关心的应该是预估ctr和cvr，这一方面揭示了系统在寻找受众的能力，另一方方面也反映了出价计费的合理性（估得更准）。推荐系统最关心的和用户参与度最相关的业务指标，例如视频类推荐关注播放时长。由于推荐场景一般是生成返回一个列表，因此更加关注item间的相对位置，AUC、gAUC和MAP这类指标被视作核心的评价指标（排的更好）。搜索系统的目标是找到用户想要的信息，某种意义上甚至存在\"正确答案\"，所以搜索系统往往会针对召回率，MAP，NDCG这些指标进行优化（搜的更全）。 模型设计上来说，广告系统为了模型的准度模型的训练方法根据环境的不同，可以分为“离线训练”和“在线更新”两部分。其中，离线训练的特点是可以利用全量样本和特征，使模型逼近全局最优点，而在线更新则可以准实时地“消化”新的数据样本，更快地反应新的数据变化趋势，满足模型实时性的需求。 类型 搜索 广告 推荐 首要准则 相关性(relevence) 投资回报率(ROI) 用户兴趣 其他需求 各垂直领域独立定义 质量和安全性(safety) 多样性(diversity)新鲜度(freshness) 个性化需求 少 少 亿级用户规模的个性化 检索信号 较为集中 较为集中 较为丰富 Downstream优化 不适用 不适用 适用 广告系统的核心部分由投放、计费、结算三个子系统组成。投放、计费、计算系统各自的技术关注点不同：投放系统关注请求响应时间，计费系统关注数据实时性，结算系统关注数据准确性（这部分是我个人理解上是不太明白，后续再回来弄清楚） 具体的来说，广告系统的内部流程参照如下： 用户在手百上刷新触发客户端向服务器发起广告检索请求，请求首先经过AFD模块进行流量分发，流量经过fmp将数据源信息(src_id/search id/用户id等)下发到feedas，feedas模块从收到流量到返回广告可以分为6个阶段 第一个阶段是获取用户特征，feedas需要访问upin（用户基本信息，兴趣信息，历史搜索浏览信息，短期兴趣等）、intentservice（行为序列，用户画像，商业意图）、usercenter（历史行为信息用于频控）、ums（用户的attention信息，dislike信息）、uas（自然属性年龄性别等等）等五个模块，获得用户画像、 用户场景、用户行为、query、频控等信息。 第二个阶段是触发阶段，在这个阶段中feedas利用之前获得的用户信息与金门等模块进行交互，获得用户的意图列表，即推荐/拓展/改写query，用以抽象理解用户提高广告推荐的精确性。（基于规则，基于模型） 第三个阶段是广告召回。我们通过基础的用户特征和意图词去广告库中召回相匹配的广告。在这个阶段中feedas直接请求feedproxy, feedproxy并行访问feedbs、闪投、GD等广告库（feedbs，interestbs，Rtabs），对广告进行召回、粗排、过滤和截断，获得不同的原始广告队列 第四个阶段是广告的创意优选。广告召回之后，会请求adrest获得这些广告的物料和样式，进行创意优选 第五个阶段是广告的策略操作，主要包括广告的排序、过滤、去重、计费、截断等一系列的策略机制，最后得到胜出的几条广告。 第六个阶段是对胜出的广告进行封装和打包，由feedas返回给AFD，AFD模块收到广告后进行广告渲染之后返回给用户进行展现，从而形成一次完整的广告请求 广告的整个过程可以被描述为如下3个阶段和6个进程 曝光指的是物理上展现的过程，实际中位置影响很大。关注指的是用户意识到广告本身的存在，如何在不打断用户的任务前提下，明确传达推送广告的原因且内容契合用户的兴趣或需求是比较有效提升关注的方法。理解阶段，让用户理解广告内容，让广告内容尽可能简单容易理解且让内容在兴趣范围内。接受阶段：考虑广告上下文和广告逻辑。保持阶段：让用户留下尽可能长时间的正面印象。决策阶段：打动用户并劝服其产生转化行为。越靠前的阶段，对点击率影响越大，而越靠后的阶段对转化率影响越大。 广告问题的形式化：计算广告的核心挑战是为一系列用户与上下文的组合找到最合适的广告投放策略以优化整体广告活动的利润。使用最优化问题表述即为 Misplaced & \\max &amp; \\sum_{i = 1}^T (r_i - q_i),\\ &amp; s.t. \\sum_{i = 1}^T d_{ik} \\leq D_k, \\forall k 其中表示从第1次到第次之间的某一次广告展示, 和分别表示每次广告展示中的总收入和总成本的差，即总体的利润，则表示在第次广告中具体广告主的限制(需求方约束)。进一步考虑具体依赖的因素，优化问题可以写成 Misplaced & \\max &amp; \\sum_{i = 1}^T (r(a_i, u_i, c_i) - q(a_i,u_i,c_i)),\\ &amp; s.t. \\sum_{i = 1}^T d(a_i,u_i,c_i,k) \\leq D_k, \\forall k 分别表示广告，用户和上下文，即广告活动的3个参与主体。注意这里隐含假设整体的收入或成本可以被分解到每次展示上，这并不合理，但为了实用仍然采用这个假设并通过频次控制、点击反馈等方法来解决多次展示之间效果相关性的问题。这样，可以直观理解为寻找在给定用户、给定场景下的最优匹配的广告集。从ROI上拆解上看，Investment一般不能优化， 只能尽可能优化Return , 这种分解方式也要依据情况分解，不同的市场形态下看 CPM市场：固定eCPM(品牌广告) CPC市场：动态CTR，固定click value(点击计费，点击广告) CPA/CPS/ROI市场：动态CTR和click value(转化计费，效果广告) 具体的优化方向上看 特征提取：受众定向的优化 微观优化：CTR预测 宏观优化：竞价市场机制 受限优化：在线分配，广告投放的质和量的协调（流量分配） 强化学习：探索、利用新的用户和广告主的匹配（冷启和拔高收入） 个性化重定向：推荐技术 系统角度看： 候选查询：实时索引（ANN） 特征存储：No-sql技术，大规模、高并发的特征存储 离线学习：hadoop 在线学习：流计算 交易市场：实时竞价 具体收入分解方式有如下方式 3. 后续的内容安排 本系列将分为四条线来进行广告技术的学习和说明 不同类型的广告：担保广告、竞价广告、程序化交易广告 广告系统流水线：将整个系统的分步骤进行逐一的讲解 不同模块的工程基础：基于2来看各个模块的工程基础 对2中典型的抽象问题进行探究和说明 Reference [1] FunRec-在线阅读 - https://github.com/datawhalechina/fun-rec [2] 推荐、广告、搜索的区别 - https://zhuanlan.zhihu.com/p/430431149","categories":[],"tags":[{"name":"computational advertising","slug":"computational-advertising","permalink":"http://yourthomaslee.github.io/tags/computational-advertising/"},{"name":"basic concepts","slug":"basic-concepts","permalink":"http://yourthomaslee.github.io/tags/basic-concepts/"}]},{"title":"Deep learning foundation 1 - classical modules","slug":"Deep learning 1 - optimization algorithm","date":"2023-02-11T02:40:05.000Z","updated":"2023-03-01T06:42:16.241Z","comments":true,"path":"2023/02/11/Deep learning 1 - optimization algorithm/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Deep%20learning%201%20-%20optimization%20algorithm/","excerpt":"","text":"SGD Adam","categories":[],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"http://yourthomaslee.github.io/tags/deep-learning/"},{"name":"optimization","slug":"optimization","permalink":"http://yourthomaslee.github.io/tags/optimization/"}]},{"title":"Deep learning foundation 1 - classical modules","slug":"Deep learning 1 - classical modules and basic tricks","date":"2023-02-11T02:40:05.000Z","updated":"2023-03-06T14:56:56.840Z","comments":true,"path":"2023/02/11/Deep learning 1 - classical modules and basic tricks/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Deep%20learning%201%20-%20classical%20modules%20and%20basic%20tricks/","excerpt":"","text":"CNN RNN Attention normalization dropout","categories":[],"tags":[{"name":"deep learning concepts","slug":"deep-learning-concepts","permalink":"http://yourthomaslee.github.io/tags/deep-learning-concepts/"},{"name":"classical modules","slug":"classical-modules","permalink":"http://yourthomaslee.github.io/tags/classical-modules/"}]},{"title":"Leetcode 1140. Stone Game II","slug":"Leetcode 1140","date":"2023-02-11T02:40:05.000Z","updated":"2023-02-22T01:23:25.806Z","comments":true,"path":"2023/02/11/Leetcode 1140/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Leetcode%201140/","excerpt":"","text":"The problem description can be found at the link My solution: 123456789101112131415161718192021class Solution {public: int stoneGameII(vector&lt;int&gt;&amp; piles) { vector&lt;vector&lt;int&gt;&gt; dp(piles.size(), vector&lt;int&gt;(piles.size() + 1, 0)); int sum = 0; for(int i = piles.size() - 1; i &gt;= 0; i--){ sum += piles[i]; for (int M = 1; M &lt;= piles.size(); M++) { if (i + 2 * M &gt;= piles.size()) { dp[i][M] = sum; } else { for (int x = 1; x &lt;= 2 * M; x++) { dp[i][M] = max(dp[i][M], sum - dp[i + x][max(M, x)]); } } } } return dp[0][1]; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"dynamic programming","slug":"dynamic-programming","permalink":"http://yourthomaslee.github.io/tags/dynamic-programming/"},{"name":"interesting problem","slug":"interesting-problem","permalink":"http://yourthomaslee.github.io/tags/interesting-problem/"}]},{"title":"Leetcode 2335. Minimum Amount of Time to Fill Cups","slug":"Leetcode 2335","date":"2023-02-11T02:40:05.000Z","updated":"2023-02-20T01:03:40.807Z","comments":true,"path":"2023/02/11/Leetcode 2335/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Leetcode%202335/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314151617class Solution {public: int fillCups(vector&lt;int&gt;&amp; amount) { int cnt = 0, remain = 0; sort(amount.begin(), amount.end(),[](int a, int b){return a &gt; b;}); for(int i = 0; i &lt; amount.size(); ++i){ if(amount[i] != 0 &amp;&amp; cnt &lt; 2){ amount[i] --; remain = amount[i]; cnt ++; } } if(cnt == 2) return 1 + fillCups(amount); else if(cnt == 1) return 1 + remain; else return 0; }}; Best solution(explanation link): 12345678910class Solution {public: int fillCups(vector&lt;int&gt;&amp; amount) { sort(amount.begin(), amount.end()); if (amount[2] &gt; amount[1] + amount[0]) { return amount[2]; } return (accumulate(amount.begin(), amount.end(), 0) + 1) / 2; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"greedy algorithm","slug":"greedy-algorithm","permalink":"http://yourthomaslee.github.io/tags/greedy-algorithm/"},{"name":"array","slug":"array","permalink":"http://yourthomaslee.github.io/tags/array/"},{"name":"easy level","slug":"easy-level","permalink":"http://yourthomaslee.github.io/tags/easy-level/"}]},{"title":"Machine learning foundation 1 - Part 4. decision tree","slug":"Machine learning foundation 1.3 - decision tree","date":"2023-02-11T02:40:05.000Z","updated":"2023-06-10T09:34:42.854Z","comments":true,"path":"2023/02/11/Machine learning foundation 1.3 - decision tree/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Machine%20learning%20foundation%201.3%20-%20decision%20tree/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 [TOC] 1. 预备知识 1.1 基础数学知识： 期望. 另外如果与独立时. 方差： 方差是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。 方差是和中心偏离的程度，用来衡量一批数据的波动大小（即这批数据偏离平均数的大小）并把它叫做这组数据的方差。 . . 如果两个随机变量相互独立，. 标准差 协方差：,相关系数. 特征相关性分析：在统计学中，皮尔逊相关系数( Pearson correlation coefficient），又称皮尔逊积矩相关系数（Pearson product-moment correlation coefficient，简称 PPMCC或PCCs），是用于度量两个变量X和Y之间的相关(线性相关)，其值介于-1与1之间。皮尔逊相关系数有一个重要的数学特性是，因两个变量的位置和尺度的变化并不会引起该系数的改变，即它该变化的不变量移动到和把Y移动到，其中a、b、c和d是常数，并不会改变两个变量的相关系数（该结论在总体和样本皮尔逊相关系数中都成立）。 假设划分前样本集合D的熵为 。使用某个特征A划分数据集D，计算划分后的数据子集的熵为 。 信息熵：条件熵：信息增益： 1.2 决策树基础 目前典型的决策树算法有三种，分别是ID3、C4.5和CART算法。 算法 划分标准 ID3 信息增益 C4.5 信息增益率 CART 基尼系数 决策树的三要素 特征选择： 从训练数据中众多的特征中选择一个特征作为当前节点的分裂标准，如何选择特征有着很多不同量化评估标准标准，从而衍生出不同的决策树算法。 **决策树生成：**根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树停止生长。 **决策树的修剪：**决策树容易过拟合，一般来需要剪枝，缩小树结构规模、缓解过拟合。剪枝技术有预剪枝和后剪枝两种。 在决策树的生成和修剪步骤，对于三个算法大同小异，下面主要学习下特征的选择问题。 决策树算法的框架如下所示 algorithm 2.3.1 决策算法 输入：训练集, 属性集 输出:一棵决策树 函数： 123456789生成节点node;if D中样本全部属于同一类别C then 将node节点标记为C类叶子节点, return ;if A为空集 or D中样本在A上取值相同 then 将node节点标记为叶节点,其类别标记为D中样本数最多的类 return ;从A中选择最优划分属性a_max;for a_max中的每一个取值a_val: 为node生成一个分支;令D_v表示D中取值为a_val的样本子集 以TreeGenerate(D_v,A-{a_max})为分支节点 因此决策树的关键在于选择最优划分属性，一般而言，随着划分过程不断进行，我们希望决策树的分支节点所包含的样本尽可能的属于同一类别。 2. 特征选择标准 2.1. 信息增益(ID3算法) 设当前样本集合D中第类样本所占的比例为 那么D的信息熵定义为： 使用属性作为划分属性的信息增益为 对取值数目较多的属性有偏好, 其根本原因在于, 当时， 最大， 从公式建模的角度上来说，信息熵建模本身就无法提供任意两个概率分布之间的距离估算。 2.2. 增益率(C4.5算法) 增益率定义为 被称为的“固有值”。需要注意的是，增益率准则对可取值数目较少的属性有所偏好。因此，C4.5算法并不是直接选择增益率最大的侯选划分属性，而是使用了一个启发式：先从侯选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的, 但从根本上来说，由于仍然使用信息熵作为基础的评估方式，启发式方法只能一定程度上缓解对多值属性的偏好。 2.3. 基尼指数(CART树) 对于离散数据，数据集的纯度可以使用基尼值来度量，值的定义如下： 直观来说，反映了从数据集中随机抽取两个样本，其类别标记不一致的概率。值越小，则数据集的纯度越高。属性的基尼指数定义为： 于是我们在侯选属性集合A中选择那个使得划分后基尼指数最小的属性作为最优划分属性，即. 对于回归任务，一颗回归树对应着输入空间的一个划分以及在划分的单元上的输出值。假设已将输入空间划分为个单元,并且在每个单元上游一个固定的输出值, 回归树模型可以表示为, 当输入空间的划分确定后，使用平方误差来表示回归树在训练数据的预测误差，并求解单元上的的最优值，易知所有值的最优值为上样本点标签的均值。 3. 树生成 3.1. ID3算法 算法 3.1. ID3树生成算法 输入: 训练数据集，特征集阈值. 输出: 决策树. Step 1. 如果中的所有实例都属于同一类, 则为单节点树，并将类作为节点的标记, 返回； Step 2. 如果, 则为单节点树，并将数据集中实例树最大的类作为节点的标记, 返回; Step 3. 计算所有属性对决策属性的信息增益，选择信息增益最大的属性; Step 4. 如果的信息增益小于阈值, 则置为单节点树，并将数据集中实例树最大的类作为节点的标记, 返回; Step 5. 根据的取值获得数据的一个划分，对划分中的每一个子数据集为训练集作为特征集，递归调用Step 1-5生成叶子节点的类别标记. 3.2. C4.5算法 算法 3.1. C4.5树生成算法 输入: 训练数据集，特征集阈值. 输出: 决策树. Step 1. 如果中的所有实例都属于同一类, 则为单节点树，并将类作为节点的标记, 返回； Step 2. 如果, 则为单节点树，并将数据集中实例树最大的类作为节点的标记, 返回; Step 3. 计算所有属性对决策属性的信息增益率，选择信息增益率最大的属性; Step 4. 如果的信息增益小于阈值, 则置为单节点树，并将数据集中实例树最大的类作为节点的标记, 返回; Step 5. 根据的取值获得数据的一个划分，对划分中的每一个子数据集为训练集作为特征集，递归调用Step 1-5生成叶子节点的类别标记. 3.3. CART算法 算法 3.3.1. 最小二乘回归算法 输入: 训练数据集; 输出：回归树 Step 1. 选择最优切分变量和切分点,求解 遍历变量，对固定的切分变量扫描切分点, 选择使上式最小的; Step 2. 用选定的划分区域并决定相应的输出值: Step 3. 继续对两个子区域调用上述步骤，直到满足停止条件 Step 4. 将输入控件划分为个子区域, 生成决策树. 算法 3.3.2 CART分类树 输入: 训练数据集，停止计算的条件. 输出: 决策树. Step 1. 如果中的所有实例都属于同一类, 则为单节点树，并将类作为节点的标记, 返回； Step 2. 如果, 则为单节点树，并将数据集中实例树最大的类作为节点的标记, 返回; Step 3. 计算所有属性对决策属性的Gini指数(对所有属性的属性值基于是否划分为两个数据集子集)，选择Gini指数最小的属性; Step 4. 根据的最优值划分获得数据的一个划分，对划分中的每一个子数据集为训练集作为特征集，递归调用Step 1-4生成叶子节点的类别标记. 4. 剪枝处理 4.1. 预剪枝 将数据集划分为训练集和测试集，每次分支也考虑验证集上的分类效果，在西瓜书中其评价指标为分类精度，若分支后的分类精度在训练集上和测试集上都有提升，那么分支，否则禁止分支。 4.2.后剪枝 以决策树生成节点的顺序为节点的序，逆序遍历所有分支节点，考察替换成叶子节点后验证集上分类精度的变化，若有提升则将分支节点替换成叶子节点； 另外一种情况是使用损失函数来进行剪枝与否判断。设树的叶节点个数为, 是树的叶子节点，该叶节点有个样本点，其中类的样本点有个，. 是叶节点上的经验熵，则决策树学习的损失函数可以定义为 , 对所有叶子节点确定剪枝前后的损失函数值来确定。 算法 4.2.1 CART剪枝算法 输入：CART算法生成的决策树 输出：最优决策树 Step 1. 设, , Step 2. 自下而上地对各内部节点计算以及,其中表示以为根节点的子树，是对训练数据的预测误差，是树的叶节点个数。 5. 连续值与缺失值处理 5.1. 连续值处理 设存在连续属性，假定出现了个不同取值，将这些值从小到大排序，记为。记由划分点得到的数据划分为。因此，对连续属性可以考察个元素的侯选划分点集合 而后考察划分。而后计算得到的信息增益可用以分支判断。需要注意的是，分支每次只分两支，也就是说离散化每次分支只进行一次，后续分支仍可继续使用该属性继续离散化分支。 5.2. 缺失值处理 使用已知数据来评估分支，而后将缺失值的对象加入到每一个拓展分支的对象集中. 例如, 设存在缺失值的属性, 表示属性上无缺失值的样本, 表示无缺失值样本所占比例, 表示无缺失值样本第类样本所占比例. 表示无缺失值样本中上取值的样本的比例. 则可将信息增益的计算式推广为: 6. 拓展 6.1. 多变量决策树 与传统的单变量决策树不同, 多变量决策树学习过程中, 不是为每个非叶节点寻找一个最优划分属性, 而是试图建立一个合适的线性分类器. 多变量决策树算法主要有OC1[Murthy et al., 1994]和[Brodley and Utgoff, 1995]提出的一系列算法. OC1先贪心地寻找每个属性的最优权值, 在局部优化的基础上在对分类边界进行随机扰动以试图寻找到更好的边界; [Brodley and Utgoff, 1995]则直接引入了线性分类器的最小二乘法. 6.2. 为何信息增益会偏向多取值特征？ 从直观的理解上来说，当特征取值较多时， 根据此特征划分得到的子集纯度有更大的可能性会更高（对比取值较少的特征）， 因此划分之后的熵会更低，而又由于划分之前的熵是一定的，因此信息增益更大。 6.3. 树形结构为何不需要归一化？ 因为数值缩放不影响分裂点位置，对树模型的结构不造成影响。按照特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会有不同。而且，树模型是不能进行梯度下降的，因为构建树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，因此树模型是阶跃的，阶跃点是不可导的，并且求导没意义，也就不需要归一化 决策树的目标是得到可靠的if-then规则集合，其规则可以由从根节点到叶子节点的完整路径导出。 决策树的构建主要通过递归的选择特征将特征域划分为若干子空间使得子空间样本集损失函数最小。 特征选择： 信息增益 [ID3]：；缺点是会选择取值较多的特征 信息增益率 [C4.5]：, 底部除以的信息熵，对其进行惩罚，实质上并没有从根本上解决，信息熵衡量了信息的有效性，取值较多问题的实质是有无用的取值被信息熵计算到了收益里面，增益率可以缓解这个问题，但不能根除，可以考虑重新设计公式。 Gini指数 (可辨识关系) [CART]：§, 去除了指数运算，降低运算量 平方误差：, 其中为划分的空间，为划分空间所对应的预测值。 ID3算法： 输入： 训练集, 特征集信息增益阈值 输出：决策树 如果中实例属于同一类 或者 为空, 则为单节点树，并将D中占比最大的类作为该节点的标记，返回；否则继续 计算中各个特征对的信息增益，选择信息增益最大的特征，如果最大信息增益小于给定阈值, 那么构建节点并设置占比最大的类作为标签，返回；否则继续 根据划分数据集, 对每个数据集，跳转到1，生成新的叶节点。 ID3算法的缺点： 没有考虑连续特征，比如长度，密度 没有考虑缺失值的情况 没有考虑过拟合的问题 决策树生成算法递归的产生决策树，直到不能继续下去为止。这样的树容易过拟合。解决决策树过拟合的一个方法是通过剪枝简化决策树。设树有叶节点个数为, 是树的叶节点，含有个样本，为叶节点的经验熵，那么决策树学习的损失函数可以定义为 对于连续属性，排序，对每两个不同的值取中位数作为分裂点，计算信息增益，选择最大信息增益的分裂点。注意，在决策树中连续属性可以被多次选择用以划分样本集 剪枝方法： 预剪枝 + 限制决策树深度 计算所有节点的合并损失，并按序列检查在验证集上的预测误差 C4.5算法 输入： 训练集, 特征集信息增益率阈值 输出：决策树 **Step 1：**决策树生成 如果中实例属于同一类 或者 为空, 则为单节点树，并将D中占比最大的类作为该节点的标记，返回；否则继续 计算中各个特征对的信息增益率，选择信息增益率最大的特征，如果最大信息增益率小于给定阈值, 那么构建节点并设置占比最大的类作为标签，返回；否则继续 根据划分数据集, 对每个数据集，跳转到1，生成新的叶节点。 **Step 2：**决策树剪枝 遍历决策树，然后检查叶子节点的父节点合并叶子节点的损失函数前后变化，如果合并后变得更小，那么剪枝。 C4.5算法缺点： 只能用以分类 重要度计算复杂度高 CART算法： 输入： 训练集, 特征集信息增益率阈值 输出：二叉决策树 回归： 选择最优切分变量与切分点, 求解 如果满足停止条件，对划分的区域打上样本集合标签的均值作为预测值生成叶子节点； 否则基于划分得到的样本空间跳转到步骤1继续生成决策树 分类： 如果中实例属于同一类 或者 为空, 则为单节点树，并将D中占比最大的类作为该节点的标记，返回；否则继续 计算中各个特征对的信Gini指数，选择指数值最大的特征，如果最大Gini指数小于给定阈值, 那么构建节点并设置占比最大的类作为标签，返回；否则继续 根据划分数据集, 对每个数据集，跳转到1，生成新的叶节点。 剪枝： 输入：CART算法生成的决策树 输出：最优决策树 自下而上地对各内部节点计算, 这里表示以为根节点的子树， 是对训练数据的预测误差，是的叶节点个数 对的内部节点进行剪枝，并对叶节点以多数表决确定其类标签，得到树 如果不是由根节点及两个叶结点构成的树，跳转步骤2. 否则令 采用交叉验证法在子树序列中选择最优子树","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"logic regression","slug":"logic-regression","permalink":"http://yourthomaslee.github.io/tags/logic-regression/"}]},{"title":"Machine learning foundation 1 - Part 3. Perception machine and support vector machine","slug":"Machine learning foundation 1.2 - perception machine and support vector machine","date":"2023-02-11T02:40:05.000Z","updated":"2023-02-28T12:40:37.345Z","comments":true,"path":"2023/02/11/Machine learning foundation 1.2 - perception machine and support vector machine/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Machine%20learning%20foundation%201.2%20-%20perception%20machine%20and%20support%20vector%20machine/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 2. Support Vector Machine 理论直觉:找一条直线将两类数据分开, 并使得间隔最大化 线性可分支持向量机 模型假设 给定二分类数据集, 其中, 存在一个线性函数使得对于 我们有, 否则. 模型结构: . 模型评估: 在分类正确的前提下, 将几何间隔最大化, 可写成受限于, 条件下的损失函数(几何间隔). 模型的优化: 考虑函数间隔受的倍数影响, 设置, 则原始损失函数可以变为 令, 引入松弛变量转换不等式条件为等式条件, 得到. 得到Lagrange函数 $$ L(w,\\lambda,a)=\\frac{1}{2}+\\sum_{i=1}^{n}\\lambda_i[1-y_i(wx_i+b)+a_i^2],,\\lambda_i\\geq 0\\notag\\ \\begin{equation} \\left { \\right. \\end{equation} $$ 典型的Lagrange问题: 原始问题为是定义在上的连续可微函数, 约束优化问题. 相应Lagrange函数, 此处. ​ slater条件: 是仿射函数, 存在, 不等式约束严格成立. ​ KKT条件: 假设和是凸函数, 是仿射函数, 并且不等式约束是严格可行的, 则$x^,\\alpha^,\\beta^*$分别是原始问题和对偶问题的解得充分必要条件是满足下面的KKT条件: $\\nabla_xL(x^,\\alpha^,\\beta^*)=0$ $\\alpha^c_i(x^)\\geq0,i=1,2,\\cdots,k$ $c_i(x^)\\leq0,; \\alpha_i^\\geq0,i,=1,2,\\cdots,k$. 可得KKT条件 基于KKT条件将以上优化问题转化为, 接下来计算Lagrange函数的偏导数. ​ 令得到, 代入中, 得到 ​ 最后使用梯度下降优化即可. 线性支持向量机 允许有部分数据函数间隔小于1, 但必须为该点引入损失 损失函数变为. Lagrange函数为. 其相应对偶问题转化. 相应偏导数 . 代入上式可得. 核函数: 线性核, 速度快, 无法处理非线性; 多项式核, 参数数量较多, 不稳定, 能处理非线性; 高斯核, 耗时, 能处理非线性数据; 包含的问题: 支持向量的确定, SMO算法, 字符串核函数.","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"perception machine","slug":"perception-machine","permalink":"http://yourthomaslee.github.io/tags/perception-machine/"},{"name":"support vector machine","slug":"support-vector-machine","permalink":"http://yourthomaslee.github.io/tags/support-vector-machine/"}]},{"title":"Leetcode 1223. Dice Roll Simulation","slug":"Leetcode 1223","date":"2023-02-10T02:40:05.000Z","updated":"2023-02-22T01:24:45.104Z","comments":true,"path":"2023/02/10/Leetcode 1223/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/10/Leetcode%201223/","excerpt":"","text":"The problem description can be found at the link Solution explanation can be referred at link Solution: 123456789101112131415161718192021class Solution {public: static constexpr int mod = 1E9 + 7; int dieSimulator(int n, vector&lt;int&gt;&amp; rollMax) { vector d(n + 1, vector&lt;int&gt;(6, 0)); vector&lt;int&gt; sum(n + 1, 0); sum[0] = 1; for (int i = 1; i &lt;= n; i++) { for (int j = 0; j &lt; 6; j++) { int pos = max(i - rollMax[j] - 1, 0); int sub = ((sum[pos] - d[pos][j]) % mod + mod) % mod; d[i][j] = ((sum[i - 1] - sub) % mod + mod) % mod; if (i &lt;= rollMax[j]) { d[i][j] = (d[i][j] + 1) % mod; } sum[i] = (sum[i] + d[i][j]) % mod; } } return sum[n]; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hard level","slug":"hard-level","permalink":"http://yourthomaslee.github.io/tags/hard-level/"},{"name":"dynamic programming","slug":"dynamic-programming","permalink":"http://yourthomaslee.github.io/tags/dynamic-programming/"},{"name":"interesting problem","slug":"interesting-problem","permalink":"http://yourthomaslee.github.io/tags/interesting-problem/"},{"name":"combination","slug":"combination","permalink":"http://yourthomaslee.github.io/tags/combination/"}]},{"title":"Machine learning foundation 1 - Part 2. Logic regression and maximum entropy models","slug":"Machine learning foundation 1.1 - logic regression and maximum entropy model","date":"2023-02-10T02:40:05.000Z","updated":"2023-02-11T10:23:15.092Z","comments":true,"path":"2023/02/10/Machine learning foundation 1.1 - logic regression and maximum entropy model/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/10/Machine%20learning%20foundation%201.1%20-%20logic%20regression%20and%20maximum%20entropy%20model/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 Outline [TOC] 1. 最大熵原理 熵§是一个评估信息（也叫不确定性）的一个函数，当分布趋向于均匀分布的时候，熵达到最大。 最大熵原理认为，学习概率模型时，在满足约束条件的情况下（拟合训练数据），在所有可能得概率模型(分布)中，熵最大的模型是最好的模型（对所有未知情况保持平等的态度，也就是等可能）。 1.1 最大熵模型的定义 我们考虑具体的一个学习任务，假设特征(可以自己预设和自己定义，提供拓展性)已经被形式化成以下函数 与满足某一事实否则 在经验分布上特征函数的期望值为, 引入模型后为, 如果训练数据中对任务足够多的信息，那么可以认为有. 定义 1. 假设满足所有约束条件的模型集合为, 定义在条件概率分布上的条件熵为§, 则模型集合中条件熵§最大的模型称为最大熵模型。 1.2 最大熵模型的学习 最大熵模型的学习过程就是求解最大熵模型的过程。已有的求解方式有两种，一种是极大似然估计，另外一种是转化对偶问题求解。此处陈列两种方式对优化目标的推演过程。 优化目标：给定训练数据集和任务所关心的一系列特征函数, 需要最大化条件信息熵§, 对偶问题: 优化目标可以转化为, 在此基础上将约束通过拉格朗日乘子法写作如下公式 Misplaced & L(P,w)=&amp;\\sum_{x,y}\\hat P(x)P(y|x)\\log P(y |x) + w_0(1 - \\sum_y P(y|x)) \\&amp;+ \\sum_{i=1}^{n}w_i(\\sum_{x,y}\\hat P(x,y)f_i(x,y) - \\sum_{x,y}\\hat P(x)P(y|x)f_i(x,y))\\ =&amp;\\sum_{x,y}\\hat P(x)P(y|x)(\\log P(y|x) - \\sum_{i=1}^n w_if_i(x,y))\\ &amp;- w_0 \\sum_y P(y|x) + \\sum_{i=1}^{n}\\sum_{x,y}w_i\\hat P(x,y)f_i(x,y) +w_0 最优化的原始问题是, 对偶问题是. 先求解内部极小化问题, 有 Misplaced & \\frac{\\partial L(P,w)}{\\partial P(y,x)} =&amp;\\sum_{x,y}\\hat P(x)(\\log P(y|x) - \\sum_{i=1}^nw_if_i(x,y) + 1) - \\sum_y w_0\\ =&amp; \\sum_{x,y}\\hat P(x) (\\log P(y|x) + 1 - w_0 - \\sum_{i=1}^n w_if_i(x,y)) 令偏导为0得到. 也就是, 由于得到，也就是说, 为规范化因子。 代入结论再求解极大化问题 得到之间的关系解得的值。 极大似然估计 根据上面步骤的中间结果可以知晓, 有了概率以后可以使用极大似然估计 Misplaced & L_{\\hat P}(P_w) &amp;= \\log \\prod_{x,y}P(y|x)^{\\hat P(x,y)} \\ &amp;= \\sum_{x,y}\\hat P(x,y)\\log P(y|x) \\ &amp;= \\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nw_if_i(x,y)-\\sum_x\\hat P(x)\\log Z_w(x) 如果将代入到公式(2)中，那么可以得到相同的结果。 这证明最大熵模型的对偶问题和极大似然估计二者是等价的。 最优化算法 最大熵模型学习归结为以似然函数为目标函数的最优化问题，通常使用迭代算法求解。从最优化的观点看，这时的目标函数是光滑的凸函数，因此多种最优化的方法都适用，保证能找到全局最优解。常用的方法有改进的迭代尺度法、梯度下降法、牛顿法或拟牛顿法。 优缺点 优点：1. 建模时，实验者只需要集中精力选择特征，不需要花费精力考虑如何使用这些特征； 2. 每个特征对概率分布的贡献由算法迭代训练得到的参数决定，可以很灵活地选择特征，使用各种不同类型的特征，且容易更换； 3. 利用最大熵建模，不需要使用数据独立同分布假设，参数平滑也可以通过特征选择的方式加以考虑 缺点： 最大熵模型的计算量巨大，在工程实现方法的好坏决定了模型的使用与否。 2. 逻辑回归模型 逻辑回归可以认为是最大熵模型在二分类问题上的一个模型实例。 定义 2. [逻辑斯谛分布]设是连续随机变量，服从逻辑斯谛分布具有下列分布函数和密度函数 式中为位置参数， 为形状参数。形状参数的值越小， 曲线中心附近增长的越快。 定义3. [逻辑回归模型] 二项逻辑斯谛回归模型用如下的条件概率分布来进行拟合数据： 这里是输入， 是输出，和是参数权重和偏置。 该模型有一个显著的特点是事件发生的几率和不发生的几率的比值可以写作 § 模型参数估计使用最大似然法估计模型参数，从而得到一个具体的模型 Misplaced & L(w) =&amp; \\log \\prod_{i=1}^N p^{y_i}(1-p)^{1-y_i}\\ =&amp; \\sum_{i = 1}^N [y_i\\log p + (1 - y_i)\\log(1 - p)]\\ =&amp; \\sum_{i = 1}^N [y_i\\log\\frac{p}{1-p} + \\log(1-p)]\\ =&amp; \\sum_{i = 1}^N [y_i(w \\cdot x + b) - \\log(1 + \\exp(w \\cdot x + b))] 由此最大化似然概率得到相应的的估计值。","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"logic regression","slug":"logic-regression","permalink":"http://yourthomaslee.github.io/tags/logic-regression/"},{"name":"maximum entropy model","slug":"maximum-entropy-model","permalink":"http://yourthomaslee.github.io/tags/maximum-entropy-model/"}]},{"title":"Leetcode 1797. Design Authentication Manager","slug":"Leetcode 1797","date":"2023-02-09T02:40:05.000Z","updated":"2023-02-20T01:05:25.451Z","comments":true,"path":"2023/02/09/Leetcode 1797/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/09/Leetcode%201797/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425class AuthenticationManager {public: int timeToLive; map&lt;string, int&gt; u2t; AuthenticationManager(int timeToLive) { this-&gt;timeToLive = timeToLive; } void generate(string tokenId, int currentTime) { u2t[tokenId] = currentTime; } void renew(string tokenId, int currentTime) { if(u2t.find(tokenId) != u2t.end() &amp;&amp; currentTime - u2t[tokenId] &lt; timeToLive) u2t[tokenId] = currentTime; } int countUnexpiredTokens(int currentTime) { int ans = 0; for(auto x: u2t){ if(currentTime - x.second &lt; timeToLive) ans++; } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"}]},{"title":"Leetcode 1233. Remove Sub-Folders from the Filesystem","slug":"Leetcode 1233","date":"2023-02-08T02:40:05.000Z","updated":"2023-02-20T01:08:11.230Z","comments":true,"path":"2023/02/08/Leetcode 1233/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/08/Leetcode%201233/","excerpt":"","text":"Problem description can be found at link My solution: 12345678910111213141516171819class Solution {public: vector&lt;string&gt; removeSubfolders(vector&lt;string&gt;&amp; folder) { sort(folder.begin(), folder.end()); vector&lt;string&gt; ans; int p = 0, len = 0; ans.emplace_back(folder[0]); for(int i = 1; i &lt; folder.size(); ++i){ len = min(folder[i].size(), folder[p].size()); if(folder[i].substr(0, len) == folder[p].substr(0, len) &amp;&amp; folder[i][len] == '/'){ continue; }else{ ans.emplace_back(folder[i]); p = i; } } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"array","slug":"array","permalink":"http://yourthomaslee.github.io/tags/array/"}]},{"title":"Machine learning foundation 0 - framework","slug":"Machine learning foundation 0 - framework","date":"2023-02-08T02:40:05.000Z","updated":"2023-02-19T03:19:01.681Z","comments":true,"path":"2023/02/08/Machine learning foundation 0 - framework/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/08/Machine%20learning%20foundation%200%20-%20framework/","excerpt":"","text":"基础概念 任务：给定一定量的数据，利用模型归纳、总结、学习数据中的规律和知识，应用到新数据的观察、评估、预测中 学习：如果一个系统能够通过执行某个过程改进它的性能， 这就是学习（Herbert A. Simon） 统计学习：从给定的、有限的、用于学习的训练数据集合(training data)出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间(hypothesis space); 应用某个评价准则(evaluation criterion)，从假设空间中选取一个最优模型，使它对已知的训练数据及位置的测试数据在给定评价准则下有最优的预测；最优模型的选取由算法实现。 其重要性在于（1）可以处理海量数据；（2）被证明是计算机智能化的有效手段；（3）是计算机学科发展的重要组成部分； 统计学习分类：从任务上来说，一般包括监督学习、无监督学习、强化学习。有时还包括半监督学习、主动学习；[李航， 统计学习方法(2rd)] 标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。监 督学习的本质是学习输入到输出的映射的统计规律。 无监督学习是指从无标注数据中学习预测模型的机器 学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。无 监 督 学 习的 本 质 是 学 习 数 据 中 的 统 计规 律 或 潜 在 结 构 强化学习(reinforcement learning)是指智能系统在与环境的连续互动中学习 最优行为策略的机器学 习问题。假设智能 系统与环境的互动基于马尔可 夫决策过 程(Markov decision process)，智能系统能观测到的是与环境互动得到的数据序列。 强化学习的本质是学习最优的序贯决策。强化学习的目标就是在所有可能的策略中选出价值函数最大的策略，而在实际 学习中往往从具体的策略出发，不断优化己有策略。 半监督学习(semi-supervised learning) 是指利用标注数据和未标注数据学习预 测模型的机器学 习问题。通常有少量标注数据、大量未标注数据，因为标注数据的构 建 往 往 需 要 人 工， 成 本 较 高 ， 未 标 注 数 据 的 收 集 不 需 太 多 成 本 。 半 监 督 学 习 旨 在 利 用 未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习 效果。 主动学习(active learning)是指机器不断主动给出实例让教师进行标注，然后利 用标注数据学习预测模型的机器学习问题。通常的监督学习使用给定的标注数据，往 往是随机得到的，可以看作是“ 被动学习”，主动学习的目标是找出对学习最有帮助的 实例让教师标注，以较小的标注代价，达到较好的学习效果。 从模型的角度上说，可以分为 概率模型（决策树、朴素贝叶斯、隐马尔科夫模型、条件随机场、概率潜在语义分析、高斯混合模型等）和非概率模型（感知机、支持向量机、近邻、AdaBoost、均值聚类、潜在语义分析以及神经网络）； 线性模型（感知机、线性支持向量机、近邻、均值聚类、潜在语义分析）和非线性模型（核支持向量机、AdaBoost、神经网络）； 参数化模型（感知机、朴素贝叶斯、逻辑回归、均值聚类、高斯混合模型等等）和非参数化模型（决策树、支持向量机、AdaBoos、近邻、语义分析和狄利克雷分配） 按算法分类则可以分为在线学习(online learning)和批量学习(batch learning); 按技巧分类则有贝叶斯学习（其 主 要 想 法 是 ， 在 概 率模 型 的 学 习 和 推 理 中 ， 利 用 贝 叶斯定理，计算在给定数据条件 下模型的条件概率，即后验概率，并应用这个原理进 行模型的估计，以及对数据的预测。将模型、未观测要素及其参数用变量表示，使用 模型的先验分布是贝叶斯学习的特点）、核方法（使用核函数表示和学习非线性模型的一种机器学习方 法）。 统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下： 得到一个有限的训练数据集合； 确定包含所有可能的模型的假设空间，即学习模型的集合； 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）； 实现求解最优模型的算法，即学习的算法（优化算法）； 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）； 利用学习的最优模型对新数据进行预测或分析； [由于李航的泛化下界分析内容没有写成闭包，此处暂时不进行深入学习，后续再复习] 后续将从两个维度进行学习，第一个是机器学习常见模型进行学习，这一部分更加侧重理论，第二个是按实现步骤进行学习，更加侧重应用和思考 有空可以后续学习的信息： 机器学习理论： Guarantees in Machine learning pen-and-paper exercises in machine learning： https://github.com/michaelgutmann/ml-pen-and-paper-exercises 模型预测可解释性： SHAP (SHapley Additive exPlanations)","categories":[],"tags":[{"name":"machine learning framework","slug":"machine-learning-framework","permalink":"http://yourthomaslee.github.io/tags/machine-learning-framework/"}]},{"title":"Machine learning foundation 1 - Part 1. linear regression","slug":"Machine learning foundation 1.0 - linear regression","date":"2023-02-08T02:40:05.000Z","updated":"2023-06-10T09:34:42.874Z","comments":true,"path":"2023/02/08/Machine learning foundation 1.0 - linear regression/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/08/Machine%20learning%20foundation%201.0%20-%20linear%20regression/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 Outline 1234567891011121314graph LRA(线性回归) --&gt; B[直觉]A(线性回归) --&gt; C[模型]A(线性回归) --&gt; D[优化]A(线性回归) --&gt; E[拓展]B[直觉] --&gt; F[找到一条直线或一个平面能够根据输入的特征向量来更好的预测输出y的值]B[直觉] --&gt; G[损失函数:平方损失,绝对值损失,huber损失]C[模型] --&gt; N[线性函数]D[优化] --&gt; H[梯度下降]D[优化] --&gt; I[正规方程组]E[拓展] --&gt; J[Lasso回归-L1 Norm]E[拓展] --&gt; K[岭回归-L2 Norm]E[拓展] --&gt; L[局部加权线性回归]E[拓展] --&gt; M[ElasticNet-L1 L2 Norm] 1. 直觉与目标 简单来说，线性回归算法就是**找到一条直线（一元线性回归）或一个平面（多元线性回归）能够根据输入的特征向量来更好的预测输出y的值。**其本质含义在于 X 与 Y 是线性相关的。 在有了该直觉之后，我们的第一个目标是根据给定的如何评估一条直线是否合理，也就是如何评估出多个不同的直线的序，目前比较典型的思路是设计一个函数，输入给定的模型和数据，输出键值，比较键值大小就可以知晓哪一条直线是最优的(一般默认越小越好)。就目前来说，典型的键值(损失)函数有三种，具体公式如下，损失函数图如下。 平方损失： , 对异常点有较大的惩罚，不够robust。 绝对值损失：，在0处不可导，不易优化 Huber损失：，该损失函数是1,2的综合，较为鲁棒 第一个目标达成后，我们的目标就变为根据数据将不合理的直线调整变换为合理，该过程也叫学习，在机器学习中叫优化, 该部分内容详见第3部分。 2. 模型 给定训练数据, 线性回归的模型设定为 一般地，我们使用平方损失函数来做为衡量直线优劣的指标，也即. 朴素的二元线性回归：梯度下降法 Missing \\end{aligned} \\begin{aligned}\\frac{\\partial L}{\\partial w}=&amp;\\sum_{i=1}^{n}2(wx_i+b-y_i)x_i\\&amp;=2\\sum_{i=1}^{n}w(x_i)^2+bx_i-x_iy_i\\\\frac{\\partial L}{\\partial b}=&amp;\\sum_{i=1}^{n}2(wx_i+b-y_i)=0\\&amp;\\Rightarrow b=\\frac{\\sum_{i=1}^{n}y_i-wx_i}{n}\\\\frac{\\partial L}{\\partial w}=&amp;2\\sum_{i=1}^{n}w(x_i)^2+(\\overline y-w\\overline x)x_i-x_iy_i\\&amp;=2\\sum_{i=1}^{n}[w(x_i)^2+\\overline y x_i - w \\overline x x_i -x_iy_i]=0\\&amp;\\Rightarrow w=\\frac{\\sum_{i=1}^{n}[x_iy_i-x_i\\overline y]}{\\sum_{i=1}^{n} [(x_i)^2-\\overline x x_i]}=\\frac{\\sum_{i=1}^{n}x_iy_i-\\frac{1}{n}\\sum_{i=1}^{n}x_i\\sum_{i=1}^{n} y_i}{\\sum_{i=1}^{n} (x_i)^2-\\frac{1}{n}\\sum_{i=1}^{n} x_i \\sum_{i=1}^{n}x_i}\\&amp;=\\frac{\\sum_{i=1}^{n}(x_i-\\overline x)(y_i-\\overline y)}{\\sum_{i=1}^{n}(x_i-\\overline x)^2}\\\\end{aligned} 注意: 2.1 最小二乘法 对该模型最原始计算方法为最小二乘法，给定训练数据如下 则有 2.1.1 最小二乘法的概率角度的视角 设误差服从正态分布，那么有~，则有~, 公式建模 极大似然估计： 3. 优化 优化一般有两种，一种是正规方程组，一种是梯度下降法。已知损失函数 正规方程组: 对损失函数求导，即有, 令该式子为0则得 梯度下降：选择批量大小为, 那么有 正规方程组需要保证没有特征之间没有相关性，另外也无法应用于大规模的线性回归，而梯度下降需要选择合适的学习率，适合大规模场景下的线性回归，同时，随机梯度下降无法保证得到的解一定是最优，但正规方程组可以保证解为最优。 4. 拓展 4.1 岭回归 由于正规方程组需要保证可逆，对于有个样本，有个属性的数据，如果，那么不可逆。岭回归通过增加L2正则化来保证可逆。具体来说损失函数如下 加入的正则化有两个效果，一个是保证可逆，另一个是抑制过拟合。 如果样本数据过少导致线性回归拟合较差，则考虑采用岭回归。如何输入特征的维度很高,而且是稀疏线性关系的话， 岭回归就不太合适,考虑使用Lasso回归。L2正则假设参数的先验分布是Gaussian分布，可以保证模型的稳定性，也就是参数的值不会太大或太小. L2范数是各参数的平方和再求平方根，我们让L2范数的正则项最小，可以使的每个元素都很小，都接近于0。但它不会是每个元素为0，而只是接近于0。越小的参数说明模型越简单，越简单的模型越不容易产生过拟合现象。L2不能控制feature的“个数”，但是能防止模型overfit到某个feature上 4.2 Lasso回归 Lasso 回归的本质是 线性回归 + L1 正则化。 L1正则化(Lasso回归)可以使得一些特征的系数变小,甚至还使一些绝对值较小的系数直接变为0，从而增强模型的泛化能力 。对于高的特征数据,尤其是线性关系是稀疏的，就采用L1正则化(Lasso回归),或者是要在一堆特征里面找出主要的特征，那么L1正则化(Lasso回归)更是首选了。L1正则假设参数的先验分布是Laplace分布，可以保证模型的稀疏性，也就是某些参数等于0, L1正则化是L0正则化的最优凸近似，比L0容易求解，并且也可以实现稀疏的效果, L1是控制feature“个数”的，并且鼓励模型在少量几个feature上有较大的权重。 4.3 局部加权线性回归 在线性回归中， 由于最终拟合出来的曲线是一条直线，其拟合能力极为有限（也可以解释为线性回归所求的是具有最小均方误差的无偏估计），因此很容易造成欠拟合现象， 而针对这个问题，有人提出了局部线性回归(LWR)。 在LWR中， 其损失函数为： 矩阵表示 此时，使用回归方程求得： 而通常， 服从高斯分布， 在目标区域附近指数型衰减; 其中， k 值越小，敏感半径越小。值决定了线性回归的拟合半径 4.3 ElasticNet回归 ElasticNet回归本质上是线性回归 + L1正则化 + L2 正则化，损失函数变为： Reference","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"linear regression","slug":"linear-regression","permalink":"http://yourthomaslee.github.io/tags/linear-regression/"}]},{"title":"Leetcode 1604. Alert Using Same Key-Card Three or More Times in a One Hour Period","slug":"Leetcode 1604","date":"2023-02-07T02:40:05.000Z","updated":"2023-02-20T01:06:15.976Z","comments":true,"path":"2023/02/07/Leetcode 1604/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/07/Leetcode%201604/","excerpt":"","text":"Problem description can be found at link My solution: 12345678910111213141516171819202122232425262728293031class Solution {public: struct op{ string name; int time; }; static bool comp(op&amp; a, op&amp; b){ if(a.name &lt; b.name){ return true; }else if(a.name == b.name){ return a.time &lt; b.time; }else return false; } vector&lt;string&gt; alertNames(vector&lt;string&gt;&amp; keyName, vector&lt;string&gt;&amp; keyTime) { vector&lt;op&gt; x; op t; for(int i = 0; i &lt; keyName.size(); ++i){ t.name = keyName[i]; t.time = stoi(keyTime[i].substr(0, 2)) * 60 + stoi(keyTime[i].substr(3, 2)); x.emplace_back(t); } sort(x.begin(), x.end(), comp); vector&lt;string&gt; ans; for(int i = 2; i &lt; x.size(); ++i){ if(ans.size() &gt; 0 &amp;&amp; x[i].name == ans[ans.size() - 1]) continue; if(x[i].name == x[i - 2].name &amp;&amp; abs(x[i].time - x[i - 2].time) &lt;= 60) ans.emplace_back(x[i].name); } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"}]},{"title":"Curriculum vitae - Baizhen Li","slug":"Curriculum Vitae - Baizhen Li","date":"2022-12-26T13:54:13.432Z","updated":"2023-02-27T04:04:36.105Z","comments":true,"path":"2022/12/26/Curriculum Vitae - Baizhen Li/","link":"","permalink":"http://yourthomaslee.github.io/2022/12/26/Curriculum%20Vitae%20-%20Baizhen%20Li/","excerpt":"","text":"Contact information: Bricklees [at] alumni [dot] tongji [dot] edu [dot] cn || baizhen9406 [at] 163 [dot] com Education Tongji UNIVERSITY 06/2018 - 03/2021 M.E., Computer Technology. GPA: 87/100 Thesis: Research on dialogue state tracking algorithm based on cross-layer fusion Awards and honors: National Scholarship(2020), Second Prize of the 15th China Post-graduate Mathematical Contest in Modelling, Outstanding Dissertation Award YANTAI UNIVERSITY 06/2013 - 07/2017 B.E., Computer Science and Technology. GPA: 79/100 Thesis: Research on knowledge acquisition algorithms: a discernibility matrix approach Awards and honors: Outstanding Dissertation Award, Third Prize of LAN QIAO International Collegiate Programming Contest Experiences I. Research experiences From 08/2019 to 12/2020, I participated in “Research on the Refined Description and Interpretability of Targets under Surveillance Video”(National natural science foundation of China, No. 61976160). I was in charge of models that provide task-oriented descriptions of a picture collected from surveillance video while working as a researcher under the direction of professor Zhihua Wei and associate professor Lijun Sun. From 06/2018 to 07/2019, I took part in \"Topic Analysis Technology based on Natural Language Processing” (application research cooperated with the key lab of information network security, China ministry of public security, No. C18608). I created topic analysis-based detection techniques for illicit website detection while working as a researcher and developer under the direction of professor Zhihua Wei and associate professor Lijun Sun. From 03/2014 to 06/2017, I participated in “Knowledge Space Research based on Granular Computing Method” (national natural science foundation of China youth science fund project, No. 61403329). I created two more effective rough sets-based knowledge discovery algorithms as a research assistant under the direction of associate professor Nan Zhang. II. Work/Internship experiences BAIDU CHINA CO., LTD. 03/2021 – 05/2022 As an engineer, I was in charge of the real-time bidding system’s cost-per-thousand-impression calibration(CTIA) module. By tweaking the algorithm’s parameters and state estimates, I improved the proportional-integral-derivative (PID) control algorithm’s performance in CTIA. HAIYIZHI INFORMATION TECHNOLOGY CO., LTD. 06/2020 – 09/2020 I created a robot that serves as the customer support representative in the postal service’s online chat. After that, I used a non-autoregressive dialog state tracking model to reduce the inference latency for dialog state tracking. Publications [1] Baizhen Li, Yibin Zhan, Zhihua Wei, Shikun Huang, Lijun Sun: Improved non-autoregressive dialog state tracking model. CCRIS 2021: 199-203 [2] Baizhen Li, Zhihua Wei, Duoqian Miao, Nan Zhang, Wen Shen, Chang Gong, Hongyun Zhang, Lijun Sun: Improved general attribute reduction algorithms. Inf. Sci. 536: 298-316 (2020) [3] Baizhen Li, Wei Chen, Zhihua Wei, Hongyun Zhang, Nan Zhang, Lijun Sun: Quick Maximum Distribution Reduction in Inconsistent Decision Tables. IJCRS 2020: 169-182 [4] Nan Zhang, Baizhen Li, Zhongxi Zhang, Yanyan Guo: A Quick Algorithm for Binary Discernibility Matrix Simplification using Deterministic Finite Automata. Inf. 9(12): 314 (2018)","categories":[],"tags":[]},{"title":"Note - Prioritized training on points that are learnable worth learning and not yet learnt","slug":"Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt","date":"2022-07-22T02:40:05.000Z","updated":"2022-12-27T03:36:11.314Z","comments":true,"path":"2022/07/22/Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/22/Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt/","excerpt":"","text":"This paper introduce RHO_LOSS, which selects points that are learnable, worth learning, and not yet learnt. RHO-LOSS trains in far fewer steps than prior art, improves accuracy, and speeds up training on a wide range of datasets, hyperparameters, and architectures (MLPs, CNNs, and BERT) Code: https://github.com/OATML/RHO-Loss Concepts: a model with parameter training on dataset using stochastic gradient descent(SGD) : a batch of size from dataset at step with is the predictive distribution of the current model, where is the sequence of data the model was trained on before training step $ D_{ho} ={ (x_{ho}, y_{ho}) } {i=1}^{n{ho} } x_{ho}y_{ho}p_{true}(x′, y′)D$. Intuition: Previous online batch selection methods aim to select points that minimize the training set loss. Instead, we aim to select points that minimize the loss on a holdout set. We aim to acquire the point that would minimize the negative log-likelihood/cross-entropy loss on the holdout set: $ arg \\min {(x,y)\\in B_t} - \\log p(y{ho}|x_{ho};D_t \\cup (x, y))$ [get similar distribution as holdout set] Inference: For a model using a point estimate of (such as an MLE or MAP), rather than a distribution over , the holdout loss factorises and (up to a constant factor) forms a Monte Carlo approximation of the expected loss under : , where denotes the cross-entropy loss: , $$ \\log p(y_{ho}|x_{ho};D_t \\cup (x, y)) = \\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x,x_{ho};D_t)}[Bayes; rule]\\ =\\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x;D_t)}[conditional; independence; rule]\\ \\propto L[y|x;D_t] - L[y|x;D_{ho},D_t]\\ \\sim L[y|x;D_t] - L[y|x;D_{ho}]\\ \\Rightarrow \\arg \\max {(x,y) \\in B_t} L[y|x;D_t] - L[y|x;D{ho}]\\quad[training; loss - ;irreducible; holdout; loss] $$ Algorithm: Exploring: why not design a new simpler loss based on rough set thoery? it seems RHOLOSS is still a little expensive in implementation and computation. Actually this work provides a good way to think about the training sample selection problem. There are still room for some more further researches in computation simplicity and cost aspects","categories":[],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"http://yourthomaslee.github.io/tags/deep-learning/"},{"name":"training sample selection","slug":"training-sample-selection","permalink":"http://yourthomaslee.github.io/tags/training-sample-selection/"}]},{"title":"Note-Trainable learning rate","slug":"Note-Trainable-learning-rate","date":"2022-07-19T09:26:53.000Z","updated":"2023-06-10T09:34:42.741Z","comments":true,"path":"2022/07/19/Note-Trainable-learning-rate/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/19/Note-Trainable-learning-rate/","excerpt":"","text":"Problem: selecting an appropriate learning rate is a challenge considering different model structures and datasets. Work: we propose an algorithm for automatically adjusting the learning rate during the gradient descent (line search method) Given the weights’ gradients, one could estimate if an overestimation or an underestimation of learning rate could further reduce the task loss by casting the learning rate as an extra trainable parameter. Problem Statement: the gradient descent framework (GD). vanilla form: where is learning rate, is loss function and is the model parameters at iteration . In vanilla GD, Is treated as a hyperparameter and does not contribute to the loss. We introduce an augmented loss term , where we consider as the learnable variable. . Something noticing is that minimizing is equivalent to finding the optimal step-size for current . Naive GD-TLR: A straightforward idea is to apply GD over : , where hyperparameter Controls the updates of the initial learning rate Disadvantages: the addition of requires an extra forward-backward pass in order to compute the introduction of a GD step for creates the extra hyperparameter Efficient GD-TLR: let Denotes a standard feed-forward network of Layers, where and denote the non-linear activation and linear transformation corresponding to layer respectively. For the convenience of writing, we just consider the linearity of a single layer , where is the input from the previous layer, is the matrix of parameters, is the output. (, ) denotes the variables after GD update. So we have First-order gradient and insight: Assuming that corresponds to a specific layer, the gradient of the augmented loss compute as: the learning rate gradient can be expressed as the inner product of consecutive gradients , as a result we can rewrite equation (2) as $ \\frac{\\partial L_\\alpha}{\\partial \\alpha}|{a=\\alpha_t} = -&lt;\\triangledown L(w_t), \\triangledown L(w{t - 1})&gt; = -&lt;g_t, g_{t-1}&gt; $. The derived gradient (take indicator ind for simplifing) has an intuitive interpretation: Ind &gt; 0: the learning rate should be increased Ind &lt; 0: the learning rate should be decreased Ind = 0: either we reached a converged state of gradient directions are perpendicular. Second-order gradient: a newton-based method requires Hessian computations/approximations of the network’s weights, and the problem at hand has an intuitive analytical form, using only first-order weight gradients, as following suggests: $$ \\frac{\\partial^2L}{\\partial \\alpha^2}|{\\alpha=\\alpha_t}=\\frac{4}{\\alpha}&lt;g_t, g_t-g{t-1}&gt;=\\frac{4}{\\alpha_t}(||g_t||^2-&lt;g_t,g_{t-1}&gt;) \\eta_t = \\frac{\\alpha_t}{\\max(4&lt;g_t, g_t-g_{t-1}), c^{-1}&lt;g_t, g_{t-1}&gt;)} $$ where we form an overall bound on the update of which imposes smoother behavior (c was set as 1/4 in paper) Efficient GD-TLR Input: number of iterations , initial weights , learning rate , hyperparameter Output: optimized weights step 1: initialize = 0 step 2: for to do step 3: single forward-backward pass: step 4: compute step 5: update alpha according to Equation 2 and 3 [ ] step 6: update w: ; step 7: ; step 8: end for Exploring problem： the analysis in appendices, may be we will explore it next time I read it. Interested in automatical layer-wise learning rate in the future research the performance and the disadvantage of the algorithm. I think there is still necessity of experiment","categories":[],"tags":[{"name":"trainable learning rate","slug":"trainable-learning-rate","permalink":"http://yourthomaslee.github.io/tags/trainable-learning-rate/"}]},{"title":"Notes-mitigating neural network overconfidence with logit normalization","slug":"Note-mitigating neural network overconfidence with logit-normalization","date":"2022-07-11T08:49:33.000Z","updated":"2022-12-27T03:34:16.757Z","comments":true,"path":"2022/07/11/Note-mitigating neural network overconfidence with logit-normalization/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/11/Note-mitigating%20neural%20network%20overconfidence%20with%20logit-normalization/","excerpt":"introduce Logit Normalization (LogitNorm), a simple fix to the cross-entropy loss (by enforcing a constant vector norm on the logits in training), to deal with overfitting or overconfidence for both in- and out-of-distribution inputs.","text":"introduce Logit Normalization (LogitNorm), a simple fix to the cross-entropy loss (by enforcing a constant vector norm on the logits in training), to deal with overfitting or overconfidence for both in- and out-of-distribution inputs. Problem: we find that even when most training examples are classified to their correct labels, the softmax cross-entropy loss can continue to increase the magnitude of the logit vectors. The growing magnitude during training thus leads to the overconfidence issue, despite having no improvement on the classification accuracy. Work: To mitigate the issue, our key idea behind LogitNorm is to decouple the influence of output’s norm from the training objective and its optimization. This can be achieved by normalizing the logit vector to have a constant norm dur- ing training. In effect, our LogitNorm loss encourages the direction of the logit output to be consistent with the corre- sponding one-hot label, without exacerbating the magnitude of the output. Trained with normalized outputs, the network tends to give conservative predictions and results in strong separability of softmax confidence scores between ID and OOD inputs Codes: https://github.com/hongxin001/logitnorm_ood Core equation: to make sure that the logit vector is a unit vector, it alleviate some challenges in optimization, or rather, let optimization does more things useful! where is logit vector, is the Euclidean norm of the logit vector, and denotes the quantity of different class labels. Comment: This work restricts the numerical bound of logit vector during optimization, and it results better model performance in classification task. Exploring problem： Can we get the better performance if we use label smoothing? what is the difference between LayerNorm and LogitNorm? Is there any other efficient way to implement LogitNorm? Is this work compatible to the paper “Long-Tail Learning via Logit Adjustment” (https://arxiv.org/pdf/2007.07314.pdf)?","categories":[],"tags":[{"name":"overfitting","slug":"overfitting","permalink":"http://yourthomaslee.github.io/tags/overfitting/"},{"name":"logit normalization","slug":"logit-normalization","permalink":"http://yourthomaslee.github.io/tags/logit-normalization/"}]},{"title":"C++ primer plus - 0 concepts","slug":"cpp primer plus - concepts","date":"2022-03-20T15:33:35.180Z","updated":"2023-03-03T02:46:33.561Z","comments":true,"path":"2022/03/20/cpp primer plus - concepts/","link":"","permalink":"http://yourthomaslee.github.io/2022/03/20/cpp%20primer%20plus%20-%20concepts/","excerpt":"","text":"基础知识 C++三种不同的编程方式：过程性编程、面向对象语言、泛型编程(泛型是指创建独立与类型的代码) Unix编译过程： 生成目标代码文件CC spiffy.cpp -&gt; spiffy.o; 而后编译器自动将目标代码文件传递给系统链接程序，该程序将代码与库代码结合起来，生成一个可执行文件spiffy.out 命名空间的引入是为了区分不同库中的相同函数，例如std::cout(两个冒号). 类是用户定义的一种数据类型，要定义类，需要描述它能够表示什么信息和可以对数据执行哪些操作。类描述了一种数据类型的全部属性，包括可使用它执行的操作，对象是根据这些描述创建的实体。需要对特定对象执行被定义允许的操作，需要给改对象发送一条消息，C++提供两种发送消息的方式：使用类方法或者使用已被重载的运算符。 函数原型之于函数就像变量声明之于变量——指出涉及的类型。 数据类型 字符类型的扩充w_char，char16_t, char32_t; bool类型；三种浮点类型float（6位的有效位）, double, long double. 运算符：±*/% const用来修饰常量（常见做法变量名首字母大写） C++11自动类型判断：auto关键字（eg. auto n=100;） 字符串：C-风格的字符串和C++的string（有用的初始化char bird[11]=“Mr. Cheeps”;）字符串用双引号包裹，且默认最后有一个字符’\\0’. 字符串的输入：cin.getline()读取一行，丢弃最后的换行符，cin.get()则读取一行但不丢弃换行符。 C类型的数据组织方式：struct, union, enum 指针：在C语言中，使用malloc来分配内存，不过C++一般使用new来进行内存的分配（typeName* pointer_name= new typeName）。new分配的内存块通常于常规变量声明分配的内存块不同，常规分配的内存都在被称为栈的内存区域中，而new从被称为堆或自由存储区的内存区分配内存。new与delete搭配使用（int * ps=new int; statements; delete ps;delete将释放ps指向的内存，但不会删除ps本身。int* ps=new int[5]; statements; delete [] ps） 数组名字是第一个元素的地址，但地址类型和第一个元素取地址得到的类型是不一样的。 自动存储：在函数内部定义的常规变量使用自动存储空间，被称为自动变量，他们所属的函数被调用时候自动产生，在该函数结束时候消亡，通常存储与栈中。 数组的替代品：vector，类功能强大，但效率稍低。模版类array(C++11特性)，考虑使用at()函数索引值 循环，关系表达式，分支语句，逻辑运算符 逗号运算符：将多个或更多的表达式子合并为一个表达式 typedef工具：C++为类型建立别名的方式有两种，一种使用预处理器#define BYTE char，第二种就是使用关键字typedef来创建别名typedef char byte；基于范围的循环(C++11)：double prices[5]={1,2,3,4,5}; for(double x:prices) cout&lt;&lt;x&lt;&lt;endl; 文件尾条件:常见的字符输入末尾检查：char ch; cin.get(ch); if(cin.fail()==true) 文件尾 cctype字符函数库：isalpha(ch)检查是ch否为字符；isdigits(ch); 函数-C++的编程模块 通用格式： 123456typeName functionName(parameterList);//prototypetypeName functionName(parameterList){ statements; return values;} 指针 volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统，硬件或者其他线程等。遇到这个关键字声明的变量， 编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问 goto: 跳转到制定标签的代码段 const修饰形参，传递指针/地址防止原始数据被破坏；const修饰指针，表明指针指向的值被限定为常量，不可以使用指针修改指向的值。 使用二维数组作为函数参数：int sum(int (*arr)[4], int size); int sum(int arr[][4], int size); 使用指向函数的指针：声明直向函数的指针时，必须指定指针指向的函数类型。这意味着声明应指定函数的的返回类型及参数列表(eg. double pam(int); double (*pf)(int)=pam; (*pf)(5); pf(5);)。当函数指针调用函数时，(*pf)和pf等价。考虑到函数指针类型的复杂，可以考虑使用auto用来做函数指针的声明，也可以考虑使用typedef起别名简化书写。 内联函数：使用inline关键字修饰函数名，并将定义整个放在原型声明的地方 引用：与指针的区别在于必须在声明引用变量时进行初始化，而指针则没有这个限制。引用不能够变换地址，引用后就一直效忠于初始化的变量。左值引用，对变量进行引用。右值引用，对变量的表达式进行引用(double j=12.0; double &amp;&amp; rref=2.0*j+18.5;) 默认参数：与python中的默认参数一样 函数模版：记住实例即可（高级用法：显式具体化，比较复杂，后续再阅读一次） 12345678template &lt;typename AnyType&gt;void Swap(AnyType &amp;a, AnyType &amp;b){ AnyType tmp; tmp=a; a=b; b=tmp;} dynamic_cast:主要用途：将基类的指针或引用安全地转换成派生类的指针或引用，并用派生类的指针或引用调用非虚函数。如果是基类指针或引用调用的是虚函数无需转换就能在运行时调用派生类的虚函数。 前提条件：当我们将dynamic_cast用于某种类型的指针或引用时，只有该类型至少含有虚函数时(最简单是基类析构函数为虚函数)，才能进行这种转换。否则，编译器会报错。 单独编译：将程序分为三部分：头文件，包含结构声明和使用这鞋结构的函数的原型(函数原型、#define或const定义的符号常量，结构声明、类声明、模版声明、内联函数声明)；源代码文件，包含与结构有关的函数的代码；源代码文件，包含调用与结构相关的函数的代码 存储连续性、作用域和链接性：四种存储持续性：自动存储持续性(函数定义的变脸的存储持续性是自动的，开始执行时存在，执行结束自动消亡)，静态存储持续性(static关键字修饰的变量整个运行过程中都存在)，线程存储持续性(让程序能够将计算放在可并行处理的不同线程职工，如果变量使用thread_local修饰，则其生命周期和所属的线程一样长)；动态存储持续性（用new运算符分配的内存将一直存在，指导被delete或程序结束为止）。不在任何函数中的变量将具有文件外的链接性，使用extern来引用其他文件中的变量。static标明变量的链接性为文件内部；mutable指出及时结构或类变量为const，其某个成员也可别更改；const全局变量的链接性为内部。 定位new运算符：new (buffer1) class;可以指定位置进行存储分配，必须包含投文件new 名称空间：namespace的引入避免变量名的冲突，使用using来指明默认空间或某个变量的空间 C++多线程编程基础知识–C++11同步 123456789101112131415161718192021222324252627#include&lt;iostream&gt;#include&lt;thread&gt;automic&lt;long&gt; sum=0L;//不可并行的原子类型变量void fun(){ for(int i=1;i&lt;=1000;i++){ sum+=1; }}/*方案2long sum=0L;std::mutex mtx;void fun(){ for(int i=1;i&lt;=1000;i++){ mtx.lock(); sum+=1; mtx.unlock(); }}*/int main(){ using std::thread; thread t1(fun); thread t2(fun); t1.join(); t2.join(); return 0;} 条件变量同步 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt; using namespace std; mutex mtx;condition_variable cv;bool ready = false; void Thread1() { unique_lock &lt;std::mutex&gt; lck(mtx); //RAII：构造函数中申请分配资源，在析构函数中释放资源 while (false == ready) { cv.wait(lck); //等待其他线程修改条件变量后唤醒，唤醒后判断是否满足条件，不满足继续等待，wait函数进入时持有锁， 加入等待队列和释放锁需要是原子的，函数退出时持有锁 } cout &lt;&lt; \"after wait\" &lt;&lt; endl;} void Thread2() { unique_lock &lt;std::mutex&gt; lck(mtx); ready = true; cout &lt;&lt; \"before notify\" &lt;&lt; endl; cv.notify_one(); //唤醒一个等待的线程} int main() { thread t1(Thread1); thread t2(Thread2); t1.join(); t2.join(); return 0;}","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"http://yourthomaslee.github.io/tags/C/"}]},{"title":"Hello World","slug":"hello-world","date":"2022-03-20T15:33:35.180Z","updated":"2022-03-20T15:33:34.000Z","comments":true,"path":"2022/03/20/hello-world/","link":"","permalink":"http://yourthomaslee.github.io/2022/03/20/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new \"My New Post\" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"life","slug":"life","permalink":"http://yourthomaslee.github.io/tags/life/"},{"name":"value","slug":"value","permalink":"http://yourthomaslee.github.io/tags/value/"},{"name":"bayesian deep learning","slug":"bayesian-deep-learning","permalink":"http://yourthomaslee.github.io/tags/bayesian-deep-learning/"},{"name":"Natural language processing","slug":"Natural-language-processing","permalink":"http://yourthomaslee.github.io/tags/Natural-language-processing/"},{"name":"dialogue state tracking","slug":"dialogue-state-tracking","permalink":"http://yourthomaslee.github.io/tags/dialogue-state-tracking/"},{"name":"dialogue history","slug":"dialogue-history","permalink":"http://yourthomaslee.github.io/tags/dialogue-history/"},{"name":"deep learning concepts","slug":"deep-learning-concepts","permalink":"http://yourthomaslee.github.io/tags/deep-learning-concepts/"},{"name":"activation function","slug":"activation-function","permalink":"http://yourthomaslee.github.io/tags/activation-function/"},{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"medium level","slug":"medium-level","permalink":"http://yourthomaslee.github.io/tags/medium-level/"},{"name":"number theory","slug":"number-theory","permalink":"http://yourthomaslee.github.io/tags/number-theory/"},{"name":"easy level","slug":"easy-level","permalink":"http://yourthomaslee.github.io/tags/easy-level/"},{"name":"sliding windows","slug":"sliding-windows","permalink":"http://yourthomaslee.github.io/tags/sliding-windows/"},{"name":"dynamic programming","slug":"dynamic-programming","permalink":"http://yourthomaslee.github.io/tags/dynamic-programming/"},{"name":"stack","slug":"stack","permalink":"http://yourthomaslee.github.io/tags/stack/"},{"name":"hard level","slug":"hard-level","permalink":"http://yourthomaslee.github.io/tags/hard-level/"},{"name":"feature engineering","slug":"feature-engineering","permalink":"http://yourthomaslee.github.io/tags/feature-engineering/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://yourthomaslee.github.io/tags/machine-learning/"},{"name":"binary operation","slug":"binary-operation","permalink":"http://yourthomaslee.github.io/tags/binary-operation/"},{"name":"string","slug":"string","permalink":"http://yourthomaslee.github.io/tags/string/"},{"name":"multitask learning","slug":"multitask-learning","permalink":"http://yourthomaslee.github.io/tags/multitask-learning/"},{"name":"modular skills","slug":"modular-skills","permalink":"http://yourthomaslee.github.io/tags/modular-skills/"},{"name":"binary number","slug":"binary-number","permalink":"http://yourthomaslee.github.io/tags/binary-number/"},{"name":"transfomer","slug":"transfomer","permalink":"http://yourthomaslee.github.io/tags/transfomer/"},{"name":"attention mechanism","slug":"attention-mechanism","permalink":"http://yourthomaslee.github.io/tags/attention-mechanism/"},{"name":"array","slug":"array","permalink":"http://yourthomaslee.github.io/tags/array/"},{"name":"control theory","slug":"control-theory","permalink":"http://yourthomaslee.github.io/tags/control-theory/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"},{"name":"greedy algorithm","slug":"greedy-algorithm","permalink":"http://yourthomaslee.github.io/tags/greedy-algorithm/"},{"name":"reinforcement learning","slug":"reinforcement-learning","permalink":"http://yourthomaslee.github.io/tags/reinforcement-learning/"},{"name":"optimal control","slug":"optimal-control","permalink":"http://yourthomaslee.github.io/tags/optimal-control/"},{"name":"adaptive control","slug":"adaptive-control","permalink":"http://yourthomaslee.github.io/tags/adaptive-control/"},{"name":"deep first search","slug":"deep-first-search","permalink":"http://yourthomaslee.github.io/tags/deep-first-search/"},{"name":"computational advertising","slug":"computational-advertising","permalink":"http://yourthomaslee.github.io/tags/computational-advertising/"},{"name":"ranking models","slug":"ranking-models","permalink":"http://yourthomaslee.github.io/tags/ranking-models/"},{"name":"deep learning framework","slug":"deep-learning-framework","permalink":"http://yourthomaslee.github.io/tags/deep-learning-framework/"},{"name":"interesting problem","slug":"interesting-problem","permalink":"http://yourthomaslee.github.io/tags/interesting-problem/"},{"name":"priority_queue","slug":"priority-queue","permalink":"http://yourthomaslee.github.io/tags/priority-queue/"},{"name":"breath-first-search","slug":"breath-first-search","permalink":"http://yourthomaslee.github.io/tags/breath-first-search/"},{"name":"recall models","slug":"recall-models","permalink":"http://yourthomaslee.github.io/tags/recall-models/"},{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"Condition random field","slug":"Condition-random-field","permalink":"http://yourthomaslee.github.io/tags/Condition-random-field/"},{"name":"Markov chain","slug":"Markov-chain","permalink":"http://yourthomaslee.github.io/tags/Markov-chain/"},{"name":"monotonic stack","slug":"monotonic-stack","permalink":"http://yourthomaslee.github.io/tags/monotonic-stack/"},{"name":"data theory","slug":"data-theory","permalink":"http://yourthomaslee.github.io/tags/data-theory/"},{"name":"feature selection","slug":"feature-selection","permalink":"http://yourthomaslee.github.io/tags/feature-selection/"},{"name":"two pointers","slug":"two-pointers","permalink":"http://yourthomaslee.github.io/tags/two-pointers/"},{"name":"guaranteed advertising","slug":"guaranteed-advertising","permalink":"http://yourthomaslee.github.io/tags/guaranteed-advertising/"},{"name":"model enhancement","slug":"model-enhancement","permalink":"http://yourthomaslee.github.io/tags/model-enhancement/"},{"name":"basic concepts","slug":"basic-concepts","permalink":"http://yourthomaslee.github.io/tags/basic-concepts/"},{"name":"deep learning","slug":"deep-learning","permalink":"http://yourthomaslee.github.io/tags/deep-learning/"},{"name":"optimization","slug":"optimization","permalink":"http://yourthomaslee.github.io/tags/optimization/"},{"name":"classical modules","slug":"classical-modules","permalink":"http://yourthomaslee.github.io/tags/classical-modules/"},{"name":"logic regression","slug":"logic-regression","permalink":"http://yourthomaslee.github.io/tags/logic-regression/"},{"name":"perception machine","slug":"perception-machine","permalink":"http://yourthomaslee.github.io/tags/perception-machine/"},{"name":"support vector machine","slug":"support-vector-machine","permalink":"http://yourthomaslee.github.io/tags/support-vector-machine/"},{"name":"combination","slug":"combination","permalink":"http://yourthomaslee.github.io/tags/combination/"},{"name":"maximum entropy model","slug":"maximum-entropy-model","permalink":"http://yourthomaslee.github.io/tags/maximum-entropy-model/"},{"name":"machine learning framework","slug":"machine-learning-framework","permalink":"http://yourthomaslee.github.io/tags/machine-learning-framework/"},{"name":"linear regression","slug":"linear-regression","permalink":"http://yourthomaslee.github.io/tags/linear-regression/"},{"name":"training sample selection","slug":"training-sample-selection","permalink":"http://yourthomaslee.github.io/tags/training-sample-selection/"},{"name":"trainable learning rate","slug":"trainable-learning-rate","permalink":"http://yourthomaslee.github.io/tags/trainable-learning-rate/"},{"name":"overfitting","slug":"overfitting","permalink":"http://yourthomaslee.github.io/tags/overfitting/"},{"name":"logit normalization","slug":"logit-normalization","permalink":"http://yourthomaslee.github.io/tags/logit-normalization/"},{"name":"C++","slug":"C","permalink":"http://yourthomaslee.github.io/tags/C/"}]}