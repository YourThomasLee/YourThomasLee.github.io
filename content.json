{"meta":{"title":"Thomas Lee(李柏珍,Baizhen Li)","subtitle":"抱残守缺","description":"个人博客试验田1号","author":"Thomas Lee (李柏珍,Baizhen Li)","url":"http://YourThomasLee.github.io","root":"/"},"pages":[],"posts":[{"title":"Deep learning foundation 0 - framework","slug":"Deep learning 0 - framework","date":"2023-02-20T02:40:05.000Z","updated":"2023-02-10T16:30:04.182Z","comments":true,"path":"2023/02/20/Deep learning 0 - framework/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/20/Deep%20learning%200%20-%20framework/","excerpt":"","text":"","categories":[],"tags":[{"name":"deep learning framework","slug":"deep-learning-framework","permalink":"http://yourthomaslee.github.io/tags/deep-learning-framework/"}]},{"title":"Leetcode 2341. Maximum Number of Pairs in Array","slug":"Leetcode 2341","date":"2023-02-16T02:40:05.000Z","updated":"2023-02-16T01:24:55.811Z","comments":true,"path":"2023/02/16/Leetcode 2341/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/16/Leetcode%202341/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314151617class Solution {public: vector&lt;int&gt; numberOfPairs(vector&lt;int&gt;&amp; nums) { map&lt;int, int&gt; m; int ans = 0, s = 0; for(auto x: nums){ if(m.find(x) == m.end()) s++; m[x]++; if(m[x] == 2) { ans ++; m.erase(x); s--; } } return {ans, s}; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"}]},{"title":"Machine learning foundation 1 - Part 6. Markov chain","slug":"Machine learning foundation 1.5 - Markov chain","date":"2023-02-16T02:40:05.000Z","updated":"2023-02-10T16:34:32.488Z","comments":true,"path":"2023/02/16/Machine learning foundation 1.5 - Markov chain/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/16/Machine%20learning%20foundation%201.5%20-%20Markov%20chain/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 Outline","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"Markov chain","slug":"Markov-chain","permalink":"http://yourthomaslee.github.io/tags/Markov-chain/"}]},{"title":"Machine learning foundation 1 - Part 7. Condition random field","slug":"Machine learning foundation 1.6 - condition random field","date":"2023-02-16T02:40:05.000Z","updated":"2023-02-10T16:35:02.755Z","comments":true,"path":"2023/02/16/Machine learning foundation 1.6 - condition random field/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/16/Machine%20learning%20foundation%201.6%20-%20condition%20random%20field/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 Outline","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"Condition random field","slug":"Condition-random-field","permalink":"http://yourthomaslee.github.io/tags/Condition-random-field/"}]},{"title":"Leetcode 1250. Check If It Is a Good Array","slug":"Leetcode 1250","date":"2023-02-15T02:40:05.000Z","updated":"2023-02-15T01:53:17.511Z","comments":true,"path":"2023/02/15/Leetcode 1250/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/15/Leetcode%201250/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314class Solution {public: bool isGoodArray(vector&lt;int&gt;&amp; nums) { int divisor = nums[0]; for (int num : nums) { divisor = gcd(divisor, num); if (divisor == 1) { break; } } return divisor == 1; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"number theory","slug":"number-theory","permalink":"http://yourthomaslee.github.io/tags/number-theory/"}]},{"title":"Leetcode 1124. Longest Well-Performing Interval","slug":"Leetcode 1124","date":"2023-02-14T02:40:05.000Z","updated":"2023-02-14T15:06:45.675Z","comments":true,"path":"2023/02/14/Leetcode 1124/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/14/Leetcode%201124/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425class Solution {public: int longestWPI(vector&lt;int&gt;&amp; hours) { int n = hours.size(); vector&lt;int&gt; s(n + 1); stack&lt;int&gt; stk; stk.push(0); for (int i = 1; i &lt;= n; i++) { s[i] = s[i - 1] + (hours[i - 1] &gt; 8 ? 1 : -1); if (s[stk.top()] &gt; s[i]) { stk.push(i); } } int res = 0; for (int r = n; r &gt;= 1; r--) { while (stk.size() &amp;&amp; s[stk.top()] &lt; s[r]) { res = max(res, r - stk.top()); stk.pop(); } } return res; }}; the explanation of solution can be found at link","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"greedy algorithm","slug":"greedy-algorithm","permalink":"http://yourthomaslee.github.io/tags/greedy-algorithm/"},{"name":"monotonic stack","slug":"monotonic-stack","permalink":"http://yourthomaslee.github.io/tags/monotonic-stack/"}]},{"title":"Machine learning foundation 2 - Part 1. data theory","slug":"Machine learning foundation 2 - data theory","date":"2023-02-13T03:40:05.000Z","updated":"2023-02-13T08:34:22.154Z","comments":true,"path":"2023/02/13/Machine learning foundation 2 - data theory/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/13/Machine%20learning%20foundation%202%20-%20data%20theory/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 数据分析领域中最为人称道的七种降维方法 降维方法PCA, isomap, lle, autoencoder等的实现","categories":[],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"http://yourthomaslee.github.io/tags/machine-learning/"},{"name":"data theory","slug":"data-theory","permalink":"http://yourthomaslee.github.io/tags/data-theory/"},{"name":"feature selection","slug":"feature-selection","permalink":"http://yourthomaslee.github.io/tags/feature-selection/"}]},{"title":"Leetcode 1234. Replace the Substring for Balanced String","slug":"Leetcode 1234","date":"2023-02-13T02:40:05.000Z","updated":"2023-02-14T15:07:17.352Z","comments":true,"path":"2023/02/13/Leetcode 1234/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/13/Leetcode%201234/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution {public: bool cmp(map&lt;char, int&gt;&amp; a, map&lt;char, int&gt;&amp; b){ bool ans = true; for(auto x: a){ ans &amp;= (b[x.first] &gt;= x.second); } return ans; } int balancedString(string s) { map&lt;char, int&gt; m; for(auto x:{'Q', 'W', 'E', 'R'}) m[x] = 0; for(auto x: s) m[x]++; int t = 0; for(auto i: {'Q', 'W', 'E', 'R'}){ m[i] = max(m[i] - int(s.size() / 4), 0); t += m[i]; cout&lt;&lt;i&lt;&lt;\": \"&lt;&lt;m[i]&lt;&lt;endl; } if(t == 0) return 0; int ans = s.size(); map&lt;char, int&gt; sm; int l = 0, r = 0; while(r &lt; s.size()){ sm[s[r]]++; if(cmp(m, sm)){ //左边界 while(l + t &lt;= r &amp;&amp; sm[s[l]] &gt; m[s[l]]){ sm[s[l]]--; l++; } cout&lt;&lt;l&lt;&lt;\" -&gt; \"&lt;&lt;r&lt;&lt;\": \"&lt;&lt;s.substr(l, r - l + 1)&lt;&lt;endl; ans = min(r - l + 1, ans); sm[s[l]]--; l++; } if(ans == t) return ans; r += 1; } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"two pointers","slug":"two-pointers","permalink":"http://yourthomaslee.github.io/tags/two-pointers/"}]},{"title":"Computational advertising 1 - guaranteed advertising","slug":"Computional advertising 0 - guaranteed advertising","date":"2023-02-12T14:40:05.000Z","updated":"2023-02-13T02:01:36.298Z","comments":true,"path":"2023/02/12/Computional advertising 0 - guaranteed advertising/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/12/Computional%20advertising%200%20-%20guaranteed%20advertising/","excerpt":"","text":"定向广告实现方式和发展历程： 担保式广告(Guaranteed delivery, GD)：媒体与广告主约定广告位、时间段和投放量，并在此基础上确定合同的综金额以及量未达标情况下的赔偿方案。这种合约仍然主要面向品牌广告主，并且按照千次展示付费(Cost per mille, CPM)的计费模式。其中两个关键问题：一是如何有效的将流量分配到各个合约互相交叉的人群覆盖上；二是要在在线环境下实时的完成每一次展示决策(在线分配问题)。当担保广告迅猛发展，争抢流量变得开始寻常，这催生了竞价广告。 合约广告相关概念 在线广告业务的初始阶段，媒体与广告主的代理商是市场的主要参与者。由广告代理公司和媒体签订协议，确保某些广告位在某时间 段为指定的广告商所占有，同时广告商按整体合同支付广告费用。CPT 结算的广告 位合约方式对技术的依赖性较小，只需要用到简单的广告排期系统。 合约广告的重要形式是按 CPM 计费的展示量合约，售卖的对象己经由“广告位”进化到了“广告 位+人群”，这催生了受众定向技术。在合约广告中，需求方的产品技术并没有太大发展，但从供给方产品和技术的复杂程度来看， CPM 合约甚至比竞价产品系统更加复杂，其复杂性主要来源于如何满足多个合约对投放系统量的要求，这就是合约广告 中重要的在线分配问题。 受众定向方法 市场上一些流行的定向方式如下 在图 4-2 中，水平方向表示的是定向技术在广告信息接收过程中大致起作用的阶段， 而垂直方向为定性的效果评价。 地域定向( geo-targeting ): 这是一种很直觉也很早就被广泛使用的定向方式。 人口属性定向( demographical targeting ): 人口属性的主要标签 包括年龄、性别、受教育程度、收入水平等。 上下文定向( contextual targeting)。根据网页或应用的具体内容来匹配相关的广告. 行为定向(behavioral targeting)根据用户的历史访问行为了解用户兴趣，从而投送相关广告的 精确位直走向( hyper-local targeting ): 移动设备上投放广告时，我们有可能获 得非常精准的地理位置 。 重定向( retargeting)对某个广告主过 去一段时间内的访客投放广告以提升效果 新客推荐定向( look-alike targeting)根据 广告 主提供的种子访客信息，结合广告平台更丰富的数据，为广告主找到行为上相似的潜在客 户 场景定向( scenario targeting)是移动环境下的新问题。你在健身 时、吃饭时、看电视时、开会时，会携带和使 用于机，这些你在使用手机时的背景状态就是场景。移动设备丰富的传感器和状态信息为场景的判断提供了可能。 受众定向产品上最关键的环节就是如何描述用户，也就是如何设计标签体系，这甚至 比受众定向的技术更加重要 。 重点探讨的是驱动直接效果的用户，在这一 目的下，规整 的结构化标签体系其实并不是必需的 。一般来说，标签体系的设计必须要分行业进行，而其 中的关键思路是深入研究该行业的用户决策过程。 展示量合约 展示量合约售卖的是某特定人群上的广告曝光次数，而人群不同于确定的广告位，因此必须在合约中约定投放的量。于是，就产生了流量预测( traffic forecasting)这 一 问题，其在广告产品中有以下 3 个主要用途： 售前指导：在展示量合约广告中，因为要约定曝光总数，所以事先尽可能准确地 预测各人群标签的流量至关重要 。 在线流量分配：由于合约之间在人群选择上会有很 多交集， 当一 次曝光同时满足两个以上合约的要求时，怎样决策将它分配给哪个合约以达 到整体满足所有合约的目的，这是下文将要讨论的在线分配问题 。为了描述这一策略 问题，我们将其简化 为一个二部图( bipartite graph)匹配问题: 二部图的一方表示广告库存的供给节点，每个 节点代表的是所有人群标签都相同的流量集合;二部图的另 一方表示广告合约的需求节点， 每个节点代表的是一个广告合约的人群标签条件。 出价指导：在竞价广告中，由于没有了 量的保证，广告主往往需要根据自己预计 的出价先了解一下可能获得多少流量，以判断自己的出价是否合理。 流量预测对于展示量合约非常重要，不过这本质上还是被动地统计流量情况。在有些 情形下，我们可以主动地影响流量，以利于合约的达成。这一产品策略问题称为流量塑形 ( traffic shaping )。","categories":[],"tags":[{"name":"computational advertising","slug":"computational-advertising","permalink":"http://yourthomaslee.github.io/tags/computational-advertising/"},{"name":"guaranteed advertising","slug":"guaranteed-advertising","permalink":"http://yourthomaslee.github.io/tags/guaranteed-advertising/"}]},{"title":"Leetcode 1138. Alphabet Board Path","slug":"Leetcode 1138","date":"2023-02-12T02:40:05.000Z","updated":"2023-02-14T15:06:53.763Z","comments":true,"path":"2023/02/12/Leetcode 1138/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/12/Leetcode%201138/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution {public: string move(int a, int b, int cc, int d){ string ans; if (a == 5){ ans.push_back('U'); a = 4; b = 0; } bool flag = false; if(cc == 5){ flag = true; cc = 4; d = 0; } int r = abs(cc - a); while(r--){ ans.push_back((cc &lt; a)?'U':'D'); } int c = abs(d - b); while(c--){ ans.push_back((d &gt; b)?'R':'L'); } if(flag) ans.push_back('D'); return ans; } vector&lt;string&gt; b ={\"abcde\", \"fghij\", \"klmno\", \"pqrst\", \"uvwxy\", \"z\"}; string alphabetBoardPath(string target) { int pos = 0, r = 0, c = 0; string ans; for(auto x: target){ pos = x - 'a'; if(x != b[r][c]){ ans += move(r, c, pos / 5, pos % 5); r = pos / 5; c = pos % 5; } ans.push_back('!'); } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"simulation","slug":"simulation","permalink":"http://yourthomaslee.github.io/tags/simulation/"}]},{"title":"Machine learning foundation 1 - Part 5. Model enhancement","slug":"Machine learning foundation 1.4 - model enhancement","date":"2023-02-12T02:40:05.000Z","updated":"2023-02-13T03:23:57.293Z","comments":true,"path":"2023/02/12/Machine learning foundation 1.4 - model enhancement/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/12/Machine%20learning%20foundation%201.4%20-%20model%20enhancement/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 [TOC] 1. 提升方法概述 在概率近似正确(probably approximately correct, PAC)框架中，一个概念，如果存在一个多项式的学习算法能够学习它，并且学习的正确率很高，则称该概念是强可学习的；如果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测略好，那么就称该概念是弱可学习的。 事实上，在PAC学习的框架下，一个概念是强可学习的充分必要条件是这个概念是弱可学习的。 提升方法是从弱学习算法出发，得到一系列弱分类器，然后组合这些弱分类器构成一个强分类器。大多数的提升方法都是改变训练数据的概率分布(训练数据的样本权重)，针对不同的训练数据分布调用共弱学习算法学习一系列的弱分类器。 对于提升方法来说，有两个非常重要的问题需要回答： 在每一轮次如何调整训练数据的权重或概率分布 如何将弱分类器组合称一个强分类器 目前典型的提升方法有adaboost，gbdt，xgboost， light gbm，随机森林等等，以下分点阐述这些算法 2. ada-boost算法 AdaBoost(Adaptive Boosting)算法是一个针对二分类的动态自适应提升方法，该方法是顺序训练M个分类器，每个分类器的样本权重根据上一个分类器的分类正确率进行调整得到，每个分类器的权重由分类器的正确率计算得到，将所有分类器的输出进行线性加权结果输入到sign函数输出预测值。 **优点:**1. 非常容易训练，实现起来比较容易; 2. 泛化错误率低（预测性能好），不易过拟合; 3. 不需要调节很多参数，最多修改一下基础模型的数量; 4. 适用范围广：二分类问题，多分类问题，回归问题 **缺点:**1. 对于离群值比较敏感 算法 2.1 adaboost算法 输入： 输出：最终分类器. Step 1. 初始化训练数据的权值分布. Step 2. 对: Step 2.1. 使用具有权值分布的训练数据集学习，得到基本分类器. Step 2.2. 计算在训练数据集上的分类误差率, 如果, 跳转到Step 2.1，否则往下执行Step 2.3. Step 2.3. 计算的权重系数， Step 2.4. 更新训练数据集的权值分布，, 其中为规范化因子，. Step 3. 构建基本分类器的线性组合，, 得到最终分类器，. 每个分类器权重：， 每个样本的权重更新公式，对于正确样本，. **AdaBoost-前向分步算法理解：**考虑加法模型(additive model), 其中为基函数，的参数，为基函数的系数。在给定训练数据和损失函数的条件下，学习加法模型成为经验风险最小化问题. 前向分布算法(forward stagewise algorithm)求解以上优化问题的想法是：从前完后，每一步只学习一个基函数及其系数，逐步逼近优化目标函数，具体地每步秩序优化如下函数. 算法 2.2. 前向分步算法 输入： 输出：加法模型. Step 1. 初始化 Step 2. 对 Step 2.1 极小化损失函数,得到参数. Step 2.2 更新. Step 3. 得到加法模型. 设定损失函数为，并从前往后分步优化，设定权重参数, 令权重参数更新方式为(TODO:补充权重更新细节). 第步则为, 由于前个分类器已经确定，只剩第个分类器待优化，故优化目标可写为. 在ada boost上进行基分类器的拓展，例如将ada boost中的基分类器替换成二分类树，这可以认为是ada boost的简单拓展；对于回归问题，使用决策树将空间区域划分为若干不相交的区域(每个叶子节点就是对应着一个区域)，而后对于每个区域进行线性回归，则可得提升树的回归算法(残差树)。 3. gbdt算法 gbdt是使用加法模型并使用前向分布算法不断减小训练过程中产生的残差估计值来达到将数据分类或者回归的提升算法，相比于adaboost和残差树，gbdt考虑更加泛化的损失函数情况，因此基于梯度的残差估计值来训练每一个轮次的弱分类器，具有更加广泛的适用性。让损失函数沿着梯度方向的下降，这是gbdt的gb的核心了。 gbdt = 前向分布+梯度提升+cart 回归树 gbdt训练：前向分布训练个分类器(贪心算法)，第一次直接基于原始数据集训练，而后使用 gbdt分类树：cart回归树预测数值，之后增加一层softmax GBDT：是一个加法模型，它串行地训练一组CART回归树，最终对所有回归树的预测结果加和，由此得到一个强学习器，每一颗新树都拟合当前损失函数的负梯度方向。 对于回归任务，它一般使用平方误差作为损失函数， 并使每棵树去拟合标签和训练好的树的残差，拟合残差的原因是它是平方损失函数的负梯度。 GBDT 它的非线性变换比较多，表达能力强，而且不需要做复杂的特征工程和特征变换。 GBDT 的缺点也很明显，Boost 是一个串行过程，不好并行化，而且计算复杂度高，同时不太适合高维稀疏特征； 传统 GBDT 在优化时只用到一阶导数信息。 4. XGboost算法 从一般步骤来审视XGboost的细节 数据： 允许特征出现缺失值 分割点寻找：在特征k上寻找最佳划分点时，不会对该列特征缺失的样本进行遍历，而只对该列特征值为不缺失的样本上对应的特征值进行遍历，通过这个技巧来减少了为稀疏离散特征寻找划分点的时间开销。 节点分裂：在逻辑实现上，为了保证完备性，会将该特征值缺失的样本分别分配到左叶子结点和右叶子结点，两种情形都计算一遍后，选择分裂后增益最大的那个方向（左分支或是右分支），作为预测时特征值缺失样本的默认分支方向。 预测时候：如果在训练中没有缺失值而在预测中出现缺失，那么会自动将缺失值的划分方向放到右子结点。 模型角度：传统GBDT以CART树作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。 学习准则： 损失函数：传统GBDT在损失函数时只用到一阶导数信息，xgboost则对损失函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。同时xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。 xgboost损失函数：为叶子节点集合的基数， 为叶子节点的输出值，期望预测不会被单个叶子结点主导，而是一种综合的结果。 泰勒公式： 优化时候针对每个叶子节点进行优化，最小化损失函数即可（损失函数二阶导大于0，所以必定存在最小值), 解一元二次方程 ，最优损失函数即为 采样：每轮计算可以不使用全部样本，随机抽取部分样本，因此算法鲁棒性更强； 训练的时候只用一部分特征(只考虑一个block,不考虑剩余的Block块即可)； 系数衰减：学习率/步长,为了给后面的训练留出更多的学习空间。 并行：xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构减小计算量，各个特征的增益计算开多线程进行 分割点选择：使用可并行的近似直方图算法，用于高效地生成候选的分割点，无需贪心法枚举所有可能的分割点。 停止生长条件（叶子节点的深度、样本数量和带来的信息增益） 最低增益：当新引入的一次分裂所带来的增益Gain&lt;0时，放弃当前的分裂。这是训练损失和模型结构复杂度的博弈过程。 深度限制：当树达到最大深度时，停止建树，因为树的深度太深容易出现过拟合，这里需要设置一个超参数max_depth。 权重限制：当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值，也会放弃此次分裂。这涉及到一个超参数: 最小样本权重和，是指如果一个叶子节点包含的样本数量太少也会放弃分裂，防止树分的太细。 xgboost是gbdt的一个工程实现，它优化的地方如下： 利用了特征的稀疏性。 数据事先排序并且以 block 形式存储，有利于并行计算。 基于分布式通信框架 rabit，可以运行在 MPI 和 yarn 上。（最新已经不基于 rabit 了） 实现做了面向体系结构的优化，针对 cache 和内存做了性能优化。 XGBoost 的缺点有 算法参数过多：调参复杂，需要对 XGBoost 原理十分清楚才能很好的使用 XGBoost。 只适合处理结构化数据：相对于深度学习算法来说，XGBoost 算法只适 合处理结构化的特征数据，而对于类似图像中的目标检测等任务重的非结构化数据没有很好的处理能力。 不适合处理超高维特征数据：XGBoost 算法对于中低维数据具有很好的处理速度和精度，但是对于例如大规模图像物体识别，或者是推荐算法的某些场景中会出现的超高维特征的数据就无能为力了，这时候我们就需要借助于深度学习等算法。 5. light gbm算法 #TODO 6. 随机森林 直觉： 随机森林是采用有放回采样样本和随机采样特征形成若干个决策树分类器投票预测最终的样本标签值的集成学习方法 优点： 模型较低的方差，较好的泛化性能； 由于随机采样特征，也可以作为特征选择的方法； 由于多个分类器之间独立不相关，并行性能较好，速度较快； 缺点：投票决策导致不能够预测从来没有出现过的标签值，同时预测值的空间为离散的，这导致在回归问题上表现较差；由于没有考虑特征之间的相关性，在有些情况下随机森林的模型效果可能不尽人意 6.1. bagging 给定大小为的样本集合，使用有放回采样方构造个样本集(每个样本集个样例)，使用个样本集训练不同的分类或者回归预测模型，并使用简单投票或者算术平均值求预测值。 6.2. 随机森林 随机森林是 Bagging 的优化版本。其包含的思想在于： 随机选择样本数建立多个训练集并随机选取特征集合，根据多个训练集与特征集合来建立多颗决策树，然后进行投票决策。 随机森林的最终目的是建立颗决策树，而每颗决策树的建立过程如下： 如果训练集大小为，对于每棵树而言，随机且有放回地从训练集中的抽取个训练样本，作为该树的训练集。 如果每个样本的特征维度为，指定一个常数，随机地从个特征中选取个特征子集，每次树进行分裂时，从这个特征中选择最优的 每棵树都尽最大程度的生长，并且没有剪枝过程。 随机森林中的随性性指的是：数据采样的随机性与特征采用的随机性。 这两个随机性的引入对随机森林的分类性能直观重要，它们使得随机森林不容易陷入过拟合，且具有很好的抗噪能力。是随机森林中唯一的一个参数。 减小特征选择个数，树的相关性和分类能力也会相应的降低 增大，两者也会随之增大。 6.3. 如何处理缺失值 首先给缺失值预设一些估计值，例如平均数，中位数，众数； 根据估计的数值，建立随机森林，把所有的数据放进随机森林里面跑一遍。记录每一组数据在决策树中一步一步分类的路径. 判断哪组数据和缺失数据路径最相似，引入一个相似度矩阵，来记录数据之间的相似度，比如有组数据，相似度矩阵大小就是。如果缺失值是类别变量，通过投票得到新估计值，如果是数值型变量，通过加权平均得到新的估计值，如此迭代，直到得到稳定的估计值。 6.4. 什么是 OOB？ OOB 即 out-of-bag ， 又称袋外数据。 这是由于 Bagging 方法会采用 Boostrap 进行抽样， 每次约有 的样本不会出现在抽样后的样本集合中，那么就把这 的样本称为袋外数据 oob(out-of-bag)。由于 oob 没有用于训练决策树，因此可用于后续对该决策树的泛化能力评估。 6.5. 随机森林的优劣 优势: 模型高度并行化, 对于高维数据集的处理能力比较好, 可以处理成千上万的输入变量,并确定出重要的变量, 因此也被认为是不错的降维方法. 能够处理分类和回归两种类型的问题, 表现良好, 由于是集成学习, 方差和偏差都比较小, 泛化性能优越. 对于数据的鲁棒性很强, 可以处理缺失数据/不平衡数据, 无需归一化 劣势: 随机森林在回归问题上较为弱势, 这是因为它不能给出一个连续型的输出.另外随机森林不能够做出超越训练数据集范围的预测, 这可能导致在有特定噪声的数据进行建模时出现过度拟合 黑盒模型, 无法控制模型运行 随机森林模型忽略了属性之间的相关性 常见问题 随机森林, gbdt和xgboost的区别在哪儿 随机森林的集成学习方法是bagging, 但是需要特别注意的是随机森林使用bootstrap有放回采样, 每个基学习器随机选择m()个属性来做输入, 在采样样本的同时也采样特征, 结合集成方法能够降低方差和偏差, 泛华性能优越. 随机森林的优势: 模型高度并行化, 对于高维数据集的处理能力比较好, 可以处理成千上万的输入变量,并确定出重要的变量, 因此也被认为是不错的降维方法. 能够处理分类和回归两种类型的问题, 表现良好, 由于是集成学习, 方差和偏差都比较小, 泛化性能优越. 对于数据的鲁棒性很强, 可以处理缺失数据/不平衡数据, 无需归一化 随机森林的劣势: 随机森林在回归问题上较为弱势, 这是因为它不能给出一个连续型的输出.另外随机森林不能够做出超越训练数据集范围的预测, 这可能导致在有特定噪声的数据进行建模时出现过度拟合 黑盒模型, 无法控制模型运行 随机森林模型忽略了属性之间的相关性 gbdt的集成学习方法是boosting, 因为梯度提升需要按照损失函数的梯度近似的拟合残差, 因此只有回归树. 与传统boosting方法的区别在于, 传统boosting方法是使用样本的权重来做前后模型的结合提升整体模型的效果. 这个梯度代表上一轮学习器损失函数对预测值求导。与Boosting Tree的区别：Boosting Tree的适合于损失函数为平方损失或者指数损失。而Gradient Boosting适合各类损失函数（损失函数为：平方损失则相当于Boosting Tree拟合残差、损失函数为：使用指数损失则可以近似于Adaboost，但树是回归树） XGBoost相对于gbdt好的地方在于使用二阶泰勒展开做优化, 节点分数正则化惩罚, 增益计算不同.","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"model enhancement","slug":"model-enhancement","permalink":"http://yourthomaslee.github.io/tags/model-enhancement/"}]},{"title":"Computational advertising 0 - concepts","slug":"Computional advertising 0 - concepts","date":"2023-02-11T14:40:05.000Z","updated":"2023-02-12T03:34:25.585Z","comments":true,"path":"2023/02/11/Computional advertising 0 - concepts/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Computional%20advertising%200%20-%20concepts/","excerpt":"","text":"1. 广告发展和基础概念 定义 1. 广告是由已确定的出资人通过各种媒介进行的有关产品(商品、服务和观点)的，通常是有偿的、有组织的、综合的、劝服性的信息传播活动 需求方=广告主=出资人； 媒介=供给方=媒体 | 代理商；受众 = 媒体的用户 广告分类： 品牌广告：借助媒体快速接触大量用户，以达到宣传品牌形象，提升中长期购买率与利润空间的目的 直接效果广告：利用广告手段马上带来大量的购买或者其它转化行为 广告的根本目的是广告主通过媒体达到低成本(Return of investment, ROI)的用户接触，这里的低成本是相对于市场或销售人员完成的劝服活动成本而言的。 互联网的广告：一切付费的信息、产品或服务的传播渠道，都是广告 在线广告的表现形式： 类型 说明 横幅广告 文字链广告 富媒体广告 侵入式投入广告素材，包括弹窗、对联、全屏等 视频广告 视频插片广告，信息流视频广告，游戏激励视频广告 交互式广告 社交广告 在社交网络中插入的广告 移动广告 邮件营销广告 通过电子邮件向用户推广信息的一种营销手段 激励广告 激励用户产生转化行为以提高效果，例如移动积分墙，电商返利购买和团购、游戏联运 数字媒体不同于传统媒体的本质特点：可以对不同受众呈现不同的广告创意，而对指定人群展现的广告也叫定向广告。定向广告对计算技术提出两个需求：一是受众定向(audience targeting)，就是通过技术手段标定某个用户的性别、年龄或其他标签，二是广告投放(ad serving)，即将广告投送由直接嵌入页面变为实时响应前端请求并动态决策和返回合适的广告创意。 定向广告实现方式和发展历程： 担保式广告(Guaranteed delivery, GD)：媒体与广告主约定广告位、时间段和投放量，并在此基础上确定合同的综金额以及量未达标情况下的赔偿方案。这种合约仍然主要面向品牌广告主，并且按照千次展示付费(Cost per mille, CPM)的计费模式。其中两个关键问题：一是如何有效的将流量分配到各个合约互相交叉的人群覆盖上；二是要在在线环境下实时的完成每一次展示决策(在线分配问题)。当担保广告迅猛发展，争抢流量变得开始寻常，这催生了竞价广告。 竞价广告(auction-based advertising): 最初产生于搜索广告，在竞价模式下，供给方只向广告主报纸质(单位流量的成本)，但不再给出量的保证。竞价系统下定价机制成为一个重要问题，目前广义第二高价(Generalized second price, GSP)和Vickrey–Clarke–Groves拍卖机制(VCG)是主流方案。竞价和精准人群定向的庞大需求，催生了广告网络(AD Network， ADN)，它批量地运营媒体的广告位，按照人群或上下文标签售卖给需求方并用竞价的方式分配流量，广告网络的结算以按点击计费(Cost per click, CPC)的方式进行，这使得尾部小流量也能够被利用，进一步扩大了广告的市场。另外，流量采买的形式越来越依赖技术手段进行指定人群受众流量的购买保证达成要求。 开放实时竞价(Real time bidding, RTB)：广告网络的竞价过程是内部进行的，无法满足广告主定制化的人群选择和优化要求，例如电商网络召回流失用户和银行通过已有信用卡用户找到相似的潜在用户群，这催生了开放的竞价逻辑，让需求方按自己的人群定义来挑选流量。RTB将竞价过程变为每次将广告展示的上下文页面URL和访客的用户表示等用户标识等信息传给需求方，它完成定制化的人群选择和出价，这催生了新的产品形态：广告交易平台(AD exchange, ADX)，而完成定制化人群标签采买广告的平台就是需求方平台(Demand side platform, DSP)，这种买卖广告的方式也叫程序化交易(Programmatic trade) 以上每一种广告产品基本都有三个组成部分，即面向需求方的接口、面向供给方的接口以及中间的投放系统及匹配策略。 需求方接口：一般来说提供的广告是分层次管理的。层次分为广告主、广告计划（plan)、广告单元(ad group)、广告创意（idea)等几个层级。以下为百度内部系统中的层级 user：账户信息，与plan关系1对N plan：计划，一个账户下可设置多个推广计划。是管理推广的最大单位，一般按产品或地域进行划分，与unit关系1对N unit：单元，每个推广计划多个单元。将意义相近结构相同的关键词放在一起管理，与winfo和idea是一对多的关系 winfo：用户购买的关键词，包括bidword、广告主出价信息，与idea关系M对N idea：展示给网民看的推广内容，包括标题、描述、显示url以及访问url 供给方接口：分为媒体和广告位两个层次，其中媒体可以是网站或者移动应用。这部分更多涉及不同计算实体之间的交互技术，此处不过多赘述。 2. 广告的建模 广告的整个过程可以被描述为如下3个阶段和6个进程 曝光指的是物理上展现的过程，实际中位置影响很大。关注指的是用户意识到广告本身的存在，如何在不打断用户的任务前提下，明确传达推送广告的原因且内容契合用户的兴趣或需求是比较有效提升关注的方法。理解阶段，让用户理解广告内容，让广告内容尽可能简单容易理解且让内容在兴趣范围内。接受阶段：考虑广告上下文和广告逻辑。保持阶段：让用户留下尽可能长时间的正面印象。决策阶段：打动用户并劝服其产生转化行为。 越靠前的阶段，对点击率影响越大，而越靠后的阶段对转化率影响越大。 互联网广告的技术特点：1. 技术和计算导向； 2. 效果的可衡量性； 3. 创意和投放方式的标准化； 4. 媒体概念的多样化； 5. 数据驱动的投放决策。 广告问题的形式化：计算广告的核心挑战是为一系列用户与上下文的组合找到最合适的广告投放策略以优化整体广告活动的利润。使用最优化问题表述即为 Misplaced & \\max &amp; \\sum_{i = 1}^T (r_i - q_i),\\ &amp; s.t. \\sum_{i = 1}^T d_{ik} \\leq D_k, \\forall k 其中表示从第1次到第次之间的某一次广告展示, 和分别表示每次广告展示中的总收入和总成本的差，即总体的利润，则表示在第次广告中具体广告主的限制(需求方约束)。进一步考虑具体依赖的因素，优化问题可以写成 Misplaced & \\max &amp; \\sum_{i = 1}^T (r(a_i, u_i, c_i) - q(a_i,u_i,c_i)),\\ &amp; s.t. \\sum_{i = 1}^T d(a_i,u_i,c_i,k) \\leq D_k, \\forall k 分别表示广告，用户和上下文，即广告活动的3个参与主体。注意这里隐含假设整体的收入或成本可以被分解到每次展示上，这并不合理，但为了实用仍然采用这个假设并通过频次控制、点击反馈等方法来解决多次展示之间效果相关性的问题。具体收入分解方式有如下方式","categories":[],"tags":[{"name":"computational advertising","slug":"computational-advertising","permalink":"http://yourthomaslee.github.io/tags/computational-advertising/"},{"name":"basic concepts","slug":"basic-concepts","permalink":"http://yourthomaslee.github.io/tags/basic-concepts/"}]},{"title":"Deep learning foundation 1 - framework","slug":"Deep learning 1 - activation function","date":"2023-02-11T02:40:05.000Z","updated":"2023-02-11T14:24:31.233Z","comments":true,"path":"2023/02/11/Deep learning 1 - activation function/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Deep%20learning%201%20-%20activation%20function/","excerpt":"","text":"Activation function 激活函数的根本目的是增加非线性，能够通过梯度下降有选择的观察某一个区域的特征 1. Sigmoid 公式​ 优点：良好的生物解释，从完全不激活(0)到完全饱和的激活(1)，可以直接映射为概率 缺点： 梯度消失(初始化小于1): （1）损失函数有梯度传递，但是由于sigmoid函数导数最大为1/4，层以后梯度至少变为原来的，对多层的神经网络训练无法提供支持;（2）当神经元的值在接近0或1出时会饱和，梯度几乎为0，为了防止饱和，必须对初始化权重留意，不宜过大，否则容易梯度消失网络就不学习了. 梯度爆炸（初始化&gt;1)， sigmoid导数最大为1/4，所以时候才可能出现梯度爆炸 非0均值：因为输出都为正，对下一层求导的局部梯度也是正，因为，会造成捆绑效应和梯度方向一致，梯度方向一致之后，使得优化变得困难和低效 2. Tanh 公式, 将数值区域从[0,1]扩张大[-1,+1]区间，输出零中心，增快收敛。但仍然有幂函数，计算成本高 3. Relu 公式. 在正区间解决了梯度消失的问题，快收敛，计算成本低。缺点是对学习率很敏感，太大会出现很多死神经元。 4. Leaky Relu &amp; SELU &amp; ELU Leaky Relu: . 分段逼近，快速收敛，但效果不稳定。属于解决死亡神经元的尝试工作之一 ELU: SELU: ELU结合了ReLU和sigmoid，具备两者的优点：(1) 在输入正半轴为线性，无饱和性，使其可以缓解梯度消失问题；(2) 在输入负半轴具有软饱和性，其下边界为 −α ，软饱和性一方面可以解决ReLU中神经元永久性dead问题，另一方面可以使ELU对输入噪声具有更强的鲁棒性；(3) 输出的均值接近0，可以缓解均值不为0带来的输出分布变化问题，加快模型收敛。 ELU在输入负半轴采用指数的形式，这导致ELU相比ReLU存在计算复杂度较高的缺点。 SELU和ELU具有同样的特点。理论上ELU优于ReLU，但在推荐实际应用场景没有得到充分证明，可能和推荐领域网络深度不深有关系，在视觉领域网络层数深，相比ReLU、Leaky ReLU，ELU可以在网络收敛性上有优势。 5. Maxout 公式, 具备relu所有的优点，没有死神经元。缺点是参数量增加了一倍。 6. Softplus 7. softmax softmax激活函数是sigmoid激活函数的扩展， 通常用于多分类网络最后的输出层。softmax通过指数归一化方式，可以强化各项之间的区分度。 6. GELU 以往的激活函数为神经网络进入了非线性（binary threshold, sigmoid, ReLU, ELU, 及特点和优劣），另外神经网络中需要在网络层中加入一些noise,或通过加入dropout等方式进行随机正则化。以往的非线性和随机正则化这两部分基本都是互不相关的，因为辅助非线性变换的那些随机正则化器是与输入无关的。 GELU将非线性与随机正则化结合，将非线性与依赖输入数据分布的随机正则化器相结合在一个激活函数的表达中。与以往dropout指定随机概率值或ReLU根据输入值的正负进行mask的方式不同，GELU根据当前input大于其余inputs的概率进行随机正则化，即为在mask时依赖输入的数据分布。 Trick：对公式中的正态分布的累积分布函数进行了tanh三阶多项式近似，取得了相较于swish用sigmoid近似更好的效果。 其中 trick和建议：1. 数据符合高斯分布的累积分布函数的近似表示是非常重要的； 2. 建议优化器与momentum一起使用","categories":[],"tags":[{"name":"deep learning concepts","slug":"deep-learning-concepts","permalink":"http://yourthomaslee.github.io/tags/deep-learning-concepts/"},{"name":"activation function","slug":"activation-function","permalink":"http://yourthomaslee.github.io/tags/activation-function/"}]},{"title":"Deep learning foundation 1 - classical modules","slug":"Deep learning 1 - classical modules","date":"2023-02-11T02:40:05.000Z","updated":"2023-02-11T14:26:11.428Z","comments":true,"path":"2023/02/11/Deep learning 1 - classical modules/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Deep%20learning%201%20-%20classical%20modules/","excerpt":"","text":"CNN RNN Attention","categories":[],"tags":[{"name":"deep learning concepts","slug":"deep-learning-concepts","permalink":"http://yourthomaslee.github.io/tags/deep-learning-concepts/"},{"name":"classical modules","slug":"classical-modules","permalink":"http://yourthomaslee.github.io/tags/classical-modules/"}]},{"title":"Leetcode 2335. Minimum Amount of Time to Fill Cups","slug":"Leetcode 2335","date":"2023-02-11T02:40:05.000Z","updated":"2023-02-14T15:07:35.029Z","comments":true,"path":"2023/02/11/Leetcode 2335/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Leetcode%202335/","excerpt":"","text":"The problem description can be found at the link My solution: 1234567891011121314151617class Solution {public: int fillCups(vector&lt;int&gt;&amp; amount) { int cnt = 0, remain = 0; sort(amount.begin(), amount.end(),[](int a, int b){return a &gt; b;}); for(int i = 0; i &lt; amount.size(); ++i){ if(amount[i] != 0 &amp;&amp; cnt &lt; 2){ amount[i] --; remain = amount[i]; cnt ++; } } if(cnt == 2) return 1 + fillCups(amount); else if(cnt == 1) return 1 + remain; else return 0; }}; Best solution(explanation link): 12345678910class Solution {public: int fillCups(vector&lt;int&gt;&amp; amount) { sort(amount.begin(), amount.end()); if (amount[2] &gt; amount[1] + amount[0]) { return amount[2]; } return (accumulate(amount.begin(), amount.end(), 0) + 1) / 2; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"greedy algorithm","slug":"greedy-algorithm","permalink":"http://yourthomaslee.github.io/tags/greedy-algorithm/"},{"name":"array","slug":"array","permalink":"http://yourthomaslee.github.io/tags/array/"}]},{"title":"Machine learning foundation 1 - Part 3. Perception machine and support vector machine","slug":"Machine learning foundation 1.2 - perception machine and support vector machine","date":"2023-02-11T02:40:05.000Z","updated":"2023-02-10T16:32:51.062Z","comments":true,"path":"2023/02/11/Machine learning foundation 1.2 - perception machine and support vector machine/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Machine%20learning%20foundation%201.2%20-%20perception%20machine%20and%20support%20vector%20machine/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 Outline","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"perception machine","slug":"perception-machine","permalink":"http://yourthomaslee.github.io/tags/perception-machine/"},{"name":"support vector machine","slug":"support-vector-machine","permalink":"http://yourthomaslee.github.io/tags/support-vector-machine/"}]},{"title":"Machine learning foundation 1 - Part 4. decision tree","slug":"Machine learning foundation 1.3 - decision tree","date":"2023-02-11T02:40:05.000Z","updated":"2023-02-13T01:47:32.353Z","comments":true,"path":"2023/02/11/Machine learning foundation 1.3 - decision tree/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/11/Machine%20learning%20foundation%201.3%20-%20decision%20tree/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 [TOC] 1. 预备知识 1.1 基础数学知识： 期望. 另外如果与独立时. 方差： 方差是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。 方差是和中心偏离的程度，用来衡量一批数据的波动大小（即这批数据偏离平均数的大小）并把它叫做这组数据的方差。 . . 如果两个随机变量相互独立，. 标准差 协方差：,相关系数. 特征相关性分析：在统计学中，皮尔逊相关系数( Pearson correlation coefficient），又称皮尔逊积矩相关系数（Pearson product-moment correlation coefficient，简称 PPMCC或PCCs），是用于度量两个变量X和Y之间的相关(线性相关)，其值介于-1与1之间。皮尔逊相关系数有一个重要的数学特性是，因两个变量的位置和尺度的变化并不会引起该系数的改变，即它该变化的不变量移动到和把Y移动到，其中a、b、c和d是常数，并不会改变两个变量的相关系数（该结论在总体和样本皮尔逊相关系数中都成立）。 假设划分前样本集合D的熵为 。使用某个特征A划分数据集D，计算划分后的数据子集的熵为 。 信息熵：条件熵：信息增益： 1.2 决策树基础 目前典型的决策树算法有三种，分别是ID3、C4.5和CART算法。 算法 划分标准 ID3 信息增益 C4.5 信息增益率 CART 基尼系数 决策树的三要素 特征选择： 从训练数据中众多的特征中选择一个特征作为当前节点的分裂标准，如何选择特征有着很多不同量化评估标准标准，从而衍生出不同的决策树算法。 **决策树生成：**根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树停止生长。 **决策树的修剪：**决策树容易过拟合，一般来需要剪枝，缩小树结构规模、缓解过拟合。剪枝技术有预剪枝和后剪枝两种。 在决策树的生成和修剪步骤，对于三个算法大同小异，下面主要学习下特征的选择问题。 决策树算法的框架如下所示 algorithm 2.3.1 决策算法 输入：训练集, 属性集 输出:一棵决策树 函数： 123456789生成节点node;if D中样本全部属于同一类别C then 将node节点标记为C类叶子节点, return ;if A为空集 or D中样本在A上取值相同 then 将node节点标记为叶节点,其类别标记为D中样本数最多的类 return ;从A中选择最优划分属性a_max;for a_max中的每一个取值a_val: 为node生成一个分支;令D_v表示D中取值为a_val的样本子集 以TreeGenerate(D_v,A-{a_max})为分支节点 因此决策树的关键在于选择最优划分属性，一般而言，随着划分过程不断进行，我们希望决策树的分支节点所包含的样本尽可能的属于同一类别。 2. 特征选择标准 2.1. 信息增益(ID3算法) 设当前样本集合D中第类样本所占的比例为 那么D的信息熵定义为： 使用属性作为划分属性的信息增益为 对取值数目较多的属性有偏好, 其根本原因在于, 当时， 最大， 从公式建模的角度上来说，信息熵建模本身就无法提供任意两个概率分布之间的距离估算。 2.2. 增益率(C4.5算法) 增益率定义为 被称为的“固有值”。需要注意的是，增益率准则对可取值数目较少的属性有所偏好。因此，C4.5算法并不是直接选择增益率最大的侯选划分属性，而是使用了一个启发式：先从侯选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的, 但从根本上来说，由于仍然使用信息熵作为基础的评估方式，启发式方法只能一定程度上缓解对多值属性的偏好。 2.3. 基尼指数(CART树) 对于离散数据，数据集的纯度可以使用基尼值来度量，值的定义如下： 直观来说，反映了从数据集中随机抽取两个样本，其类别标记不一致的概率。值越小，则数据集的纯度越高。属性的基尼指数定义为： 于是我们在侯选属性集合A中选择那个使得划分后基尼指数最小的属性作为最优划分属性，即. 对于回归任务，一颗回归树对应着输入空间的一个划分以及在划分的单元上的输出值。假设已将输入空间划分为个单元,并且在每个单元上游一个固定的输出值, 回归树模型可以表示为, 当输入空间的划分确定后，使用平方误差来表示回归树在训练数据的预测误差，并求解单元上的的最优值，易知所有值的最优值为上样本点标签的均值。 3. 树生成 3.1. ID3算法 算法 3.1. ID3树生成算法 输入: 训练数据集，特征集阈值. 输出: 决策树. Step 1. 如果中的所有实例都属于同一类, 则为单节点树，并将类作为节点的标记, 返回； Step 2. 如果, 则为单节点树，并将数据集中实例树最大的类作为节点的标记, 返回; Step 3. 计算所有属性对决策属性的信息增益，选择信息增益最大的属性; Step 4. 如果的信息增益小于阈值, 则置为单节点树，并将数据集中实例树最大的类作为节点的标记, 返回; Step 5. 根据的取值获得数据的一个划分，对划分中的每一个子数据集为训练集作为特征集，递归调用Step 1-5生成叶子节点的类别标记. 3.2. C4.5算法 算法 3.1. C4.5树生成算法 输入: 训练数据集，特征集阈值. 输出: 决策树. Step 1. 如果中的所有实例都属于同一类, 则为单节点树，并将类作为节点的标记, 返回； Step 2. 如果, 则为单节点树，并将数据集中实例树最大的类作为节点的标记, 返回; Step 3. 计算所有属性对决策属性的信息增益率，选择信息增益率最大的属性; Step 4. 如果的信息增益小于阈值, 则置为单节点树，并将数据集中实例树最大的类作为节点的标记, 返回; Step 5. 根据的取值获得数据的一个划分，对划分中的每一个子数据集为训练集作为特征集，递归调用Step 1-5生成叶子节点的类别标记. 3.3. CART算法 算法 3.3.1. 最小二乘回归算法 输入: 训练数据集; 输出：回归树 Step 1. 选择最优切分变量和切分点,求解 遍历变量，对固定的切分变量扫描切分点, 选择使上式最小的; Step 2. 用选定的划分区域并决定相应的输出值: Step 3. 继续对两个子区域调用上述步骤，直到满足停止条件 Step 4. 将输入控件划分为个子区域, 生成决策树. 算法 3.3.2 CART分类树 输入: 训练数据集，停止计算的条件. 输出: 决策树. Step 1. 如果中的所有实例都属于同一类, 则为单节点树，并将类作为节点的标记, 返回； Step 2. 如果, 则为单节点树，并将数据集中实例树最大的类作为节点的标记, 返回; Step 3. 计算所有属性对决策属性的Gini指数(对所有属性的属性值基于是否划分为两个数据集子集)，选择Gini指数最小的属性; Step 4. 根据的最优值划分获得数据的一个划分，对划分中的每一个子数据集为训练集作为特征集，递归调用Step 1-4生成叶子节点的类别标记. 4. 剪枝处理 4.1. 预剪枝 将数据集划分为训练集和测试集，每次分支也考虑验证集上的分类效果，在西瓜书中其评价指标为分类精度，若分支后的分类精度在训练集上和测试集上都有提升，那么分支，否则禁止分支。 4.2.后剪枝 以决策树生成节点的顺序为节点的序，逆序遍历所有分支节点，考察替换成叶子节点后验证集上分类精度的变化，若有提升则将分支节点替换成叶子节点； 另外一种情况是使用损失函数来进行剪枝与否判断。设树的叶节点个数为, 是树的叶子节点，该叶节点有个样本点，其中类的样本点有个，. 是叶节点上的经验熵，则决策树学习的损失函数可以定义为 , 对所有叶子节点确定剪枝前后的损失函数值来确定。 算法 4.2.1 CART剪枝算法 输入：CART算法生成的决策树 输出：最优决策树 Step 1. 设, , Step 2. 自下而上地对各内部节点计算以及,其中表示以为根节点的子树，是对训练数据的预测误差，是树的叶节点个数。 5. 连续值与缺失值处理 5.1. 连续值处理 设存在连续属性，假定出现了个不同取值，将这些值从小到大排序，记为。记由划分点得到的数据划分为。因此，对连续属性可以考察个元素的侯选划分点集合 而后考察划分。而后计算得到的信息增益可用以分支判断。需要注意的是，分支每次只分两支，也就是说离散化每次分支只进行一次，后续分支仍可继续使用该属性继续离散化分支。 5.2. 缺失值处理 使用已知数据来评估分支，而后将缺失值的对象加入到每一个拓展分支的对象集中. 例如, 设存在缺失值的属性, 表示属性上无缺失值的样本, 表示无缺失值样本所占比例, 表示无缺失值样本第类样本所占比例. 表示无缺失值样本中上取值的样本的比例. 则可将信息增益的计算式推广为: 6. 拓展 6.1. 多变量决策树 与传统的单变量决策树不同, 多变量决策树学习过程中, 不是为每个非叶节点寻找一个最优划分属性, 而是试图建立一个合适的线性分类器. 多变量决策树算法主要有OC1[Murthy et al., 1994]和[Brodley and Utgoff, 1995]提出的一系列算法. OC1先贪心地寻找每个属性的最优权值, 在局部优化的基础上在对分类边界进行随机扰动以试图寻找到更好的边界; [Brodley and Utgoff, 1995]则直接引入了线性分类器的最小二乘法. 6.2. 为何信息增益会偏向多取值特征？ 从直观的理解上来说，当特征取值较多时， 根据此特征划分得到的子集纯度有更大的可能性会更高（对比取值较少的特征）， 因此划分之后的熵会更低，而又由于划分之前的熵是一定的，因此信息增益更大。 6.3. 树形结构为何不需要归一化？ 因为数值缩放不影响分裂点位置，对树模型的结构不造成影响。按照特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会有不同。而且，树模型是不能进行梯度下降的，因为构建树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，因此树模型是阶跃的，阶跃点是不可导的，并且求导没意义，也就不需要归一化 决策树的目标是得到可靠的if-then规则集合，其规则可以由从根节点到叶子节点的完整路径导出。 决策树的构建主要通过递归的选择特征将特征域划分为若干子空间使得子空间样本集损失函数最小。 特征选择： 信息增益 [ID3]：；缺点是会选择取值较多的特征 信息增益率 [C4.5]：, 底部除以的信息熵，对其进行惩罚，实质上并没有从根本上解决，信息熵衡量了信息的有效性，取值较多问题的实质是有无用的取值被信息熵计算到了收益里面，增益率可以缓解这个问题，但不能根除，可以考虑重新设计公式。 Gini指数 (可辨识关系) [CART]：§, 去除了指数运算，降低运算量 平方误差：, 其中为划分的空间，为划分空间所对应的预测值。 ID3算法： 输入： 训练集, 特征集信息增益阈值 输出：决策树 如果中实例属于同一类 或者 为空, 则为单节点树，并将D中占比最大的类作为该节点的标记，返回；否则继续 计算中各个特征对的信息增益，选择信息增益最大的特征，如果最大信息增益小于给定阈值, 那么构建节点并设置占比最大的类作为标签，返回；否则继续 根据划分数据集, 对每个数据集，跳转到1，生成新的叶节点。 ID3算法的缺点： 没有考虑连续特征，比如长度，密度 没有考虑缺失值的情况 没有考虑过拟合的问题 决策树生成算法递归的产生决策树，直到不能继续下去为止。这样的树容易过拟合。解决决策树过拟合的一个方法是通过剪枝简化决策树。设树有叶节点个数为, 是树的叶节点，含有个样本，为叶节点的经验熵，那么决策树学习的损失函数可以定义为 对于连续属性，排序，对每两个不同的值取中位数作为分裂点，计算信息增益，选择最大信息增益的分裂点。注意，在决策树中连续属性可以被多次选择用以划分样本集 剪枝方法： 预剪枝 + 限制决策树深度 计算所有节点的合并损失，并按序列检查在验证集上的预测误差 C4.5算法 输入： 训练集, 特征集信息增益率阈值 输出：决策树 **Step 1：**决策树生成 如果中实例属于同一类 或者 为空, 则为单节点树，并将D中占比最大的类作为该节点的标记，返回；否则继续 计算中各个特征对的信息增益率，选择信息增益率最大的特征，如果最大信息增益率小于给定阈值, 那么构建节点并设置占比最大的类作为标签，返回；否则继续 根据划分数据集, 对每个数据集，跳转到1，生成新的叶节点。 **Step 2：**决策树剪枝 遍历决策树，然后检查叶子节点的父节点合并叶子节点的损失函数前后变化，如果合并后变得更小，那么剪枝。 C4.5算法缺点： 只能用以分类 重要度计算复杂度高 CART算法： 输入： 训练集, 特征集信息增益率阈值 输出：二叉决策树 回归： 选择最优切分变量与切分点, 求解 如果满足停止条件，对划分的区域打上样本集合标签的均值作为预测值生成叶子节点； 否则基于划分得到的样本空间跳转到步骤1继续生成决策树 分类： 如果中实例属于同一类 或者 为空, 则为单节点树，并将D中占比最大的类作为该节点的标记，返回；否则继续 计算中各个特征对的信Gini指数，选择指数值最大的特征，如果最大Gini指数小于给定阈值, 那么构建节点并设置占比最大的类作为标签，返回；否则继续 根据划分数据集, 对每个数据集，跳转到1，生成新的叶节点。 剪枝： 输入：CART算法生成的决策树 输出：最优决策树 自下而上地对各内部节点计算, 这里表示以为根节点的子树， 是对训练数据的预测误差，是的叶节点个数 对的内部节点进行剪枝，并对叶节点以多数表决确定其类标签，得到树 如果不是由根节点及两个叶结点构成的树，跳转步骤2. 否则令 采用交叉验证法在子树序列中选择最优子树","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"logic regression","slug":"logic-regression","permalink":"http://yourthomaslee.github.io/tags/logic-regression/"}]},{"title":"Leetcode 1223. Dice Roll Simulation","slug":"Leetcode 1223","date":"2023-02-10T02:40:05.000Z","updated":"2023-02-14T15:07:02.859Z","comments":true,"path":"2023/02/10/Leetcode 1223/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/10/Leetcode%201223/","excerpt":"","text":"The problem description can be found at the link Solution explanation can be referred at link Solution: 123456789101112131415161718192021class Solution {public: static constexpr int mod = 1E9 + 7; int dieSimulator(int n, vector&lt;int&gt;&amp; rollMax) { vector d(n + 1, vector&lt;int&gt;(6, 0)); vector&lt;int&gt; sum(n + 1, 0); sum[0] = 1; for (int i = 1; i &lt;= n; i++) { for (int j = 0; j &lt; 6; j++) { int pos = max(i - rollMax[j] - 1, 0); int sub = ((sum[pos] - d[pos][j]) % mod + mod) % mod; d[i][j] = ((sum[i - 1] - sub) % mod + mod) % mod; if (i &lt;= rollMax[j]) { d[i][j] = (d[i][j] + 1) % mod; } sum[i] = (sum[i] + d[i][j]) % mod; } } return sum[n]; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"dynamic programming","slug":"dynamic-programming","permalink":"http://yourthomaslee.github.io/tags/dynamic-programming/"},{"name":"combination","slug":"combination","permalink":"http://yourthomaslee.github.io/tags/combination/"},{"name":"interesting problems","slug":"interesting-problems","permalink":"http://yourthomaslee.github.io/tags/interesting-problems/"}]},{"title":"Machine learning foundation 1 - Part 2. Logic regression and maximum entropy models","slug":"Machine learning foundation 1.1 - logic regression and maximum entropy model","date":"2023-02-10T02:40:05.000Z","updated":"2023-02-11T10:23:15.092Z","comments":true,"path":"2023/02/10/Machine learning foundation 1.1 - logic regression and maximum entropy model/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/10/Machine%20learning%20foundation%201.1%20-%20logic%20regression%20and%20maximum%20entropy%20model/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 Outline [TOC] 1. 最大熵原理 熵§是一个评估信息（也叫不确定性）的一个函数，当分布趋向于均匀分布的时候，熵达到最大。 最大熵原理认为，学习概率模型时，在满足约束条件的情况下（拟合训练数据），在所有可能得概率模型(分布)中，熵最大的模型是最好的模型（对所有未知情况保持平等的态度，也就是等可能）。 1.1 最大熵模型的定义 我们考虑具体的一个学习任务，假设特征(可以自己预设和自己定义，提供拓展性)已经被形式化成以下函数 与满足某一事实否则 在经验分布上特征函数的期望值为, 引入模型后为, 如果训练数据中对任务足够多的信息，那么可以认为有. 定义 1. 假设满足所有约束条件的模型集合为, 定义在条件概率分布上的条件熵为§, 则模型集合中条件熵§最大的模型称为最大熵模型。 1.2 最大熵模型的学习 最大熵模型的学习过程就是求解最大熵模型的过程。已有的求解方式有两种，一种是极大似然估计，另外一种是转化对偶问题求解。此处陈列两种方式对优化目标的推演过程。 优化目标：给定训练数据集和任务所关心的一系列特征函数, 需要最大化条件信息熵§, 对偶问题: 优化目标可以转化为, 在此基础上将约束通过拉格朗日乘子法写作如下公式 Misplaced & L(P,w)=&amp;\\sum_{x,y}\\hat P(x)P(y|x)\\log P(y |x) + w_0(1 - \\sum_y P(y|x)) \\&amp;+ \\sum_{i=1}^{n}w_i(\\sum_{x,y}\\hat P(x,y)f_i(x,y) - \\sum_{x,y}\\hat P(x)P(y|x)f_i(x,y))\\ =&amp;\\sum_{x,y}\\hat P(x)P(y|x)(\\log P(y|x) - \\sum_{i=1}^n w_if_i(x,y))\\ &amp;- w_0 \\sum_y P(y|x) + \\sum_{i=1}^{n}\\sum_{x,y}w_i\\hat P(x,y)f_i(x,y) +w_0 最优化的原始问题是, 对偶问题是. 先求解内部极小化问题, 有 Misplaced & \\frac{\\partial L(P,w)}{\\partial P(y,x)} =&amp;\\sum_{x,y}\\hat P(x)(\\log P(y|x) - \\sum_{i=1}^nw_if_i(x,y) + 1) - \\sum_y w_0\\ =&amp; \\sum_{x,y}\\hat P(x) (\\log P(y|x) + 1 - w_0 - \\sum_{i=1}^n w_if_i(x,y)) 令偏导为0得到. 也就是, 由于得到，也就是说, 为规范化因子。 代入结论再求解极大化问题 得到之间的关系解得的值。 极大似然估计 根据上面步骤的中间结果可以知晓, 有了概率以后可以使用极大似然估计 Misplaced & L_{\\hat P}(P_w) &amp;= \\log \\prod_{x,y}P(y|x)^{\\hat P(x,y)} \\ &amp;= \\sum_{x,y}\\hat P(x,y)\\log P(y|x) \\ &amp;= \\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nw_if_i(x,y)-\\sum_x\\hat P(x)\\log Z_w(x) 如果将代入到公式(2)中，那么可以得到相同的结果。 这证明最大熵模型的对偶问题和极大似然估计二者是等价的。 最优化算法 最大熵模型学习归结为以似然函数为目标函数的最优化问题，通常使用迭代算法求解。从最优化的观点看，这时的目标函数是光滑的凸函数，因此多种最优化的方法都适用，保证能找到全局最优解。常用的方法有改进的迭代尺度法、梯度下降法、牛顿法或拟牛顿法。 优缺点 优点：1. 建模时，实验者只需要集中精力选择特征，不需要花费精力考虑如何使用这些特征； 2. 每个特征对概率分布的贡献由算法迭代训练得到的参数决定，可以很灵活地选择特征，使用各种不同类型的特征，且容易更换； 3. 利用最大熵建模，不需要使用数据独立同分布假设，参数平滑也可以通过特征选择的方式加以考虑 缺点： 最大熵模型的计算量巨大，在工程实现方法的好坏决定了模型的使用与否。 2. 逻辑回归模型 逻辑回归可以认为是最大熵模型在二分类问题上的一个模型实例。 定义 2. [逻辑斯谛分布]设是连续随机变量，服从逻辑斯谛分布具有下列分布函数和密度函数 式中为位置参数， 为形状参数。形状参数的值越小， 曲线中心附近增长的越快。 定义3. [逻辑回归模型] 二项逻辑斯谛回归模型用如下的条件概率分布来进行拟合数据： 这里是输入， 是输出，和是参数权重和偏置。 该模型有一个显著的特点是事件发生的几率和不发生的几率的比值可以写作 § 模型参数估计使用最大似然法估计模型参数，从而得到一个具体的模型 Misplaced & L(w) =&amp; \\log \\prod_{i=1}^N p^{y_i}(1-p)^{1-y_i}\\ =&amp; \\sum_{i = 1}^N [y_i\\log p + (1 - y_i)\\log(1 - p)]\\ =&amp; \\sum_{i = 1}^N [y_i\\log\\frac{p}{1-p} + \\log(1-p)]\\ =&amp; \\sum_{i = 1}^N [y_i(w \\cdot x + b) - \\log(1 + \\exp(w \\cdot x + b))] 由此最大化似然概率得到相应的的估计值。","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"logic regression","slug":"logic-regression","permalink":"http://yourthomaslee.github.io/tags/logic-regression/"},{"name":"maximum entropy model","slug":"maximum-entropy-model","permalink":"http://yourthomaslee.github.io/tags/maximum-entropy-model/"}]},{"title":"Leetcode 1797. Design Authentication Manager","slug":"Leetcode 1797","date":"2023-02-09T02:40:05.000Z","updated":"2023-02-14T15:07:27.828Z","comments":true,"path":"2023/02/09/Leetcode 1797/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/09/Leetcode%201797/","excerpt":"","text":"The problem description can be found at the link My solution: 12345678910111213141516171819202122232425class AuthenticationManager {public: int timeToLive; map&lt;string, int&gt; u2t; AuthenticationManager(int timeToLive) { this-&gt;timeToLive = timeToLive; } void generate(string tokenId, int currentTime) { u2t[tokenId] = currentTime; } void renew(string tokenId, int currentTime) { if(u2t.find(tokenId) != u2t.end() &amp;&amp; currentTime - u2t[tokenId] &lt; timeToLive) u2t[tokenId] = currentTime; } int countUnexpiredTokens(int currentTime) { int ans = 0; for(auto x: u2t){ if(currentTime - x.second &lt; timeToLive) ans++; } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"}]},{"title":"Leetcode 1233. Remove Sub-Folders from the Filesystem","slug":"Leetcode 1233","date":"2023-02-08T02:40:05.000Z","updated":"2023-02-14T15:07:10.511Z","comments":true,"path":"2023/02/08/Leetcode 1233/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/08/Leetcode%201233/","excerpt":"","text":"Problem description can be found at link My solution: 12345678910111213141516171819class Solution {public: vector&lt;string&gt; removeSubfolders(vector&lt;string&gt;&amp; folder) { sort(folder.begin(), folder.end()); vector&lt;string&gt; ans; int p = 0, len = 0; ans.emplace_back(folder[0]); for(int i = 1; i &lt; folder.size(); ++i){ len = min(folder[i].size(), folder[p].size()); if(folder[i].substr(0, len) == folder[p].substr(0, len) &amp;&amp; folder[i][len] == '/'){ continue; }else{ ans.emplace_back(folder[i]); p = i; } } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"array","slug":"array","permalink":"http://yourthomaslee.github.io/tags/array/"}]},{"title":"Machine learning foundation 1 - Part 1. linear regression","slug":"Machine learning foundation 1.0 - linear regression","date":"2023-02-08T02:40:05.000Z","updated":"2023-02-10T04:33:43.374Z","comments":true,"path":"2023/02/08/Machine learning foundation 1.0 - linear regression/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/08/Machine%20learning%20foundation%201.0%20-%20linear%20regression/","excerpt":"","text":"12345678统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下：1. 得到一个有限的训练数据集合；2. 确定包含所有可能的模型的假设空间，即学习模型的集合；3. 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）；4. 实现求解最优模型的算法，即学习的算法（优化算法）；5. 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）；6. 利用学习的最优模型对新数据进行预测或分析；后续将对一个个模型进行深入的学习和理解 Outline 1234567891011121314graph LRA(线性回归) --&gt; B[直觉]A(线性回归) --&gt; C[模型]A(线性回归) --&gt; D[优化]A(线性回归) --&gt; E[拓展]B[直觉] --&gt; F[找到一条直线或一个平面能够根据输入的特征向量来更好的预测输出y的值]B[直觉] --&gt; G[损失函数:平方损失,绝对值损失,huber损失]C[模型] --&gt; N[线性函数]D[优化] --&gt; H[梯度下降]D[优化] --&gt; I[正规方程组]E[拓展] --&gt; J[Lasso回归-L1 Norm]E[拓展] --&gt; K[岭回归-L2 Norm]E[拓展] --&gt; L[局部加权线性回归]E[拓展] --&gt; M[ElasticNet-L1 L2 Norm] 1. 直觉与目标 简单来说，线性回归算法就是**找到一条直线（一元线性回归）或一个平面（多元线性回归）能够根据输入的特征向量来更好的预测输出y的值。**其本质含义在于 X 与 Y 是线性相关的。 在有了该直觉之后，我们的第一个目标是根据给定的如何评估一条直线是否合理，也就是如何评估出多个不同的直线的序，目前比较典型的思路是设计一个函数，输入给定的模型和数据，输出键值，比较键值大小就可以知晓哪一条直线是最优的(一般默认越小越好)。就目前来说，典型的键值(损失)函数有三种，具体公式如下，损失函数图如下。 平方损失： , 对异常点有较大的惩罚，不够robust。 绝对值损失：，在0处不可导，不易优化 Huber损失：，该损失函数是1,2的综合，较为鲁棒 第一个目标达成后，我们的目标就变为根据数据将不合理的直线调整变换为合理，该过程也叫学习，在机器学习中叫优化, 该部分内容详见第3部分。 2. 模型 给定训练数据, 线性回归的模型设定为 一般地，我们使用平方损失函数来做为衡量直线优劣的指标，也即. 朴素的二元线性回归：梯度下降法 Missing \\end{aligned} \\begin{aligned}\\frac{\\partial L}{\\partial w}=&amp;\\sum_{i=1}^{n}2(wx_i+b-y_i)x_i\\&amp;=2\\sum_{i=1}^{n}w(x_i)^2+bx_i-x_iy_i\\\\frac{\\partial L}{\\partial b}=&amp;\\sum_{i=1}^{n}2(wx_i+b-y_i)=0\\&amp;\\Rightarrow b=\\frac{\\sum_{i=1}^{n}y_i-wx_i}{n}\\\\frac{\\partial L}{\\partial w}=&amp;2\\sum_{i=1}^{n}w(x_i)^2+(\\overline y-w\\overline x)x_i-x_iy_i\\&amp;=2\\sum_{i=1}^{n}[w(x_i)^2+\\overline y x_i - w \\overline x x_i -x_iy_i]=0\\&amp;\\Rightarrow w=\\frac{\\sum_{i=1}^{n}[x_iy_i-x_i\\overline y]}{\\sum_{i=1}^{n} [(x_i)^2-\\overline x x_i]}=\\frac{\\sum_{i=1}^{n}x_iy_i-\\frac{1}{n}\\sum_{i=1}^{n}x_i\\sum_{i=1}^{n} y_i}{\\sum_{i=1}^{n} (x_i)^2-\\frac{1}{n}\\sum_{i=1}^{n} x_i \\sum_{i=1}^{n}x_i}\\&amp;=\\frac{\\sum_{i=1}^{n}(x_i-\\overline x)(y_i-\\overline y)}{\\sum_{i=1}^{n}(x_i-\\overline x)^2}\\\\end{aligned} 注意: 2.1 最小二乘法 对该模型最原始计算方法为最小二乘法，给定训练数据如下 则有 2.1.1 最小二乘法的概率角度的视角 设误差服从正态分布，那么有~，则有~, 公式建模 极大似然估计： 3. 优化 优化一般有两种，一种是正规方程组，一种是梯度下降法。已知损失函数 正规方程组: 对损失函数求导，即有, 令该式子为0则得 梯度下降：选择批量大小为, 那么有 正规方程组需要保证没有特征之间没有相关性，另外也无法应用于大规模的线性回归，而梯度下降需要选择合适的学习率，适合大规模场景下的线性回归，同时，随机梯度下降无法保证得到的解一定是最优，但正规方程组可以保证解为最优。 4. 拓展 4.1 岭回归 由于正规方程组需要保证可逆，对于有个样本，有个属性的数据，如果，那么不可逆。岭回归通过增加L2正则化来保证可逆。具体来说损失函数如下 加入的正则化有两个效果，一个是保证可逆，另一个是抑制过拟合。 如果样本数据过少导致线性回归拟合较差，则考虑采用岭回归。如何输入特征的维度很高,而且是稀疏线性关系的话， 岭回归就不太合适,考虑使用Lasso回归。L2正则假设参数的先验分布是Gaussian分布，可以保证模型的稳定性，也就是参数的值不会太大或太小. L2范数是各参数的平方和再求平方根，我们让L2范数的正则项最小，可以使的每个元素都很小，都接近于0。但它不会是每个元素为0，而只是接近于0。越小的参数说明模型越简单，越简单的模型越不容易产生过拟合现象。L2不能控制feature的“个数”，但是能防止模型overfit到某个feature上 4.2 Lasso回归 Lasso 回归的本质是 线性回归 + L1 正则化。 L1正则化(Lasso回归)可以使得一些特征的系数变小,甚至还使一些绝对值较小的系数直接变为0，从而增强模型的泛化能力 。对于高的特征数据,尤其是线性关系是稀疏的，就采用L1正则化(Lasso回归),或者是要在一堆特征里面找出主要的特征，那么L1正则化(Lasso回归)更是首选了。L1正则假设参数的先验分布是Laplace分布，可以保证模型的稀疏性，也就是某些参数等于0, L1正则化是L0正则化的最优凸近似，比L0容易求解，并且也可以实现稀疏的效果, L1是控制feature“个数”的，并且鼓励模型在少量几个feature上有较大的权重。 4.3 局部加权线性回归 在线性回归中， 由于最终拟合出来的曲线是一条直线，其拟合能力极为有限（也可以解释为线性回归所求的是具有最小均方误差的无偏估计），因此很容易造成欠拟合现象， 而针对这个问题，有人提出了局部线性回归(LWR)。 在LWR中， 其损失函数为： 矩阵表示 此时，使用回归方程求得： 而通常， 服从高斯分布， 在目标区域附近指数型衰减; 其中， k 值越小，敏感半径越小。值决定了线性回归的拟合半径 4.3 ElasticNet回归 ElasticNet回归本质上是线性回归 + L1正则化 + L2 正则化，损失函数变为： Reference","categories":[],"tags":[{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"linear regression","slug":"linear-regression","permalink":"http://yourthomaslee.github.io/tags/linear-regression/"}]},{"title":"Machine learning foundation 0 - framework","slug":"Machine learning foundation 0 - framework","date":"2023-02-08T02:40:05.000Z","updated":"2023-02-10T04:31:35.776Z","comments":true,"path":"2023/02/08/Machine learning foundation 0 - framework/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/08/Machine%20learning%20foundation%200%20-%20framework/","excerpt":"","text":"基础概念 任务：给定一定量的数据，利用模型归纳、总结、学习数据中的规律和知识，应用到新数据的观察、评估、预测中 学习：如果一个系统能够通过执行某个过程改进它的性能， 这就是学习（Herbert A. Simon） 统计学习：从给定的、有限的、用于学习的训练数据集合(training data)出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间(hypothesis space); 应用某个评价准则(evaluation criterion)，从假设空间中选取一个最优模型，使它对已知的训练数据及位置的测试数据在给定评价准则下有最优的预测；最优模型的选取由算法实现。 其重要性在于（1）可以处理海量数据；（2）被证明是计算机智能化的有效手段；（3）是计算机学科发展的重要组成部分； 统计学习分类：从任务上来说，一般包括监督学习、无监督学习、强化学习。有时还包括半监督学习、主动学习；[李航， 统计学习方法(2rd)] 标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。监 督学习的本质是学习输入到输出的映射的统计规律。 无监督学习是指从无标注数据中学习预测模型的机器 学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。无 监 督 学 习的 本 质 是 学 习 数 据 中 的 统 计规 律 或 潜 在 结 构 强化学习(reinforcement learning)是指智能系统在与环境的连续互动中学习 最优行为策略的机器学 习问题。假设智能 系统与环境的互动基于马尔可 夫决策过 程(Markov decision process)，智能系统能观测到的是与环境互动得到的数据序列。 强化学习的本质是学习最优的序贯决策。强化学习的目标就是在所有可能的策略中选出价值函数最大的策略，而在实际 学习中往往从具体的策略出发，不断优化己有策略。 半监督学习(semi-supervised learning) 是指利用标注数据和未标注数据学习预 测模型的机器学 习问题。通常有少量标注数据、大量未标注数据，因为标注数据的构 建 往 往 需 要 人 工， 成 本 较 高 ， 未 标 注 数 据 的 收 集 不 需 太 多 成 本 。 半 监 督 学 习 旨 在 利 用 未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习 效果。 主动学习(active learning)是指机器不断主动给出实例让教师进行标注，然后利 用标注数据学习预测模型的机器学习问题。通常的监督学习使用给定的标注数据，往 往是随机得到的，可以看作是“ 被动学习”，主动学习的目标是找出对学习最有帮助的 实例让教师标注，以较小的标注代价，达到较好的学习效果。 从模型的角度上说，可以分为 概率模型（决策树、朴素贝叶斯、隐马尔科夫模型、条件随机场、概率潜在语义分析、高斯混合模型等）和非概率模型（感知机、支持向量机、近邻、AdaBoost、均值聚类、潜在语义分析以及神经网络）； 线性模型（感知机、线性支持向量机、近邻、均值聚类、潜在语义分析）和非线性模型（核支持向量机、AdaBoost、神经网络）； 参数化模型（感知机、朴素贝叶斯、逻辑回归、均值聚类、高斯混合模型等等）和非参数化模型（决策树、支持向量机、AdaBoos、近邻、语义分析和狄利克雷分配） 按算法分类则可以分为在线学习(online learning)和批量学习(batch learning); 按技巧分类则有贝叶斯学习（其 主 要 想 法 是 ， 在 概 率模 型 的 学 习 和 推 理 中 ， 利 用 贝 叶斯定理，计算在给定数据条件 下模型的条件概率，即后验概率，并应用这个原理进 行模型的估计，以及对数据的预测。将模型、未观测要素及其参数用变量表示，使用 模型的先验分布是贝叶斯学习的特点）、核方法（使用核函数表示和学习非线性模型的一种机器学习方 法）。 统计学习方法三大要素：模型（model)、策略（strategy)和算法（algorithm）。其一般的实现步骤如下： 得到一个有限的训练数据集合； 确定包含所有可能的模型的假设空间，即学习模型的集合； 确定模型选择的准则，即学习的策略（一般经验风险最小化[各种损失函数]+结构风险最小化[L1正则化、L2正则化]）； 实现求解最优模型的算法，即学习的算法（优化算法）； 通过学习方法选择最优的模型（简单交叉、K折交叉、留1交叉验证）； 利用学习的最优模型对新数据进行预测或分析； [由于李航的泛化下界分析内容没有写成闭包，此处暂时不进行深入学习，后续再复习] 后续将从两个维度进行学习，第一个是机器学习常见模型进行学习，这一部分更加侧重理论，第二个是按实现步骤进行学习，更加侧重应用和思考 有空可以后续学习的信息： 机器学习理论： Guarantees in Machine learning pen-and-paper exercises in machine learning： https://github.com/michaelgutmann/ml-pen-and-paper-exercises","categories":[],"tags":[{"name":"machine learning framework","slug":"machine-learning-framework","permalink":"http://yourthomaslee.github.io/tags/machine-learning-framework/"}]},{"title":"Leetcode 1604. Alert Using Same Key-Card Three or More Times in a One Hour Period","slug":"Leetcode 1604","date":"2023-02-07T02:40:05.000Z","updated":"2023-02-07T15:10:40.190Z","comments":true,"path":"2023/02/07/Leetcode 1604/","link":"","permalink":"http://yourthomaslee.github.io/2023/02/07/Leetcode%201604/","excerpt":"","text":"Problem description can be found at link My solution: 12345678910111213141516171819202122232425262728293031class Solution {public: struct op{ string name; int time; }; static bool comp(op&amp; a, op&amp; b){ if(a.name &lt; b.name){ return true; }else if(a.name == b.name){ return a.time &lt; b.time; }else return false; } vector&lt;string&gt; alertNames(vector&lt;string&gt;&amp; keyName, vector&lt;string&gt;&amp; keyTime) { vector&lt;op&gt; x; op t; for(int i = 0; i &lt; keyName.size(); ++i){ t.name = keyName[i]; t.time = stoi(keyTime[i].substr(0, 2)) * 60 + stoi(keyTime[i].substr(3, 2)); x.emplace_back(t); } sort(x.begin(), x.end(), comp); vector&lt;string&gt; ans; for(int i = 2; i &lt; x.size(); ++i){ if(ans.size() &gt; 0 &amp;&amp; x[i].name == ans[ans.size() - 1]) continue; if(x[i].name == x[i - 2].name &amp;&amp; abs(x[i].time - x[i - 2].time) &lt;= 60) ans.emplace_back(x[i].name); } return ans; }};","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"}]},{"title":"Note - An attention free transformer","slug":"Note-An attention free transformer","date":"2023-01-17T02:40:05.000Z","updated":"2023-02-07T15:08:41.515Z","comments":true,"path":"2023/01/17/Note-An attention free transformer/","link":"","permalink":"http://yourthomaslee.github.io/2023/01/17/Note-An%20attention%20free%20transformer/","excerpt":"","text":"Paper address: https://arxiv.org/pdf/2105.14103.pdf Related codes: https://github.com/BlinkDL/RWKV-LM Have not updated yet Concepts: a model with parameter training on dataset using stochastic gradient descent(SGD) : a batch of size from dataset at step with is the predictive distribution of the current model, where is the sequence of data the model was trained on before training step $ D_{ho} ={ (x_{ho}, y_{ho}) } {i=1}^{n{ho} } x_{ho}y_{ho}p_{true}(x′, y′)D$. Intuition: Previous online batch selection methods aim to select points that minimize the training set loss. Instead, we aim to select points that minimize the loss on a holdout set. We aim to acquire the point that would minimize the negative log-likelihood/cross-entropy loss on the holdout set: $ arg \\min {(x,y)\\in B_t} - \\log p(y{ho}|x_{ho};D_t \\cup (x, y))$ [get similar distribution as holdout set] Inference: For a model using a point estimate of (such as an MLE or MAP), rather than a distribution over , the holdout loss factorises and (up to a constant factor) forms a Monte Carlo approximation of the expected loss under : , where denotes the cross-entropy loss: , $$ \\log p(y_{ho}|x_{ho};D_t \\cup (x, y)) = \\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x,x_{ho};D_t)}[Bayes; rule]\\ =\\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x;D_t)}[conditional; independence; rule]\\ \\propto L[y|x;D_t] - L[y|x;D_{ho},D_t]\\ \\sim L[y|x;D_t] - L[y|x;D_{ho}]\\ \\Rightarrow \\arg \\max {(x,y) \\in B_t} L[y|x;D_t] - L[y|x;D{ho}]\\quad[training; loss - ;irreducible; holdout; loss] $$ Algorithm: Exploring: why not design a new simpler loss based on rough set thoery? it seems RHOLOSS is still a little expensive in implementation and computation. Actually this work provides a good way to think about the training sample selection problem. There are still room for some more further researches in computation simplicity and cost aspects","categories":[],"tags":[{"name":"transfomer","slug":"transfomer","permalink":"http://yourthomaslee.github.io/tags/transfomer/"},{"name":"language model","slug":"language-model","permalink":"http://yourthomaslee.github.io/tags/language-model/"}]},{"title":"Curriculum vitae - Baizhen Li","slug":"Curriculum Vitae - Baizhen Li","date":"2022-12-26T13:54:13.432Z","updated":"2023-02-11T01:38:21.585Z","comments":true,"path":"2022/12/26/Curriculum Vitae - Baizhen Li/","link":"","permalink":"http://yourthomaslee.github.io/2022/12/26/Curriculum%20Vitae%20-%20Baizhen%20Li/","excerpt":"","text":"Contact information: Bricklees [at] alumni [dot] tongji [dot] edu [dot] cn || baizhen9406 [at] 163 [dot] com Education Tongji UNIVERSITY 06/2018 - 03/2021 M.E., Computer Technology. GPA: 87/100 Thesis: Research on dialogue state tracking algorithm based on cross-layer fusion Awards and honors: National Scholarship(2020), Second Prize of the 15th China Post-graduate Mathematical Contest in Modelling, Outstanding Dissertation Award YANTAI UNIVERSITY 06/2013 - 07/2017 B.E., Computer Science and Technology. GPA: 79/100 Thesis: Research on knowledge acquisition algorithms: a discernibility matrix approach Awards and honors: Outstanding Dissertation Award, Third Prize of LAN QIAO International Collegiate Programming Contest Experiences I. Research experiences From 08/2019 to 12/2020, I participated in “Research on the Refined Description and Interpretability of Targets under Surveillance Video”(National natural science foundation of China, No. 61976160). I was in charge of models that provide task-oriented descriptions of a picture collected from surveillance video while working as a researcher under the direction of professor Zhihua Wei and associate professor Lijun Sun. From 06/2018 to 07/2019, I took part in \"Topic Analysis Technology based on Natural Language Processing” (application research cooperated with the key lab of information network security, China ministry of public security, No. C18608). I created topic analysis-based detection techniques for illicit website detection while working as a researcher and developer under the direction of professor Zhihua Wei and associate professor Lijun Sun. From 03/2014 to 06/2017, I participated in “Knowledge Space Research based on Granular Computing Method” (national natural science foundation of China youth science fund project, No. 61403329). I created two more effective rough sets-based knowledge discovery algorithms as a research assistant under the direction of associate professor Nan Zhang. II. Work/Internship experiences BAIDU CHINA CO., LTD. 03/2021 – 05/2022 As an engineer, I was in charge of the real-time bidding system’s cost-per-thousand-impression calibration(CTIA) module. By tweaking the algorithm’s parameters and state estimates, I improved the proportional-integral-derivative (PID) control algorithm’s performance in CTIA. HAIYIZHI INFORMATION TECHNOLOGY CO., LTD. 06/2020 – 09/2020 I created a robot that serves as the customer support representative in the postal service’s online chat. After that, I used a non-autoregressive dialog state tracking model to reduce the inference latency for dialog state tracking. Publications [1] Baizhen Li, Yibin Zhan, Zhihua Wei, Shikun Huang, Lijun Sun: Improved non-autoregressive dialog state tracking model. CCRIS 2021: 199-203 [2] Baizhen Li, Zhihua Wei, Duoqian Miao, Nan Zhang, Wen Shen, Chang Gong, Hongyun Zhang, Lijun Sun: Improved general attribute reduction algorithms. Inf. Sci. 536: 298-316 (2020) [3] Baizhen Li, Wei Chen, Zhihua Wei, Hongyun Zhang, Nan Zhang, Lijun Sun: Quick Maximum Distribution Reduction in Inconsistent Decision Tables. IJCRS 2020: 169-182 [4] Nan Zhang, Baizhen Li, Zhongxi Zhang, Yanyan Guo: A Quick Algorithm for Binary Discernibility Matrix Simplification using Deterministic Finite Automata. Inf. 9(12): 314 (2018)","categories":[],"tags":[]},{"title":"Note - Prioritized training on points that are learnable worth learning and not yet learnt","slug":"Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt","date":"2022-07-22T02:40:05.000Z","updated":"2022-12-27T03:36:11.314Z","comments":true,"path":"2022/07/22/Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/22/Note-Prioritized-training-on-points-that-are-learnable-worth-learning-and-not-yet-learnt/","excerpt":"","text":"This paper introduce RHO_LOSS, which selects points that are learnable, worth learning, and not yet learnt. RHO-LOSS trains in far fewer steps than prior art, improves accuracy, and speeds up training on a wide range of datasets, hyperparameters, and architectures (MLPs, CNNs, and BERT) Code: https://github.com/OATML/RHO-Loss Concepts: a model with parameter training on dataset using stochastic gradient descent(SGD) : a batch of size from dataset at step with is the predictive distribution of the current model, where is the sequence of data the model was trained on before training step $ D_{ho} ={ (x_{ho}, y_{ho}) } {i=1}^{n{ho} } x_{ho}y_{ho}p_{true}(x′, y′)D$. Intuition: Previous online batch selection methods aim to select points that minimize the training set loss. Instead, we aim to select points that minimize the loss on a holdout set. We aim to acquire the point that would minimize the negative log-likelihood/cross-entropy loss on the holdout set: $ arg \\min {(x,y)\\in B_t} - \\log p(y{ho}|x_{ho};D_t \\cup (x, y))$ [get similar distribution as holdout set] Inference: For a model using a point estimate of (such as an MLE or MAP), rather than a distribution over , the holdout loss factorises and (up to a constant factor) forms a Monte Carlo approximation of the expected loss under : , where denotes the cross-entropy loss: , $$ \\log p(y_{ho}|x_{ho};D_t \\cup (x, y)) = \\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x,x_{ho};D_t)}[Bayes; rule]\\ =\\log \\frac{p(y|x, y_{ho},x_{ho};D_t \\cup (x, y)) ; p(y_{ho}|x_{ho},x;D_t)}{p(y|x;D_t)}[conditional; independence; rule]\\ \\propto L[y|x;D_t] - L[y|x;D_{ho},D_t]\\ \\sim L[y|x;D_t] - L[y|x;D_{ho}]\\ \\Rightarrow \\arg \\max {(x,y) \\in B_t} L[y|x;D_t] - L[y|x;D{ho}]\\quad[training; loss - ;irreducible; holdout; loss] $$ Algorithm: Exploring: why not design a new simpler loss based on rough set thoery? it seems RHOLOSS is still a little expensive in implementation and computation. Actually this work provides a good way to think about the training sample selection problem. There are still room for some more further researches in computation simplicity and cost aspects","categories":[],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"http://yourthomaslee.github.io/tags/deep-learning/"},{"name":"training sample selection","slug":"training-sample-selection","permalink":"http://yourthomaslee.github.io/tags/training-sample-selection/"}]},{"title":"Note-Trainable learning rate","slug":"Note-Trainable-learning-rate","date":"2022-07-19T09:26:53.000Z","updated":"2022-12-27T03:38:45.291Z","comments":true,"path":"2022/07/19/Note-Trainable-learning-rate/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/19/Note-Trainable-learning-rate/","excerpt":"","text":"Problem: selecting an appropriate learning rate is a challenge considering different model structures and datasets. Work: we propose an algorithm for automatically adjusting the learning rate during the gradient descent (line search method) Given the weights’ gradients, one could estimate if an overestimation or an underestimation of learning rate could further reduce the task loss by casting the learning rate as an extra trainable parameter. Problem Statement: the gradient descent framework (GD). vanilla form: , where is learning rate, is loss function and is the model parameters at iteration . In vanilla GD, Is treated as a hyperparameter and does not contribute to the loss. We introduce an augmented loss term , where we consider as the learnable variable. . Something noticing is that minimizing is equivalent to finding the optimal step-size for current . Naive GD-TLR: A straightforward idea is to apply GD over : , where hyperparameter Controls the updates of the initial learning rate Disadvantages: the addition of requires an extra forward-backward pass in order to compute the introduction of a GD step for creates the extra hyperparameter Efficient GD-TLR: let Denotes a standard feed-forward network of Layers, where and denote the non-linear activation and linear transformation corresponding to layer respectively. For the convenience of writing, we just consider the linearity of a single layer , where is the input from the previous layer, is the matrix of parameters, is the output. (, ) denotes the variables after GD update. So we have First-order gradient and insight: Assuming that corresponds to a specific layer, the gradient of the augmented loss compute as: the learning rate gradient can be expressed as the inner product of consecutive gradients , as a result we can rewrite equation (2) as $ \\frac{\\partial L_\\alpha}{\\partial \\alpha}|{a=\\alpha_t} = -&lt;\\triangledown L(w_t), \\triangledown L(w{t - 1})&gt; = -&lt;g_t, g_{t-1}&gt; $. The derived gradient (take indicator ind for simplifing) has an intuitive interpretation: Ind &gt; 0: the learning rate should be increased Ind &lt; 0: the learning rate should be decreased Ind = 0: either we reached a converged state of gradient directions are perpendicular. Second-order gradient: a newton-based method requires Hessian computations/approximations of the network’s weights, and the problem at hand has an intuitive analytical form, using only first-order weight gradients, as following suggests: $$ \\frac{\\partial^2L}{\\partial \\alpha^2}|{\\alpha=\\alpha_t}=\\frac{4}{\\alpha}&lt;g_t, g_t-g{t-1}&gt;=\\frac{4}{\\alpha_t}(||g_t||^2-&lt;g_t,g_{t-1}&gt;) \\eta_t = \\frac{\\alpha_t}{\\max(4&lt;g_t, g_t-g_{t-1}), c^{-1}&lt;g_t, g_{t-1}&gt;)} $$ where we form an overall bound on the update of which imposes smoother behavior (c was set as 1/4 in paper) Efficient GD-TLR Input: number of iterations , initial weights , learning rate , hyperparameter Output: optimized weights step 1: initialize = 0 step 2: for to do step 3: single forward-backward pass: step 4: compute step 5: update alpha according to Equation 2 and 3 [ ] step 6: update w: ; step 7: ; step 8: end for Exploring problem： the analysis in appendices, may be we will explore it next time I read it. Interested in automatical layer-wise learning rate in the future research the performance and the disadvantage of the algorithm. I think there is still necessity of experiment","categories":[],"tags":[{"name":"trainable learning rate","slug":"trainable-learning-rate","permalink":"http://yourthomaslee.github.io/tags/trainable-learning-rate/"}]},{"title":"Notes-mitigating neural network overconfidence with logit normalization","slug":"Note-mitigating neural network overconfidence with logit-normalization","date":"2022-07-11T08:49:33.000Z","updated":"2022-12-27T03:34:16.757Z","comments":true,"path":"2022/07/11/Note-mitigating neural network overconfidence with logit-normalization/","link":"","permalink":"http://yourthomaslee.github.io/2022/07/11/Note-mitigating%20neural%20network%20overconfidence%20with%20logit-normalization/","excerpt":"introduce Logit Normalization (LogitNorm), a simple fix to the cross-entropy loss (by enforcing a constant vector norm on the logits in training), to deal with overfitting or overconfidence for both in- and out-of-distribution inputs.","text":"introduce Logit Normalization (LogitNorm), a simple fix to the cross-entropy loss (by enforcing a constant vector norm on the logits in training), to deal with overfitting or overconfidence for both in- and out-of-distribution inputs. Problem: we find that even when most training examples are classified to their correct labels, the softmax cross-entropy loss can continue to increase the magnitude of the logit vectors. The growing magnitude during training thus leads to the overconfidence issue, despite having no improvement on the classification accuracy. Work: To mitigate the issue, our key idea behind LogitNorm is to decouple the influence of output’s norm from the training objective and its optimization. This can be achieved by normalizing the logit vector to have a constant norm dur- ing training. In effect, our LogitNorm loss encourages the direction of the logit output to be consistent with the corre- sponding one-hot label, without exacerbating the magnitude of the output. Trained with normalized outputs, the network tends to give conservative predictions and results in strong separability of softmax confidence scores between ID and OOD inputs Codes: https://github.com/hongxin001/logitnorm_ood Core equation: to make sure that the logit vector is a unit vector, it alleviate some challenges in optimization, or rather, let optimization does more things useful! where is logit vector, is the Euclidean norm of the logit vector, and denotes the quantity of different class labels. Comment: This work restricts the numerical bound of logit vector during optimization, and it results better model performance in classification task. Exploring problem： Can we get the better performance if we use label smoothing? what is the difference between LayerNorm and LogitNorm? Is there any other efficient way to implement LogitNorm? Is this work compatible to the paper “Long-Tail Learning via Logit Adjustment” (https://arxiv.org/pdf/2007.07314.pdf)?","categories":[],"tags":[{"name":"overfitting","slug":"overfitting","permalink":"http://yourthomaslee.github.io/tags/overfitting/"},{"name":"logit normalization","slug":"logit-normalization","permalink":"http://yourthomaslee.github.io/tags/logit-normalization/"}]},{"title":"Hello World","slug":"hello-world","date":"2022-03-20T15:33:35.180Z","updated":"2022-03-20T15:33:34.000Z","comments":true,"path":"2022/03/20/hello-world/","link":"","permalink":"http://yourthomaslee.github.io/2022/03/20/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new \"My New Post\" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"deep learning framework","slug":"deep-learning-framework","permalink":"http://yourthomaslee.github.io/tags/deep-learning-framework/"},{"name":"leetcode","slug":"leetcode","permalink":"http://yourthomaslee.github.io/tags/leetcode/"},{"name":"hash","slug":"hash","permalink":"http://yourthomaslee.github.io/tags/hash/"},{"name":"machine learning models","slug":"machine-learning-models","permalink":"http://yourthomaslee.github.io/tags/machine-learning-models/"},{"name":"Markov chain","slug":"Markov-chain","permalink":"http://yourthomaslee.github.io/tags/Markov-chain/"},{"name":"Condition random field","slug":"Condition-random-field","permalink":"http://yourthomaslee.github.io/tags/Condition-random-field/"},{"name":"number theory","slug":"number-theory","permalink":"http://yourthomaslee.github.io/tags/number-theory/"},{"name":"greedy algorithm","slug":"greedy-algorithm","permalink":"http://yourthomaslee.github.io/tags/greedy-algorithm/"},{"name":"monotonic stack","slug":"monotonic-stack","permalink":"http://yourthomaslee.github.io/tags/monotonic-stack/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://yourthomaslee.github.io/tags/machine-learning/"},{"name":"data theory","slug":"data-theory","permalink":"http://yourthomaslee.github.io/tags/data-theory/"},{"name":"feature selection","slug":"feature-selection","permalink":"http://yourthomaslee.github.io/tags/feature-selection/"},{"name":"two pointers","slug":"two-pointers","permalink":"http://yourthomaslee.github.io/tags/two-pointers/"},{"name":"computational advertising","slug":"computational-advertising","permalink":"http://yourthomaslee.github.io/tags/computational-advertising/"},{"name":"guaranteed advertising","slug":"guaranteed-advertising","permalink":"http://yourthomaslee.github.io/tags/guaranteed-advertising/"},{"name":"simulation","slug":"simulation","permalink":"http://yourthomaslee.github.io/tags/simulation/"},{"name":"model enhancement","slug":"model-enhancement","permalink":"http://yourthomaslee.github.io/tags/model-enhancement/"},{"name":"basic concepts","slug":"basic-concepts","permalink":"http://yourthomaslee.github.io/tags/basic-concepts/"},{"name":"deep learning concepts","slug":"deep-learning-concepts","permalink":"http://yourthomaslee.github.io/tags/deep-learning-concepts/"},{"name":"activation function","slug":"activation-function","permalink":"http://yourthomaslee.github.io/tags/activation-function/"},{"name":"classical modules","slug":"classical-modules","permalink":"http://yourthomaslee.github.io/tags/classical-modules/"},{"name":"array","slug":"array","permalink":"http://yourthomaslee.github.io/tags/array/"},{"name":"perception machine","slug":"perception-machine","permalink":"http://yourthomaslee.github.io/tags/perception-machine/"},{"name":"support vector machine","slug":"support-vector-machine","permalink":"http://yourthomaslee.github.io/tags/support-vector-machine/"},{"name":"logic regression","slug":"logic-regression","permalink":"http://yourthomaslee.github.io/tags/logic-regression/"},{"name":"dynamic programming","slug":"dynamic-programming","permalink":"http://yourthomaslee.github.io/tags/dynamic-programming/"},{"name":"combination","slug":"combination","permalink":"http://yourthomaslee.github.io/tags/combination/"},{"name":"interesting problems","slug":"interesting-problems","permalink":"http://yourthomaslee.github.io/tags/interesting-problems/"},{"name":"maximum entropy model","slug":"maximum-entropy-model","permalink":"http://yourthomaslee.github.io/tags/maximum-entropy-model/"},{"name":"linear regression","slug":"linear-regression","permalink":"http://yourthomaslee.github.io/tags/linear-regression/"},{"name":"machine learning framework","slug":"machine-learning-framework","permalink":"http://yourthomaslee.github.io/tags/machine-learning-framework/"},{"name":"transfomer","slug":"transfomer","permalink":"http://yourthomaslee.github.io/tags/transfomer/"},{"name":"language model","slug":"language-model","permalink":"http://yourthomaslee.github.io/tags/language-model/"},{"name":"deep learning","slug":"deep-learning","permalink":"http://yourthomaslee.github.io/tags/deep-learning/"},{"name":"training sample selection","slug":"training-sample-selection","permalink":"http://yourthomaslee.github.io/tags/training-sample-selection/"},{"name":"trainable learning rate","slug":"trainable-learning-rate","permalink":"http://yourthomaslee.github.io/tags/trainable-learning-rate/"},{"name":"overfitting","slug":"overfitting","permalink":"http://yourthomaslee.github.io/tags/overfitting/"},{"name":"logit normalization","slug":"logit-normalization","permalink":"http://yourthomaslee.github.io/tags/logit-normalization/"}]}